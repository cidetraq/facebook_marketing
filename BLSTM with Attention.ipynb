{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach to emulate:\n",
    "\n",
    "1.Input Layer\n",
    "\n",
    "2.Embedding layer\n",
    "\n",
    "3.BLSTM layer, with element-wise sum of forward/backward pass outputs\\\n",
    "\n",
    "Classification should have dropout  applied on the embedding layer, LSTM layer and penultimate layer. as Well as L2 regularization\n",
    "\n",
    "4.Attention Layer\n",
    "\n",
    "5.Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"]='theano'\n",
    "os.environ[\"KERAS_BACKEND\"]='tensorflow'\n",
    "import keras\n",
    "keras.backend.backend()\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional, GRU, Input, TimeDistributed\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers\n",
    "import lmdb\n",
    "from lmdb_embeddings.reader import LmdbEmbeddingsReader\n",
    "import lmdb_embeddings.exceptions as exceptions\n",
    "from keras.utils import to_categorical, np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import re\n",
    "import spacy\n",
    "import tensorflow as tf\n",
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Theano\n",
    "class AttLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.init = initializers.get('normal')\n",
    "        #self.input_spec = [InputSpec(ndim=3)]\n",
    "        super(AttLayer, self).__init__(** kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape)==3\n",
    "        self.W = self.add_weight(name='kernel', \n",
    "        shape=(input_shape[-1],),\n",
    "        initializer='normal',\n",
    "        trainable=True)\n",
    "        super(AttLayer, self).build(input_shape)  \n",
    "        \n",
    "    def call(self, x, mask=None):\n",
    "        eij = K.tanh(K.dot(x, self.W))\n",
    "\n",
    "        ai = K.exp(eij)\n",
    "        weights = ai/K.sum(ai, axis=1).dimshuffle(0,'x')\n",
    "\n",
    "        weighted_input = x*weights.dimshuffle(0,1,'x')\n",
    "        return weighted_input.sum(axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensorflow\n",
    "class AttLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.init = initializers.get('normal')\n",
    "        #self.input_spec = [InputSpec(ndim=3)]\n",
    "        super(AttLayer, self).__init__(** kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape)==3\n",
    "        self.W = self.add_weight(name='kernel', \n",
    "        shape=(input_shape[-1],),\n",
    "        initializer='normal',\n",
    "        trainable=True)\n",
    "        super(AttLayer, self).build(input_shape)  \n",
    "        \n",
    "    def call(self, x, mask=None):\n",
    "        eij = K.tanh(np.dot(x, self.W))\n",
    "        ai = K.exp(eij)\n",
    "        product=tf.expand_dims(K.sum(ai, axis=1), 1)\n",
    "        weights = ai/product \n",
    "        weighted_input = x*weights\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=Sequential()\n",
    "classifier.add(Bidirectional(GRU(units=25, return_sequences=True), input_shape=(6,300)))\n",
    "classifier.add(AttLayer())\n",
    "classifier.add(Dropout(0.3))\n",
    "classifier.add(Dense(units=4, activation='softmax'))\n",
    "classifier.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=load_model('models/emotions_blstm_att_tf.h5', custom_objects={'AttLayer': AttLayer()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=LmdbEmbeddingsReader('data/lmdb_databases')\n",
    "encoder=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('data/isear_plus_semeval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = ['not', 'no', 'neither', 'nor', 'but', 'however', 'although', 'nonetheless', 'despite', 'except',\n",
    "                         'even though', 'yet']\n",
    "stop = list(set(stopwords.words('english')))\n",
    "for neg in negative:\n",
    "    for stopword in stop:\n",
    "        if stopword==neg:\n",
    "            stop.remove(stopword)\n",
    "rm=['don\\'t', 'shouldn\\'t', 'doesn\\'t', 'didn\\'t']\n",
    "for r in rm:\n",
    "    stop.remove(r)\n",
    "exclude = set(string.punctuation)\n",
    "exclude.add('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(doc):\n",
    "    lemma=WordNetLemmatizer()\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = \"\".join([ch for ch in stop_free if ch not in exclude])\n",
    "    re.sub(r'\\n', '', punc_free)\n",
    "    normalized = \" \".join([lemma.lemmatize(word) for word in punc_free.split()])\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_words(li):\n",
    "    total_vecs=[]\n",
    "    for word in li:\n",
    "        try:\n",
    "            vector = embeddings.get_word_vector(word)\n",
    "        except exceptions.MissingWordError:\n",
    "            # 'google' is not in the database.\n",
    "            vector= np.zeros(300, dtype='float32')\n",
    "        total_vecs.append(vector)\n",
    "    return np.array(total_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_y(y):\n",
    "    encoder.fit(y)\n",
    "    y=encoder.transform(y)\n",
    "    y_1=np_utils.to_categorical(y)\n",
    "    #y_1=np.reshape(y_1, (-1, 4, 1))\n",
    "    return y_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_splits(series):\n",
    "    word_splits=series.str.split(' ')\n",
    "    return word_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_6(X,y=None):\n",
    "    X=pd.Series(X).apply(clean).apply(input_duplicator_train)\n",
    "    splits=word_splits(X)\n",
    "    numbers_series=splits.apply(vec_words)\n",
    "    num_docs=len(numbers_series)\n",
    "    X_1=[]\n",
    "    y_1=[]\n",
    "    for index in range(0, num_docs):\n",
    "        doc=numbers_series.iloc[index]\n",
    "        print(len(doc))\n",
    "        for i in range(6, len(doc)):\n",
    "            X_1.append(doc[i-6:i])\n",
    "            if y is not None:\n",
    "                y_1.append(y.iloc[index])\n",
    "                y_1=transform_y(y_1)\n",
    "    if y is not None:\n",
    "        return np.array(X_1), np.array(y_1)\n",
    "    else:\n",
    "        return np.array(X_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_duplicator_train(text):\n",
    "    splits=text.split(' ')\n",
    "    while len(splits)<7:\n",
    "        orig_doc=splits.copy()\n",
    "        for word in orig_doc:\n",
    "            splits.append(word)\n",
    "    return ' '.join(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_duplicator(text):\n",
    "    X=pd.Series(text).apply(clean)\n",
    "    splits=word_splits(X)\n",
    "    numbers_series=splits\n",
    "    num_docs=len(numbers_series)\n",
    "    for index, doc in enumerate(numbers_series):\n",
    "        while len(doc)<7:\n",
    "            orig_doc=doc.copy()\n",
    "            orig_doc=list(orig_doc)\n",
    "            doc=list(doc)\n",
    "            for word in orig_doc:\n",
    "                doc.append(word)\n",
    "                #doc=np.insert(doc,(len(doc)),word, axis=0)\n",
    "                #doc=np.append(doc, word, axis=1)\n",
    "            modified=True\n",
    "        numbers_series.iloc[index]=np.array(doc)\n",
    "    X_1 = []\n",
    "    if num_docs>1:\n",
    "        for index in range(0, num_docs):\n",
    "            doc=numbers_series.iloc[index]\n",
    "            for i in range(6, len(doc)):\n",
    "                X_1.append(doc[i-6:i])\n",
    "    else:\n",
    "        doc=numbers_series.iloc[0]\n",
    "        print(doc.shape)\n",
    "        for i in range(6, len(doc)):\n",
    "                X_1.append(doc[i-6:i])\n",
    "    return X_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(classifier, text):\n",
    "    X=transform(text)\n",
    "    prediction=classifier.predict(X)\n",
    "    prediction=np.mean(prediction, axis=0)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1, y_1=transform(data['1'], data['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_1, y_1, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Previous best with theano\n",
    "classifier.evaluate(X_test, y_test)\n",
    "#Theano training is many, many times slower than tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With Tensorflow\n",
    "classifier.evaluate(X_test, y_test)\n",
    "#Comparable results to without attention. This needs better implementation, closer to the papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict('''I do not happy''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save('models/emotions_blstm_att_tf.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Hierachical Attention Network With Buckets</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentence Segmentation\n",
    "text='Sentence #one... I hope it picks this up. Sentence LMFAO two! Sentence three?'\n",
    "tokens=nlp(text)\n",
    "for s in tokens.sents:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bucketed_sequence import BucketedSequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from absl import app\n",
    "\n",
    "UNK = np.zeros(300)\n",
    "#FLAGS = flags.FLAGS\n",
    "\n",
    "'''flags.DEFINE_integer('batch_size', 64, 'Batch size')\n",
    "flags.DEFINE_integer('epochs', 20, 'Number of epochs to train')\n",
    "flags.DEFINE_integer('lstm_units', 50, 'Number of LSTM units in RNN')\n",
    "flags.DEFINE_integer('dense_breadth', 64, 'Number of neurons in the dense ' +\n",
    "                     'layer')\n",
    "\n",
    "flags.DEFINE_integer('dataset_size', 4726, 'Size of training dataset')\n",
    "flags.DEFINE_integer('val_size', 1182, 'Size of validation set')\n",
    "flags.DEFINE_integer('buckets', 4, 'Number of buckets to use (run with ' +\n",
    "                     '0 to disable)')'''\n",
    "\n",
    "'''flags.DEFINE_integer('seqlen_mean', 50, 'Sequence length mean (drawn ' +\n",
    "                     'from normal distribution)')\n",
    "flags.DEFINE_integer('seqlen_stddev', 200, 'Sequence length standard ' +\n",
    "                     'deviation (drawn from normal distribution)')'''\n",
    "\n",
    "batch_size=64\n",
    "epochs=100\n",
    "lstm_units=25\n",
    "dense_breadth=64\n",
    "buckets=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=Sequential()\n",
    "classifier.add(Bidirectional(GRU(units=25, return_sequences=True), input_shape=(54,300)))\n",
    "classifier.add(LSTM(50, return_sequences=True))\n",
    "classifier.add(AttLayer())\n",
    "classifier.add(Dropout(0.3))\n",
    "classifier.add(Dense(units=4, activation='softmax'))\n",
    "classifier.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(seqs, maxlen, UNK):\n",
    "    # NOTE: prepends data\n",
    "    padded = np.array(pad_sequences(seqs, maxlen=maxlen, value=UNK, \n",
    "                                    dtype=seqs[0].dtype))\n",
    "    return np.vstack([np.expand_dims(x, axis=0) for x in padded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model):\n",
    "    # Prepare data\n",
    "    X,y=transform(data['1'], data['0'])\n",
    "    len_train=[x.shape[0] for x in X[:4000]]\n",
    "    len_val=[x.shape[0] for x in X[4000:]]\n",
    "    sequence_lengths = [x.shape[0] for x in X]\n",
    "    X = pad(X, np.max(sequence_lengths))\n",
    "    X_train=X[:4000]\n",
    "    X_test=X[4000:]\n",
    "    y_train=y[:4000]\n",
    "    y_test=y[4000:]\n",
    "    if buckets > 0:\n",
    "        # Create Sequence objects\n",
    "        train_generator = BucketedSequence(buckets, batch_size,\n",
    "                                           len_train, X_train, y_train)\n",
    "        val_generator = BucketedSequence(buckets, batch_size,\n",
    "                                         len_val, X_test, y_test)\n",
    "\n",
    "        model.fit_generator(train_generator, epochs=epochs,\n",
    "                            validation_data=val_generator,\n",
    "                            shuffle=False, verbose=True)\n",
    "    else:\n",
    "        # No bucketing\n",
    "        model.fit(x=x_train, y=y_train, epochs=epochs,\n",
    "                  validation_data=(x_val, y_val),\n",
    "                  batch_size=batch_size, verbose=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=transform(data['1'], data['0'])\n",
    "len_train=[x.shape[0] for x in X[:4000]]\n",
    "len_val=[x.shape[0] for x in X[4000:]]\n",
    "sequence_lengths = [x.shape[0] for x in X]\n",
    "X = pad(X, np.max(sequence_lengths))\n",
    "X_train=X[:4000]\n",
    "X_test=X[4000:]\n",
    "y_train=y[:4000]\n",
    "y_test=y[4000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pad(X,54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 300)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.expand_dims(y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Negations</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "negations=pd.read_csv('data/constructed_negations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "isear_semeval_negs=pd.concat([data, negations], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=isear_semeval_negs.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "X,y=transform(data['1'], data['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm=SMOTE(random_state=1, ratio='auto', k_neighbors=5, m_neighbors=10, \n",
    "         out_step=0.5, kind='regular', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pad(X,54, np.zeros(300))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0.     0.     0.     ... 0.2891 0.1951 0.1152].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-289-fd8a506effde>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my_1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mX_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mX_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_a\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0my_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_a\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nicholas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_sample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \"\"\"\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nicholas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \"\"\"\n\u001b[1;32m--> 157\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_hash_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_hash_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhash_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nicholas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[0;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[0;32m    574\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32mc:\\users\\nicholas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    439\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    442\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m             \u001b[1;31m# To ensure that array flags are maintained\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0.     0.     0.     ... 0.2891 0.1951 0.1152].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "X_1=[]\n",
    "y_1=[]\n",
    "for i in range(len(X_train)):\n",
    "    X_a, y_a=sm.fit_sample(np.ravel(X_train[i]), y_train[i])\n",
    "    X_1.append(X_a)\n",
    "    y_1.append(y_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy        3240\n",
       "sadness    2334\n",
       "anger      1484\n",
       "fear       1458\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['0'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4726/4726 [==============================] - ETA: 5:20 - loss: 1.3889 - acc: 0.250 - ETA: 2:43 - loss: 1.3869 - acc: 0.265 - ETA: 1:51 - loss: 1.3870 - acc: 0.260 - ETA: 1:25 - loss: 1.3875 - acc: 0.218 - ETA: 1:09 - loss: 1.3883 - acc: 0.212 - ETA: 59s - loss: 1.3871 - acc: 0.239 - ETA: 51s - loss: 1.3873 - acc: 0.25 - ETA: 45s - loss: 1.3870 - acc: 0.25 - ETA: 41s - loss: 1.3874 - acc: 0.25 - ETA: 38s - loss: 1.3876 - acc: 0.24 - ETA: 35s - loss: 1.3867 - acc: 0.25 - ETA: 32s - loss: 1.3863 - acc: 0.25 - ETA: 30s - loss: 1.3864 - acc: 0.25 - ETA: 28s - loss: 1.3862 - acc: 0.25 - ETA: 27s - loss: 1.3861 - acc: 0.25 - ETA: 25s - loss: 1.3857 - acc: 0.25 - ETA: 24s - loss: 1.3856 - acc: 0.25 - ETA: 23s - loss: 1.3854 - acc: 0.25 - ETA: 22s - loss: 1.3848 - acc: 0.25 - ETA: 21s - loss: 1.3849 - acc: 0.24 - ETA: 21s - loss: 1.3844 - acc: 0.25 - ETA: 20s - loss: 1.3843 - acc: 0.25 - ETA: 19s - loss: 1.3841 - acc: 0.25 - ETA: 18s - loss: 1.3842 - acc: 0.25 - ETA: 18s - loss: 1.3838 - acc: 0.25 - ETA: 17s - loss: 1.3840 - acc: 0.25 - ETA: 17s - loss: 1.3833 - acc: 0.26 - ETA: 16s - loss: 1.3836 - acc: 0.26 - ETA: 16s - loss: 1.3831 - acc: 0.26 - ETA: 15s - loss: 1.3830 - acc: 0.26 - ETA: 15s - loss: 1.3833 - acc: 0.26 - ETA: 15s - loss: 1.3833 - acc: 0.26 - ETA: 14s - loss: 1.3825 - acc: 0.26 - ETA: 14s - loss: 1.3817 - acc: 0.26 - ETA: 14s - loss: 1.3816 - acc: 0.26 - ETA: 13s - loss: 1.3812 - acc: 0.26 - ETA: 13s - loss: 1.3806 - acc: 0.27 - ETA: 13s - loss: 1.3798 - acc: 0.27 - ETA: 12s - loss: 1.3795 - acc: 0.27 - ETA: 12s - loss: 1.3786 - acc: 0.27 - ETA: 12s - loss: 1.3799 - acc: 0.27 - ETA: 12s - loss: 1.3795 - acc: 0.28 - ETA: 11s - loss: 1.3793 - acc: 0.27 - ETA: 11s - loss: 1.3791 - acc: 0.27 - ETA: 11s - loss: 1.3782 - acc: 0.27 - ETA: 11s - loss: 1.3788 - acc: 0.28 - ETA: 11s - loss: 1.3784 - acc: 0.27 - ETA: 10s - loss: 1.3786 - acc: 0.27 - ETA: 10s - loss: 1.3798 - acc: 0.27 - ETA: 10s - loss: 1.3791 - acc: 0.28 - ETA: 10s - loss: 1.3785 - acc: 0.28 - ETA: 10s - loss: 1.3777 - acc: 0.28 - ETA: 9s - loss: 1.3772 - acc: 0.2901 - ETA: 9s - loss: 1.3766 - acc: 0.292 - ETA: 9s - loss: 1.3761 - acc: 0.296 - ETA: 9s - loss: 1.3754 - acc: 0.298 - ETA: 9s - loss: 1.3750 - acc: 0.298 - ETA: 9s - loss: 1.3746 - acc: 0.299 - ETA: 8s - loss: 1.3738 - acc: 0.301 - ETA: 8s - loss: 1.3736 - acc: 0.303 - ETA: 8s - loss: 1.3732 - acc: 0.304 - ETA: 8s - loss: 1.3725 - acc: 0.305 - ETA: 8s - loss: 1.3715 - acc: 0.306 - ETA: 8s - loss: 1.3715 - acc: 0.306 - ETA: 8s - loss: 1.3705 - acc: 0.307 - ETA: 7s - loss: 1.3707 - acc: 0.307 - ETA: 7s - loss: 1.3697 - acc: 0.308 - ETA: 7s - loss: 1.3700 - acc: 0.310 - ETA: 7s - loss: 1.3690 - acc: 0.312 - ETA: 7s - loss: 1.3688 - acc: 0.313 - ETA: 7s - loss: 1.3685 - acc: 0.313 - ETA: 7s - loss: 1.3666 - acc: 0.316 - ETA: 7s - loss: 1.3653 - acc: 0.317 - ETA: 6s - loss: 1.3641 - acc: 0.318 - ETA: 6s - loss: 1.3638 - acc: 0.318 - ETA: 6s - loss: 1.3628 - acc: 0.319 - ETA: 6s - loss: 1.3614 - acc: 0.320 - ETA: 6s - loss: 1.3590 - acc: 0.323 - ETA: 6s - loss: 1.3570 - acc: 0.324 - ETA: 6s - loss: 1.3571 - acc: 0.323 - ETA: 6s - loss: 1.3572 - acc: 0.327 - ETA: 5s - loss: 1.3560 - acc: 0.328 - ETA: 5s - loss: 1.3537 - acc: 0.330 - ETA: 5s - loss: 1.3518 - acc: 0.333 - ETA: 5s - loss: 1.3496 - acc: 0.336 - ETA: 5s - loss: 1.3487 - acc: 0.336 - ETA: 5s - loss: 1.3476 - acc: 0.337 - ETA: 5s - loss: 1.3465 - acc: 0.337 - ETA: 5s - loss: 1.3444 - acc: 0.338 - ETA: 5s - loss: 1.3434 - acc: 0.338 - ETA: 5s - loss: 1.3412 - acc: 0.341 - ETA: 4s - loss: 1.3393 - acc: 0.342 - ETA: 4s - loss: 1.3382 - acc: 0.342 - ETA: 4s - loss: 1.3361 - acc: 0.343 - ETA: 4s - loss: 1.3349 - acc: 0.345 - ETA: 4s - loss: 1.3331 - acc: 0.346 - ETA: 4s - loss: 1.3304 - acc: 0.349 - ETA: 4s - loss: 1.3293 - acc: 0.350 - ETA: 4s - loss: 1.3280 - acc: 0.352 - ETA: 4s - loss: 1.3260 - acc: 0.352 - ETA: 4s - loss: 1.3270 - acc: 0.351 - ETA: 3s - loss: 1.3248 - acc: 0.352 - ETA: 3s - loss: 1.3253 - acc: 0.353 - ETA: 3s - loss: 1.3226 - acc: 0.355 - ETA: 3s - loss: 1.3193 - acc: 0.356 - ETA: 3s - loss: 1.3175 - acc: 0.357 - ETA: 3s - loss: 1.3173 - acc: 0.357 - ETA: 3s - loss: 1.3153 - acc: 0.358 - ETA: 3s - loss: 1.3134 - acc: 0.359 - ETA: 3s - loss: 1.3103 - acc: 0.361 - ETA: 3s - loss: 1.3084 - acc: 0.362 - ETA: 3s - loss: 1.3071 - acc: 0.362 - ETA: 2s - loss: 1.3067 - acc: 0.363 - ETA: 2s - loss: 1.3044 - acc: 0.365 - ETA: 2s - loss: 1.3015 - acc: 0.367 - ETA: 2s - loss: 1.3018 - acc: 0.367 - ETA: 2s - loss: 1.3005 - acc: 0.368 - ETA: 2s - loss: 1.2989 - acc: 0.370 - ETA: 2s - loss: 1.2974 - acc: 0.371 - ETA: 2s - loss: 1.2958 - acc: 0.372 - ETA: 2s - loss: 1.2939 - acc: 0.373 - ETA: 2s - loss: 1.2923 - acc: 0.374 - ETA: 2s - loss: 1.2910 - acc: 0.374 - ETA: 1s - loss: 1.2888 - acc: 0.376 - ETA: 1s - loss: 1.2868 - acc: 0.377 - ETA: 1s - loss: 1.2843 - acc: 0.379 - ETA: 1s - loss: 1.2809 - acc: 0.382 - ETA: 1s - loss: 1.2812 - acc: 0.383 - ETA: 1s - loss: 1.2810 - acc: 0.383 - ETA: 1s - loss: 1.2796 - acc: 0.384 - ETA: 1s - loss: 1.2769 - acc: 0.386 - ETA: 1s - loss: 1.2766 - acc: 0.387 - ETA: 1s - loss: 1.2752 - acc: 0.388 - ETA: 1s - loss: 1.2736 - acc: 0.388 - ETA: 1s - loss: 1.2718 - acc: 0.390 - ETA: 0s - loss: 1.2703 - acc: 0.390 - ETA: 0s - loss: 1.2683 - acc: 0.392 - ETA: 0s - loss: 1.2671 - acc: 0.392 - ETA: 0s - loss: 1.2660 - acc: 0.392 - ETA: 0s - loss: 1.2641 - acc: 0.394 - ETA: 0s - loss: 1.2611 - acc: 0.396 - ETA: 0s - loss: 1.2592 - acc: 0.397 - ETA: 0s - loss: 1.2573 - acc: 0.399 - ETA: 0s - loss: 1.2557 - acc: 0.399 - ETA: 0s - loss: 1.2538 - acc: 0.401 - ETA: 0s - loss: 1.2508 - acc: 0.403 - ETA: 0s - loss: 1.2493 - acc: 0.405 - 12s 3ms/step - loss: 1.2486 - acc: 0.4056\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4726/4726 [==============================] - ETA: 10s - loss: 1.0946 - acc: 0.43 - ETA: 10s - loss: 1.1217 - acc: 0.43 - ETA: 10s - loss: 1.0871 - acc: 0.44 - ETA: 10s - loss: 1.0690 - acc: 0.49 - ETA: 9s - loss: 1.0501 - acc: 0.5125 - ETA: 9s - loss: 1.0350 - acc: 0.546 - ETA: 9s - loss: 1.0234 - acc: 0.549 - ETA: 9s - loss: 1.0260 - acc: 0.550 - ETA: 9s - loss: 1.0283 - acc: 0.531 - ETA: 9s - loss: 1.0250 - acc: 0.528 - ETA: 9s - loss: 1.0305 - acc: 0.528 - ETA: 9s - loss: 1.0238 - acc: 0.528 - ETA: 9s - loss: 1.0174 - acc: 0.538 - ETA: 8s - loss: 1.0080 - acc: 0.544 - ETA: 8s - loss: 1.0234 - acc: 0.535 - ETA: 8s - loss: 1.0211 - acc: 0.539 - ETA: 8s - loss: 1.0277 - acc: 0.536 - ETA: 8s - loss: 1.0252 - acc: 0.541 - ETA: 8s - loss: 1.0240 - acc: 0.536 - ETA: 8s - loss: 1.0089 - acc: 0.545 - ETA: 8s - loss: 1.0187 - acc: 0.546 - ETA: 8s - loss: 1.0176 - acc: 0.549 - ETA: 8s - loss: 1.0137 - acc: 0.555 - ETA: 8s - loss: 1.0012 - acc: 0.562 - ETA: 8s - loss: 0.9996 - acc: 0.567 - ETA: 8s - loss: 1.0042 - acc: 0.564 - ETA: 8s - loss: 0.9930 - acc: 0.574 - ETA: 7s - loss: 0.9943 - acc: 0.577 - ETA: 7s - loss: 0.9872 - acc: 0.581 - ETA: 7s - loss: 0.9828 - acc: 0.583 - ETA: 7s - loss: 0.9880 - acc: 0.578 - ETA: 7s - loss: 0.9891 - acc: 0.576 - ETA: 7s - loss: 0.9886 - acc: 0.574 - ETA: 7s - loss: 0.9857 - acc: 0.577 - ETA: 7s - loss: 0.9860 - acc: 0.574 - ETA: 7s - loss: 0.9901 - acc: 0.572 - ETA: 7s - loss: 0.9863 - acc: 0.574 - ETA: 7s - loss: 0.9869 - acc: 0.574 - ETA: 7s - loss: 0.9880 - acc: 0.573 - ETA: 7s - loss: 0.9882 - acc: 0.577 - ETA: 7s - loss: 0.9874 - acc: 0.578 - ETA: 6s - loss: 0.9902 - acc: 0.579 - ETA: 6s - loss: 0.9949 - acc: 0.577 - ETA: 6s - loss: 0.9933 - acc: 0.576 - ETA: 6s - loss: 0.9900 - acc: 0.578 - ETA: 6s - loss: 0.9889 - acc: 0.579 - ETA: 6s - loss: 0.9888 - acc: 0.577 - ETA: 6s - loss: 0.9875 - acc: 0.578 - ETA: 6s - loss: 0.9838 - acc: 0.580 - ETA: 6s - loss: 0.9825 - acc: 0.582 - ETA: 6s - loss: 0.9846 - acc: 0.579 - ETA: 6s - loss: 0.9809 - acc: 0.581 - ETA: 6s - loss: 0.9792 - acc: 0.582 - ETA: 6s - loss: 0.9771 - acc: 0.584 - ETA: 6s - loss: 0.9760 - acc: 0.583 - ETA: 6s - loss: 0.9753 - acc: 0.585 - ETA: 5s - loss: 0.9784 - acc: 0.585 - ETA: 5s - loss: 0.9759 - acc: 0.586 - ETA: 5s - loss: 0.9754 - acc: 0.587 - ETA: 5s - loss: 0.9764 - acc: 0.587 - ETA: 5s - loss: 0.9758 - acc: 0.588 - ETA: 5s - loss: 0.9746 - acc: 0.588 - ETA: 5s - loss: 0.9711 - acc: 0.592 - ETA: 5s - loss: 0.9715 - acc: 0.591 - ETA: 5s - loss: 0.9712 - acc: 0.592 - ETA: 5s - loss: 0.9726 - acc: 0.591 - ETA: 5s - loss: 0.9696 - acc: 0.592 - ETA: 5s - loss: 0.9726 - acc: 0.591 - ETA: 5s - loss: 0.9726 - acc: 0.591 - ETA: 5s - loss: 0.9708 - acc: 0.592 - ETA: 5s - loss: 0.9677 - acc: 0.593 - ETA: 4s - loss: 0.9685 - acc: 0.592 - ETA: 4s - loss: 0.9645 - acc: 0.595 - ETA: 4s - loss: 0.9677 - acc: 0.593 - ETA: 4s - loss: 0.9717 - acc: 0.592 - ETA: 4s - loss: 0.9740 - acc: 0.590 - ETA: 4s - loss: 0.9757 - acc: 0.590 - ETA: 4s - loss: 0.9775 - acc: 0.588 - ETA: 4s - loss: 0.9745 - acc: 0.590 - ETA: 4s - loss: 0.9731 - acc: 0.591 - ETA: 4s - loss: 0.9732 - acc: 0.592 - ETA: 4s - loss: 0.9739 - acc: 0.591 - ETA: 4s - loss: 0.9745 - acc: 0.592 - ETA: 4s - loss: 0.9747 - acc: 0.591 - ETA: 4s - loss: 0.9733 - acc: 0.591 - ETA: 4s - loss: 0.9764 - acc: 0.590 - ETA: 3s - loss: 0.9759 - acc: 0.591 - ETA: 3s - loss: 0.9759 - acc: 0.590 - ETA: 3s - loss: 0.9753 - acc: 0.591 - ETA: 3s - loss: 0.9749 - acc: 0.590 - ETA: 3s - loss: 0.9759 - acc: 0.590 - ETA: 3s - loss: 0.9749 - acc: 0.590 - ETA: 3s - loss: 0.9741 - acc: 0.591 - ETA: 3s - loss: 0.9726 - acc: 0.592 - ETA: 3s - loss: 0.9719 - acc: 0.592 - ETA: 3s - loss: 0.9698 - acc: 0.594 - ETA: 3s - loss: 0.9731 - acc: 0.592 - ETA: 3s - loss: 0.9750 - acc: 0.591 - ETA: 3s - loss: 0.9724 - acc: 0.593 - ETA: 3s - loss: 0.9708 - acc: 0.593 - ETA: 3s - loss: 0.9699 - acc: 0.594 - ETA: 2s - loss: 0.9695 - acc: 0.595 - ETA: 2s - loss: 0.9693 - acc: 0.596 - ETA: 2s - loss: 0.9691 - acc: 0.596 - ETA: 2s - loss: 0.9698 - acc: 0.595 - ETA: 2s - loss: 0.9696 - acc: 0.595 - ETA: 2s - loss: 0.9697 - acc: 0.595 - ETA: 2s - loss: 0.9696 - acc: 0.595 - ETA: 2s - loss: 0.9678 - acc: 0.597 - ETA: 2s - loss: 0.9672 - acc: 0.597 - ETA: 2s - loss: 0.9658 - acc: 0.599 - ETA: 2s - loss: 0.9653 - acc: 0.599 - ETA: 2s - loss: 0.9638 - acc: 0.600 - ETA: 2s - loss: 0.9617 - acc: 0.601 - ETA: 2s - loss: 0.9594 - acc: 0.602 - ETA: 2s - loss: 0.9578 - acc: 0.603 - ETA: 2s - loss: 0.9570 - acc: 0.604 - ETA: 1s - loss: 0.9562 - acc: 0.604 - ETA: 1s - loss: 0.9558 - acc: 0.603 - ETA: 1s - loss: 0.9545 - acc: 0.603 - ETA: 1s - loss: 0.9529 - acc: 0.604 - ETA: 1s - loss: 0.9504 - acc: 0.605 - ETA: 1s - loss: 0.9488 - acc: 0.605 - ETA: 1s - loss: 0.9476 - acc: 0.606 - ETA: 1s - loss: 0.9454 - acc: 0.608 - ETA: 1s - loss: 0.9448 - acc: 0.608 - ETA: 1s - loss: 0.9434 - acc: 0.608 - ETA: 1s - loss: 0.9434 - acc: 0.608 - ETA: 1s - loss: 0.9441 - acc: 0.607 - ETA: 1s - loss: 0.9432 - acc: 0.607 - ETA: 1s - loss: 0.9439 - acc: 0.607 - ETA: 1s - loss: 0.9436 - acc: 0.607 - ETA: 0s - loss: 0.9436 - acc: 0.607 - ETA: 0s - loss: 0.9434 - acc: 0.608 - ETA: 0s - loss: 0.9411 - acc: 0.609 - ETA: 0s - loss: 0.9387 - acc: 0.611 - ETA: 0s - loss: 0.9373 - acc: 0.610 - ETA: 0s - loss: 0.9353 - acc: 0.612 - ETA: 0s - loss: 0.9348 - acc: 0.612 - ETA: 0s - loss: 0.9342 - acc: 0.612 - ETA: 0s - loss: 0.9333 - acc: 0.613 - ETA: 0s - loss: 0.9327 - acc: 0.614 - ETA: 0s - loss: 0.9314 - acc: 0.615 - ETA: 0s - loss: 0.9311 - acc: 0.615 - ETA: 0s - loss: 0.9301 - acc: 0.615 - ETA: 0s - loss: 0.9289 - acc: 0.616 - ETA: 0s - loss: 0.9267 - acc: 0.617 - 10s 2ms/step - loss: 0.9263 - acc: 0.6176\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4726/4726 [==============================] - ETA: 8s - loss: 0.6983 - acc: 0.750 - ETA: 8s - loss: 0.7469 - acc: 0.718 - ETA: 9s - loss: 0.8202 - acc: 0.687 - ETA: 9s - loss: 0.8001 - acc: 0.679 - ETA: 9s - loss: 0.8527 - acc: 0.668 - ETA: 9s - loss: 0.8271 - acc: 0.682 - ETA: 9s - loss: 0.8022 - acc: 0.692 - ETA: 9s - loss: 0.7749 - acc: 0.710 - ETA: 9s - loss: 0.7609 - acc: 0.715 - ETA: 9s - loss: 0.7752 - acc: 0.718 - ETA: 9s - loss: 0.7692 - acc: 0.718 - ETA: 8s - loss: 0.7539 - acc: 0.721 - ETA: 8s - loss: 0.7685 - acc: 0.716 - ETA: 8s - loss: 0.7610 - acc: 0.721 - ETA: 8s - loss: 0.7633 - acc: 0.718 - ETA: 8s - loss: 0.7603 - acc: 0.718 - ETA: 8s - loss: 0.7622 - acc: 0.713 - ETA: 8s - loss: 0.7668 - acc: 0.710 - ETA: 8s - loss: 0.7593 - acc: 0.717 - ETA: 8s - loss: 0.7585 - acc: 0.715 - ETA: 8s - loss: 0.7589 - acc: 0.712 - ETA: 8s - loss: 0.7552 - acc: 0.718 - ETA: 8s - loss: 0.7412 - acc: 0.725 - ETA: 8s - loss: 0.7421 - acc: 0.726 - ETA: 8s - loss: 0.7391 - acc: 0.728 - ETA: 8s - loss: 0.7353 - acc: 0.730 - ETA: 8s - loss: 0.7294 - acc: 0.732 - ETA: 7s - loss: 0.7276 - acc: 0.732 - ETA: 7s - loss: 0.7294 - acc: 0.728 - ETA: 7s - loss: 0.7384 - acc: 0.726 - ETA: 7s - loss: 0.7447 - acc: 0.721 - ETA: 7s - loss: 0.7456 - acc: 0.720 - ETA: 7s - loss: 0.7426 - acc: 0.722 - ETA: 7s - loss: 0.7371 - acc: 0.725 - ETA: 7s - loss: 0.7390 - acc: 0.725 - ETA: 7s - loss: 0.7499 - acc: 0.721 - ETA: 7s - loss: 0.7497 - acc: 0.721 - ETA: 7s - loss: 0.7560 - acc: 0.718 - ETA: 7s - loss: 0.7571 - acc: 0.718 - ETA: 7s - loss: 0.7605 - acc: 0.718 - ETA: 7s - loss: 0.7595 - acc: 0.720 - ETA: 6s - loss: 0.7542 - acc: 0.721 - ETA: 6s - loss: 0.7677 - acc: 0.718 - ETA: 6s - loss: 0.7736 - acc: 0.713 - ETA: 6s - loss: 0.7744 - acc: 0.711 - ETA: 6s - loss: 0.7771 - acc: 0.709 - ETA: 6s - loss: 0.7792 - acc: 0.709 - ETA: 6s - loss: 0.7763 - acc: 0.709 - ETA: 6s - loss: 0.7718 - acc: 0.711 - ETA: 6s - loss: 0.7704 - acc: 0.713 - ETA: 6s - loss: 0.7702 - acc: 0.715 - ETA: 6s - loss: 0.7669 - acc: 0.717 - ETA: 6s - loss: 0.7655 - acc: 0.717 - ETA: 6s - loss: 0.7646 - acc: 0.718 - ETA: 6s - loss: 0.7631 - acc: 0.718 - ETA: 6s - loss: 0.7716 - acc: 0.713 - ETA: 5s - loss: 0.7740 - acc: 0.711 - ETA: 5s - loss: 0.7733 - acc: 0.711 - ETA: 5s - loss: 0.7713 - acc: 0.712 - ETA: 5s - loss: 0.7683 - acc: 0.714 - ETA: 5s - loss: 0.7663 - acc: 0.715 - ETA: 5s - loss: 0.7673 - acc: 0.713 - ETA: 5s - loss: 0.7655 - acc: 0.715 - ETA: 5s - loss: 0.7653 - acc: 0.714 - ETA: 5s - loss: 0.7659 - acc: 0.714 - ETA: 5s - loss: 0.7635 - acc: 0.715 - ETA: 5s - loss: 0.7652 - acc: 0.715 - ETA: 5s - loss: 0.7629 - acc: 0.715 - ETA: 5s - loss: 0.7651 - acc: 0.714 - ETA: 5s - loss: 0.7629 - acc: 0.715 - ETA: 5s - loss: 0.7635 - acc: 0.715 - ETA: 4s - loss: 0.7638 - acc: 0.716 - ETA: 4s - loss: 0.7616 - acc: 0.716 - ETA: 4s - loss: 0.7632 - acc: 0.715 - ETA: 4s - loss: 0.7616 - acc: 0.716 - ETA: 4s - loss: 0.7617 - acc: 0.717 - ETA: 4s - loss: 0.7651 - acc: 0.716 - ETA: 4s - loss: 0.7670 - acc: 0.717 - ETA: 4s - loss: 0.7656 - acc: 0.717 - ETA: 4s - loss: 0.7633 - acc: 0.718 - ETA: 4s - loss: 0.7650 - acc: 0.718 - ETA: 4s - loss: 0.7637 - acc: 0.717 - ETA: 4s - loss: 0.7663 - acc: 0.716 - ETA: 4s - loss: 0.7669 - acc: 0.717 - ETA: 4s - loss: 0.7643 - acc: 0.718 - ETA: 4s - loss: 0.7652 - acc: 0.718 - ETA: 3s - loss: 0.7642 - acc: 0.718 - ETA: 3s - loss: 0.7651 - acc: 0.718 - ETA: 3s - loss: 0.7673 - acc: 0.717 - ETA: 3s - loss: 0.7674 - acc: 0.718 - ETA: 3s - loss: 0.7641 - acc: 0.719 - ETA: 3s - loss: 0.7649 - acc: 0.719 - ETA: 3s - loss: 0.7649 - acc: 0.720 - ETA: 3s - loss: 0.7655 - acc: 0.719 - ETA: 3s - loss: 0.7645 - acc: 0.720 - ETA: 3s - loss: 0.7650 - acc: 0.720 - ETA: 3s - loss: 0.7637 - acc: 0.720 - ETA: 3s - loss: 0.7615 - acc: 0.721 - ETA: 3s - loss: 0.7628 - acc: 0.720 - ETA: 3s - loss: 0.7606 - acc: 0.721 - ETA: 3s - loss: 0.7616 - acc: 0.721 - ETA: 2s - loss: 0.7598 - acc: 0.722 - ETA: 2s - loss: 0.7568 - acc: 0.723 - ETA: 2s - loss: 0.7579 - acc: 0.723 - ETA: 2s - loss: 0.7570 - acc: 0.723 - ETA: 2s - loss: 0.7577 - acc: 0.723 - ETA: 2s - loss: 0.7565 - acc: 0.724 - ETA: 2s - loss: 0.7553 - acc: 0.724 - ETA: 2s - loss: 0.7552 - acc: 0.723 - ETA: 2s - loss: 0.7530 - acc: 0.725 - ETA: 2s - loss: 0.7509 - acc: 0.725 - ETA: 2s - loss: 0.7488 - acc: 0.727 - ETA: 2s - loss: 0.7487 - acc: 0.726 - ETA: 2s - loss: 0.7492 - acc: 0.727 - ETA: 2s - loss: 0.7530 - acc: 0.726 - ETA: 2s - loss: 0.7526 - acc: 0.726 - ETA: 2s - loss: 0.7536 - acc: 0.726 - ETA: 1s - loss: 0.7519 - acc: 0.726 - ETA: 1s - loss: 0.7523 - acc: 0.726 - ETA: 1s - loss: 0.7529 - acc: 0.725 - ETA: 1s - loss: 0.7526 - acc: 0.725 - ETA: 1s - loss: 0.7519 - acc: 0.725 - ETA: 1s - loss: 0.7498 - acc: 0.727 - ETA: 1s - loss: 0.7497 - acc: 0.726 - ETA: 1s - loss: 0.7486 - acc: 0.727 - ETA: 1s - loss: 0.7487 - acc: 0.727 - ETA: 1s - loss: 0.7474 - acc: 0.728 - ETA: 1s - loss: 0.7464 - acc: 0.728 - ETA: 1s - loss: 0.7463 - acc: 0.728 - ETA: 1s - loss: 0.7476 - acc: 0.728 - ETA: 1s - loss: 0.7469 - acc: 0.728 - ETA: 1s - loss: 0.7452 - acc: 0.729 - ETA: 0s - loss: 0.7432 - acc: 0.729 - ETA: 0s - loss: 0.7429 - acc: 0.729 - ETA: 0s - loss: 0.7425 - acc: 0.728 - ETA: 0s - loss: 0.7436 - acc: 0.728 - ETA: 0s - loss: 0.7437 - acc: 0.727 - ETA: 0s - loss: 0.7424 - acc: 0.727 - ETA: 0s - loss: 0.7412 - acc: 0.728 - ETA: 0s - loss: 0.7423 - acc: 0.727 - ETA: 0s - loss: 0.7407 - acc: 0.728 - ETA: 0s - loss: 0.7391 - acc: 0.729 - ETA: 0s - loss: 0.7393 - acc: 0.729 - ETA: 0s - loss: 0.7375 - acc: 0.730 - ETA: 0s - loss: 0.7368 - acc: 0.731 - ETA: 0s - loss: 0.7378 - acc: 0.730 - ETA: 0s - loss: 0.7357 - acc: 0.731 - 10s 2ms/step - loss: 0.7367 - acc: 0.7313\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4726/4726 [==============================] - ETA: 9s - loss: 0.5499 - acc: 0.812 - ETA: 9s - loss: 0.4784 - acc: 0.859 - ETA: 9s - loss: 0.6235 - acc: 0.791 - ETA: 9s - loss: 0.5679 - acc: 0.828 - ETA: 9s - loss: 0.5371 - acc: 0.843 - ETA: 9s - loss: 0.5568 - acc: 0.838 - ETA: 9s - loss: 0.5751 - acc: 0.821 - ETA: 9s - loss: 0.5780 - acc: 0.824 - ETA: 9s - loss: 0.6027 - acc: 0.809 - ETA: 9s - loss: 0.5879 - acc: 0.818 - ETA: 9s - loss: 0.6228 - acc: 0.798 - ETA: 8s - loss: 0.6231 - acc: 0.796 - ETA: 8s - loss: 0.6493 - acc: 0.786 - ETA: 8s - loss: 0.6429 - acc: 0.787 - ETA: 8s - loss: 0.6298 - acc: 0.791 - ETA: 8s - loss: 0.6319 - acc: 0.793 - ETA: 8s - loss: 0.6210 - acc: 0.794 - ETA: 8s - loss: 0.6251 - acc: 0.788 - ETA: 8s - loss: 0.6332 - acc: 0.779 - ETA: 8s - loss: 0.6312 - acc: 0.779 - ETA: 8s - loss: 0.6416 - acc: 0.775 - ETA: 8s - loss: 0.6512 - acc: 0.772 - ETA: 8s - loss: 0.6428 - acc: 0.775 - ETA: 8s - loss: 0.6426 - acc: 0.772 - ETA: 8s - loss: 0.6386 - acc: 0.775 - ETA: 8s - loss: 0.6352 - acc: 0.775 - ETA: 8s - loss: 0.6375 - acc: 0.772 - ETA: 8s - loss: 0.6369 - acc: 0.773 - ETA: 7s - loss: 0.6301 - acc: 0.775 - ETA: 7s - loss: 0.6292 - acc: 0.777 - ETA: 7s - loss: 0.6322 - acc: 0.774 - ETA: 7s - loss: 0.6341 - acc: 0.771 - ETA: 7s - loss: 0.6303 - acc: 0.772 - ETA: 7s - loss: 0.6271 - acc: 0.773 - ETA: 7s - loss: 0.6269 - acc: 0.775 - ETA: 7s - loss: 0.6228 - acc: 0.776 - ETA: 7s - loss: 0.6205 - acc: 0.777 - ETA: 7s - loss: 0.6216 - acc: 0.774 - ETA: 7s - loss: 0.6213 - acc: 0.775 - ETA: 7s - loss: 0.6245 - acc: 0.773 - ETA: 7s - loss: 0.6234 - acc: 0.775 - ETA: 7s - loss: 0.6234 - acc: 0.774 - ETA: 6s - loss: 0.6251 - acc: 0.775 - ETA: 6s - loss: 0.6226 - acc: 0.775 - ETA: 6s - loss: 0.6205 - acc: 0.777 - ETA: 6s - loss: 0.6255 - acc: 0.775 - ETA: 6s - loss: 0.6274 - acc: 0.773 - ETA: 6s - loss: 0.6298 - acc: 0.773 - ETA: 6s - loss: 0.6411 - acc: 0.771 - ETA: 6s - loss: 0.6400 - acc: 0.771 - ETA: 6s - loss: 0.6415 - acc: 0.770 - ETA: 6s - loss: 0.6355 - acc: 0.772 - ETA: 6s - loss: 0.6363 - acc: 0.771 - ETA: 6s - loss: 0.6311 - acc: 0.773 - ETA: 6s - loss: 0.6352 - acc: 0.772 - ETA: 6s - loss: 0.6352 - acc: 0.771 - ETA: 5s - loss: 0.6436 - acc: 0.767 - ETA: 5s - loss: 0.6423 - acc: 0.768 - ETA: 5s - loss: 0.6398 - acc: 0.769 - ETA: 5s - loss: 0.6390 - acc: 0.770 - ETA: 5s - loss: 0.6384 - acc: 0.771 - ETA: 5s - loss: 0.6390 - acc: 0.771 - ETA: 5s - loss: 0.6420 - acc: 0.769 - ETA: 5s - loss: 0.6453 - acc: 0.767 - ETA: 5s - loss: 0.6500 - acc: 0.764 - ETA: 5s - loss: 0.6519 - acc: 0.763 - ETA: 5s - loss: 0.6493 - acc: 0.765 - ETA: 5s - loss: 0.6538 - acc: 0.763 - ETA: 5s - loss: 0.6530 - acc: 0.764 - ETA: 5s - loss: 0.6493 - acc: 0.766 - ETA: 5s - loss: 0.6469 - acc: 0.767 - ETA: 4s - loss: 0.6470 - acc: 0.766 - ETA: 4s - loss: 0.6476 - acc: 0.766 - ETA: 4s - loss: 0.6513 - acc: 0.766 - ETA: 4s - loss: 0.6515 - acc: 0.765 - ETA: 4s - loss: 0.6509 - acc: 0.766 - ETA: 4s - loss: 0.6556 - acc: 0.765 - ETA: 4s - loss: 0.6551 - acc: 0.766 - ETA: 4s - loss: 0.6550 - acc: 0.766 - ETA: 4s - loss: 0.6534 - acc: 0.767 - ETA: 4s - loss: 0.6541 - acc: 0.766 - ETA: 4s - loss: 0.6529 - acc: 0.766 - ETA: 4s - loss: 0.6520 - acc: 0.766 - ETA: 4s - loss: 0.6510 - acc: 0.767 - ETA: 4s - loss: 0.6546 - acc: 0.766 - ETA: 4s - loss: 0.6570 - acc: 0.766 - ETA: 3s - loss: 0.6569 - acc: 0.765 - ETA: 3s - loss: 0.6549 - acc: 0.766 - ETA: 3s - loss: 0.6558 - acc: 0.766 - ETA: 3s - loss: 0.6588 - acc: 0.765 - ETA: 3s - loss: 0.6561 - acc: 0.766 - ETA: 3s - loss: 0.6537 - acc: 0.767 - ETA: 3s - loss: 0.6534 - acc: 0.767 - ETA: 3s - loss: 0.6559 - acc: 0.767 - ETA: 3s - loss: 0.6543 - acc: 0.767 - ETA: 3s - loss: 0.6550 - acc: 0.767 - ETA: 3s - loss: 0.6574 - acc: 0.765 - ETA: 3s - loss: 0.6565 - acc: 0.765 - ETA: 3s - loss: 0.6550 - acc: 0.766 - ETA: 3s - loss: 0.6555 - acc: 0.766 - ETA: 3s - loss: 0.6567 - acc: 0.765 - ETA: 2s - loss: 0.6577 - acc: 0.765 - ETA: 2s - loss: 0.6556 - acc: 0.765 - ETA: 2s - loss: 0.6540 - acc: 0.766 - ETA: 2s - loss: 0.6536 - acc: 0.766 - ETA: 2s - loss: 0.6534 - acc: 0.766 - ETA: 2s - loss: 0.6513 - acc: 0.767 - ETA: 2s - loss: 0.6507 - acc: 0.768 - ETA: 2s - loss: 0.6500 - acc: 0.768 - ETA: 2s - loss: 0.6500 - acc: 0.767 - ETA: 2s - loss: 0.6526 - acc: 0.766 - ETA: 2s - loss: 0.6537 - acc: 0.766 - ETA: 2s - loss: 0.6556 - acc: 0.765 - ETA: 2s - loss: 0.6560 - acc: 0.764 - ETA: 2s - loss: 0.6552 - acc: 0.765 - ETA: 2s - loss: 0.6574 - acc: 0.765 - ETA: 1s - loss: 0.6585 - acc: 0.764 - ETA: 1s - loss: 0.6591 - acc: 0.764 - ETA: 1s - loss: 0.6584 - acc: 0.764 - ETA: 1s - loss: 0.6582 - acc: 0.764 - ETA: 1s - loss: 0.6577 - acc: 0.764 - ETA: 1s - loss: 0.6569 - acc: 0.765 - ETA: 1s - loss: 0.6572 - acc: 0.764 - ETA: 1s - loss: 0.6574 - acc: 0.764 - ETA: 1s - loss: 0.6583 - acc: 0.764 - ETA: 1s - loss: 0.6578 - acc: 0.764 - ETA: 1s - loss: 0.6594 - acc: 0.764 - ETA: 1s - loss: 0.6596 - acc: 0.764 - ETA: 1s - loss: 0.6602 - acc: 0.764 - ETA: 1s - loss: 0.6600 - acc: 0.764 - ETA: 1s - loss: 0.6600 - acc: 0.764 - ETA: 1s - loss: 0.6599 - acc: 0.764 - ETA: 0s - loss: 0.6593 - acc: 0.765 - ETA: 0s - loss: 0.6584 - acc: 0.765 - ETA: 0s - loss: 0.6585 - acc: 0.765 - ETA: 0s - loss: 0.6581 - acc: 0.765 - ETA: 0s - loss: 0.6582 - acc: 0.765 - ETA: 0s - loss: 0.6577 - acc: 0.765 - ETA: 0s - loss: 0.6570 - acc: 0.765 - ETA: 0s - loss: 0.6561 - acc: 0.765 - ETA: 0s - loss: 0.6562 - acc: 0.765 - ETA: 0s - loss: 0.6560 - acc: 0.765 - ETA: 0s - loss: 0.6546 - acc: 0.766 - ETA: 0s - loss: 0.6523 - acc: 0.767 - ETA: 0s - loss: 0.6533 - acc: 0.766 - ETA: 0s - loss: 0.6557 - acc: 0.766 - ETA: 0s - loss: 0.6556 - acc: 0.766 - 10s 2ms/step - loss: 0.6564 - acc: 0.7662\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4726/4726 [==============================] - ETA: 9s - loss: 0.5038 - acc: 0.875 - ETA: 9s - loss: 0.5230 - acc: 0.828 - ETA: 9s - loss: 0.5902 - acc: 0.791 - ETA: 9s - loss: 0.5421 - acc: 0.804 - ETA: 9s - loss: 0.5301 - acc: 0.812 - ETA: 9s - loss: 0.5630 - acc: 0.807 - ETA: 9s - loss: 0.5483 - acc: 0.817 - ETA: 9s - loss: 0.5507 - acc: 0.812 - ETA: 9s - loss: 0.5787 - acc: 0.805 - ETA: 9s - loss: 0.5603 - acc: 0.812 - ETA: 9s - loss: 0.5670 - acc: 0.804 - ETA: 9s - loss: 0.5614 - acc: 0.799 - ETA: 8s - loss: 0.5908 - acc: 0.788 - ETA: 8s - loss: 0.6148 - acc: 0.781 - ETA: 8s - loss: 0.6025 - acc: 0.787 - ETA: 8s - loss: 0.6095 - acc: 0.777 - ETA: 8s - loss: 0.5939 - acc: 0.784 - ETA: 8s - loss: 0.5991 - acc: 0.789 - ETA: 8s - loss: 0.5981 - acc: 0.789 - ETA: 8s - loss: 0.5966 - acc: 0.790 - ETA: 8s - loss: 0.6008 - acc: 0.790 - ETA: 8s - loss: 0.5994 - acc: 0.792 - ETA: 8s - loss: 0.5929 - acc: 0.794 - ETA: 8s - loss: 0.5791 - acc: 0.800 - ETA: 8s - loss: 0.5771 - acc: 0.802 - ETA: 8s - loss: 0.5669 - acc: 0.806 - ETA: 7s - loss: 0.5713 - acc: 0.805 - ETA: 7s - loss: 0.5687 - acc: 0.805 - ETA: 7s - loss: 0.5782 - acc: 0.797 - ETA: 7s - loss: 0.5829 - acc: 0.794 - ETA: 7s - loss: 0.5824 - acc: 0.793 - ETA: 7s - loss: 0.5857 - acc: 0.790 - ETA: 7s - loss: 0.5903 - acc: 0.789 - ETA: 7s - loss: 0.5909 - acc: 0.785 - ETA: 7s - loss: 0.5954 - acc: 0.782 - ETA: 7s - loss: 0.5906 - acc: 0.783 - ETA: 7s - loss: 0.5922 - acc: 0.780 - ETA: 7s - loss: 0.5976 - acc: 0.779 - ETA: 7s - loss: 0.5976 - acc: 0.780 - ETA: 7s - loss: 0.5966 - acc: 0.780 - ETA: 7s - loss: 0.5989 - acc: 0.779 - ETA: 7s - loss: 0.5987 - acc: 0.779 - ETA: 6s - loss: 0.5983 - acc: 0.780 - ETA: 6s - loss: 0.6045 - acc: 0.779 - ETA: 6s - loss: 0.6083 - acc: 0.776 - ETA: 6s - loss: 0.6086 - acc: 0.777 - ETA: 6s - loss: 0.6068 - acc: 0.778 - ETA: 6s - loss: 0.6039 - acc: 0.779 - ETA: 6s - loss: 0.5999 - acc: 0.781 - ETA: 6s - loss: 0.6002 - acc: 0.781 - ETA: 6s - loss: 0.6051 - acc: 0.781 - ETA: 6s - loss: 0.6037 - acc: 0.781 - ETA: 6s - loss: 0.6080 - acc: 0.778 - ETA: 6s - loss: 0.6142 - acc: 0.777 - ETA: 6s - loss: 0.6093 - acc: 0.780 - ETA: 6s - loss: 0.6110 - acc: 0.779 - ETA: 6s - loss: 0.6073 - acc: 0.781 - ETA: 5s - loss: 0.6095 - acc: 0.779 - ETA: 5s - loss: 0.6100 - acc: 0.778 - ETA: 5s - loss: 0.6127 - acc: 0.776 - ETA: 5s - loss: 0.6122 - acc: 0.776 - ETA: 5s - loss: 0.6130 - acc: 0.775 - ETA: 5s - loss: 0.6120 - acc: 0.776 - ETA: 5s - loss: 0.6124 - acc: 0.775 - ETA: 5s - loss: 0.6136 - acc: 0.776 - ETA: 5s - loss: 0.6127 - acc: 0.776 - ETA: 5s - loss: 0.6116 - acc: 0.776 - ETA: 5s - loss: 0.6106 - acc: 0.778 - ETA: 5s - loss: 0.6101 - acc: 0.778 - ETA: 5s - loss: 0.6111 - acc: 0.778 - ETA: 5s - loss: 0.6115 - acc: 0.779 - ETA: 5s - loss: 0.6101 - acc: 0.779 - ETA: 4s - loss: 0.6141 - acc: 0.777 - ETA: 4s - loss: 0.6117 - acc: 0.777 - ETA: 4s - loss: 0.6111 - acc: 0.778 - ETA: 4s - loss: 0.6093 - acc: 0.780 - ETA: 4s - loss: 0.6076 - acc: 0.781 - ETA: 4s - loss: 0.6059 - acc: 0.782 - ETA: 4s - loss: 0.6030 - acc: 0.782 - ETA: 4s - loss: 0.6038 - acc: 0.782 - ETA: 4s - loss: 0.6019 - acc: 0.782 - ETA: 4s - loss: 0.6068 - acc: 0.781 - ETA: 4s - loss: 0.6087 - acc: 0.780 - ETA: 4s - loss: 0.6104 - acc: 0.780 - ETA: 4s - loss: 0.6102 - acc: 0.780 - ETA: 4s - loss: 0.6062 - acc: 0.782 - ETA: 4s - loss: 0.6057 - acc: 0.783 - ETA: 3s - loss: 0.6061 - acc: 0.783 - ETA: 3s - loss: 0.6067 - acc: 0.782 - ETA: 3s - loss: 0.6062 - acc: 0.781 - ETA: 3s - loss: 0.6042 - acc: 0.783 - ETA: 3s - loss: 0.6032 - acc: 0.783 - ETA: 3s - loss: 0.6032 - acc: 0.783 - ETA: 3s - loss: 0.6037 - acc: 0.782 - ETA: 3s - loss: 0.6018 - acc: 0.783 - ETA: 3s - loss: 0.6024 - acc: 0.782 - ETA: 3s - loss: 0.6029 - acc: 0.783 - ETA: 3s - loss: 0.6010 - acc: 0.783 - ETA: 3s - loss: 0.6003 - acc: 0.784 - ETA: 3s - loss: 0.6008 - acc: 0.784 - ETA: 3s - loss: 0.6006 - acc: 0.784 - ETA: 3s - loss: 0.6000 - acc: 0.785 - ETA: 2s - loss: 0.6022 - acc: 0.784 - ETA: 2s - loss: 0.6056 - acc: 0.782 - ETA: 2s - loss: 0.6091 - acc: 0.781 - ETA: 2s - loss: 0.6075 - acc: 0.782 - ETA: 2s - loss: 0.6095 - acc: 0.782 - ETA: 2s - loss: 0.6088 - acc: 0.782 - ETA: 2s - loss: 0.6084 - acc: 0.782 - ETA: 2s - loss: 0.6083 - acc: 0.782 - ETA: 2s - loss: 0.6077 - acc: 0.782 - ETA: 2s - loss: 0.6090 - acc: 0.782 - ETA: 2s - loss: 0.6089 - acc: 0.782 - ETA: 2s - loss: 0.6083 - acc: 0.782 - ETA: 2s - loss: 0.6079 - acc: 0.781 - ETA: 2s - loss: 0.6070 - acc: 0.783 - ETA: 2s - loss: 0.6074 - acc: 0.783 - ETA: 1s - loss: 0.6069 - acc: 0.783 - ETA: 1s - loss: 0.6078 - acc: 0.783 - ETA: 1s - loss: 0.6067 - acc: 0.784 - ETA: 1s - loss: 0.6079 - acc: 0.783 - ETA: 1s - loss: 0.6083 - acc: 0.782 - ETA: 1s - loss: 0.6073 - acc: 0.782 - ETA: 1s - loss: 0.6066 - acc: 0.783 - ETA: 1s - loss: 0.6092 - acc: 0.781 - ETA: 1s - loss: 0.6085 - acc: 0.781 - ETA: 1s - loss: 0.6089 - acc: 0.781 - ETA: 1s - loss: 0.6073 - acc: 0.781 - ETA: 1s - loss: 0.6076 - acc: 0.780 - ETA: 1s - loss: 0.6058 - acc: 0.781 - ETA: 1s - loss: 0.6042 - acc: 0.782 - ETA: 1s - loss: 0.6044 - acc: 0.781 - ETA: 0s - loss: 0.6044 - acc: 0.781 - ETA: 0s - loss: 0.6043 - acc: 0.781 - ETA: 0s - loss: 0.6025 - acc: 0.782 - ETA: 0s - loss: 0.6018 - acc: 0.782 - ETA: 0s - loss: 0.6014 - acc: 0.782 - ETA: 0s - loss: 0.6026 - acc: 0.781 - ETA: 0s - loss: 0.6046 - acc: 0.781 - ETA: 0s - loss: 0.6050 - acc: 0.781 - ETA: 0s - loss: 0.6059 - acc: 0.781 - ETA: 0s - loss: 0.6057 - acc: 0.781 - ETA: 0s - loss: 0.6038 - acc: 0.781 - ETA: 0s - loss: 0.6032 - acc: 0.781 - ETA: 0s - loss: 0.6040 - acc: 0.781 - ETA: 0s - loss: 0.6042 - acc: 0.781 - ETA: 0s - loss: 0.6032 - acc: 0.782 - 10s 2ms/step - loss: 0.6026 - acc: 0.7823\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4726/4726 [==============================] - ETA: 9s - loss: 0.4637 - acc: 0.750 - ETA: 9s - loss: 0.5339 - acc: 0.750 - ETA: 9s - loss: 0.5426 - acc: 0.791 - ETA: 9s - loss: 0.5410 - acc: 0.789 - ETA: 9s - loss: 0.5820 - acc: 0.781 - ETA: 9s - loss: 0.5760 - acc: 0.781 - ETA: 9s - loss: 0.5613 - acc: 0.772 - ETA: 9s - loss: 0.5519 - acc: 0.773 - ETA: 8s - loss: 0.5766 - acc: 0.770 - ETA: 8s - loss: 0.5496 - acc: 0.787 - ETA: 8s - loss: 0.5812 - acc: 0.784 - ETA: 8s - loss: 0.5704 - acc: 0.789 - ETA: 8s - loss: 0.5848 - acc: 0.790 - ETA: 8s - loss: 0.5741 - acc: 0.796 - ETA: 8s - loss: 0.5929 - acc: 0.789 - ETA: 8s - loss: 0.6083 - acc: 0.789 - ETA: 8s - loss: 0.6002 - acc: 0.790 - ETA: 8s - loss: 0.5993 - acc: 0.784 - ETA: 8s - loss: 0.5881 - acc: 0.789 - ETA: 8s - loss: 0.5726 - acc: 0.795 - ETA: 8s - loss: 0.5774 - acc: 0.794 - ETA: 8s - loss: 0.5770 - acc: 0.795 - ETA: 8s - loss: 0.5755 - acc: 0.793 - ETA: 8s - loss: 0.5762 - acc: 0.794 - ETA: 8s - loss: 0.5666 - acc: 0.798 - ETA: 7s - loss: 0.5627 - acc: 0.799 - ETA: 7s - loss: 0.5616 - acc: 0.800 - ETA: 7s - loss: 0.5658 - acc: 0.798 - ETA: 7s - loss: 0.5649 - acc: 0.796 - ETA: 7s - loss: 0.5596 - acc: 0.797 - ETA: 7s - loss: 0.5533 - acc: 0.801 - ETA: 7s - loss: 0.5579 - acc: 0.800 - ETA: 7s - loss: 0.5542 - acc: 0.799 - ETA: 7s - loss: 0.5715 - acc: 0.790 - ETA: 7s - loss: 0.5775 - acc: 0.788 - ETA: 7s - loss: 0.5769 - acc: 0.789 - ETA: 7s - loss: 0.5783 - acc: 0.791 - ETA: 7s - loss: 0.5738 - acc: 0.792 - ETA: 7s - loss: 0.5796 - acc: 0.790 - ETA: 7s - loss: 0.5838 - acc: 0.789 - ETA: 7s - loss: 0.5797 - acc: 0.790 - ETA: 6s - loss: 0.5751 - acc: 0.793 - ETA: 6s - loss: 0.5749 - acc: 0.793 - ETA: 6s - loss: 0.5728 - acc: 0.793 - ETA: 6s - loss: 0.5739 - acc: 0.794 - ETA: 6s - loss: 0.5761 - acc: 0.791 - ETA: 6s - loss: 0.5818 - acc: 0.790 - ETA: 6s - loss: 0.5845 - acc: 0.787 - ETA: 6s - loss: 0.5873 - acc: 0.787 - ETA: 6s - loss: 0.5835 - acc: 0.788 - ETA: 6s - loss: 0.5813 - acc: 0.789 - ETA: 6s - loss: 0.5759 - acc: 0.793 - ETA: 6s - loss: 0.5736 - acc: 0.794 - ETA: 6s - loss: 0.5768 - acc: 0.794 - ETA: 6s - loss: 0.5802 - acc: 0.792 - ETA: 6s - loss: 0.5843 - acc: 0.791 - ETA: 5s - loss: 0.5836 - acc: 0.791 - ETA: 5s - loss: 0.5839 - acc: 0.790 - ETA: 5s - loss: 0.5862 - acc: 0.790 - ETA: 5s - loss: 0.5856 - acc: 0.790 - ETA: 5s - loss: 0.5892 - acc: 0.788 - ETA: 5s - loss: 0.5847 - acc: 0.790 - ETA: 5s - loss: 0.5846 - acc: 0.790 - ETA: 5s - loss: 0.5834 - acc: 0.791 - ETA: 5s - loss: 0.5828 - acc: 0.791 - ETA: 5s - loss: 0.5830 - acc: 0.792 - ETA: 5s - loss: 0.5846 - acc: 0.790 - ETA: 5s - loss: 0.5815 - acc: 0.791 - ETA: 5s - loss: 0.5801 - acc: 0.790 - ETA: 5s - loss: 0.5786 - acc: 0.792 - ETA: 5s - loss: 0.5787 - acc: 0.792 - ETA: 4s - loss: 0.5806 - acc: 0.790 - ETA: 4s - loss: 0.5838 - acc: 0.789 - ETA: 4s - loss: 0.5831 - acc: 0.790 - ETA: 4s - loss: 0.5842 - acc: 0.790 - ETA: 4s - loss: 0.5809 - acc: 0.790 - ETA: 4s - loss: 0.5789 - acc: 0.791 - ETA: 4s - loss: 0.5800 - acc: 0.791 - ETA: 4s - loss: 0.5819 - acc: 0.789 - ETA: 4s - loss: 0.5856 - acc: 0.788 - ETA: 4s - loss: 0.5885 - acc: 0.787 - ETA: 4s - loss: 0.5864 - acc: 0.788 - ETA: 4s - loss: 0.5828 - acc: 0.790 - ETA: 4s - loss: 0.5841 - acc: 0.790 - ETA: 4s - loss: 0.5816 - acc: 0.792 - ETA: 4s - loss: 0.5829 - acc: 0.791 - ETA: 3s - loss: 0.5806 - acc: 0.793 - ETA: 3s - loss: 0.5809 - acc: 0.793 - ETA: 3s - loss: 0.5813 - acc: 0.792 - ETA: 3s - loss: 0.5792 - acc: 0.793 - ETA: 3s - loss: 0.5797 - acc: 0.793 - ETA: 3s - loss: 0.5807 - acc: 0.793 - ETA: 3s - loss: 0.5839 - acc: 0.792 - ETA: 3s - loss: 0.5859 - acc: 0.792 - ETA: 3s - loss: 0.5851 - acc: 0.792 - ETA: 3s - loss: 0.5844 - acc: 0.792 - ETA: 3s - loss: 0.5834 - acc: 0.792 - ETA: 3s - loss: 0.5826 - acc: 0.794 - ETA: 3s - loss: 0.5822 - acc: 0.794 - ETA: 3s - loss: 0.5798 - acc: 0.795 - ETA: 3s - loss: 0.5799 - acc: 0.795 - ETA: 2s - loss: 0.5785 - acc: 0.796 - ETA: 2s - loss: 0.5765 - acc: 0.797 - ETA: 2s - loss: 0.5777 - acc: 0.796 - ETA: 2s - loss: 0.5751 - acc: 0.797 - ETA: 2s - loss: 0.5734 - acc: 0.798 - ETA: 2s - loss: 0.5749 - acc: 0.797 - ETA: 2s - loss: 0.5764 - acc: 0.797 - ETA: 2s - loss: 0.5756 - acc: 0.797 - ETA: 2s - loss: 0.5742 - acc: 0.798 - ETA: 2s - loss: 0.5738 - acc: 0.799 - ETA: 2s - loss: 0.5709 - acc: 0.800 - ETA: 2s - loss: 0.5696 - acc: 0.800 - ETA: 2s - loss: 0.5718 - acc: 0.801 - ETA: 2s - loss: 0.5724 - acc: 0.801 - ETA: 2s - loss: 0.5712 - acc: 0.802 - ETA: 1s - loss: 0.5712 - acc: 0.801 - ETA: 1s - loss: 0.5703 - acc: 0.801 - ETA: 1s - loss: 0.5692 - acc: 0.802 - ETA: 1s - loss: 0.5695 - acc: 0.802 - ETA: 1s - loss: 0.5695 - acc: 0.801 - ETA: 1s - loss: 0.5684 - acc: 0.802 - ETA: 1s - loss: 0.5699 - acc: 0.802 - ETA: 1s - loss: 0.5701 - acc: 0.802 - ETA: 1s - loss: 0.5674 - acc: 0.803 - ETA: 1s - loss: 0.5684 - acc: 0.803 - ETA: 1s - loss: 0.5697 - acc: 0.802 - ETA: 1s - loss: 0.5680 - acc: 0.803 - ETA: 1s - loss: 0.5673 - acc: 0.802 - ETA: 1s - loss: 0.5663 - acc: 0.802 - ETA: 1s - loss: 0.5699 - acc: 0.801 - ETA: 1s - loss: 0.5684 - acc: 0.802 - ETA: 0s - loss: 0.5685 - acc: 0.801 - ETA: 0s - loss: 0.5673 - acc: 0.802 - ETA: 0s - loss: 0.5668 - acc: 0.802 - ETA: 0s - loss: 0.5654 - acc: 0.803 - ETA: 0s - loss: 0.5669 - acc: 0.802 - ETA: 0s - loss: 0.5664 - acc: 0.802 - ETA: 0s - loss: 0.5664 - acc: 0.801 - ETA: 0s - loss: 0.5660 - acc: 0.802 - ETA: 0s - loss: 0.5649 - acc: 0.802 - ETA: 0s - loss: 0.5638 - acc: 0.802 - ETA: 0s - loss: 0.5634 - acc: 0.802 - ETA: 0s - loss: 0.5626 - acc: 0.803 - ETA: 0s - loss: 0.5610 - acc: 0.804 - ETA: 0s - loss: 0.5590 - acc: 0.805 - ETA: 0s - loss: 0.5598 - acc: 0.804 - 10s 2ms/step - loss: 0.5593 - acc: 0.8051\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4726/4726 [==============================] - ETA: 8s - loss: 0.6523 - acc: 0.687 - ETA: 8s - loss: 0.6348 - acc: 0.718 - ETA: 8s - loss: 0.5535 - acc: 0.760 - ETA: 8s - loss: 0.5417 - acc: 0.781 - ETA: 8s - loss: 0.5437 - acc: 0.781 - ETA: 8s - loss: 0.5848 - acc: 0.760 - ETA: 8s - loss: 0.5656 - acc: 0.767 - ETA: 8s - loss: 0.5856 - acc: 0.761 - ETA: 8s - loss: 0.5748 - acc: 0.760 - ETA: 8s - loss: 0.5386 - acc: 0.781 - ETA: 8s - loss: 0.5310 - acc: 0.789 - ETA: 8s - loss: 0.5223 - acc: 0.794 - ETA: 8s - loss: 0.5298 - acc: 0.790 - ETA: 8s - loss: 0.5250 - acc: 0.796 - ETA: 8s - loss: 0.5163 - acc: 0.800 - ETA: 8s - loss: 0.5142 - acc: 0.804 - ETA: 8s - loss: 0.5259 - acc: 0.801 - ETA: 8s - loss: 0.5343 - acc: 0.795 - ETA: 8s - loss: 0.5263 - acc: 0.802 - ETA: 8s - loss: 0.5206 - acc: 0.806 - ETA: 8s - loss: 0.5048 - acc: 0.814 - ETA: 8s - loss: 0.5020 - acc: 0.813 - ETA: 7s - loss: 0.5014 - acc: 0.812 - ETA: 7s - loss: 0.5043 - acc: 0.811 - ETA: 7s - loss: 0.5009 - acc: 0.812 - ETA: 7s - loss: 0.5079 - acc: 0.811 - ETA: 7s - loss: 0.5072 - acc: 0.812 - ETA: 7s - loss: 0.5053 - acc: 0.811 - ETA: 7s - loss: 0.5032 - acc: 0.811 - ETA: 7s - loss: 0.4998 - acc: 0.813 - ETA: 7s - loss: 0.4953 - acc: 0.816 - ETA: 7s - loss: 0.4967 - acc: 0.816 - ETA: 7s - loss: 0.5013 - acc: 0.814 - ETA: 7s - loss: 0.5108 - acc: 0.813 - ETA: 7s - loss: 0.5108 - acc: 0.814 - ETA: 7s - loss: 0.5056 - acc: 0.817 - ETA: 7s - loss: 0.5032 - acc: 0.817 - ETA: 7s - loss: 0.5034 - acc: 0.818 - ETA: 6s - loss: 0.4990 - acc: 0.818 - ETA: 6s - loss: 0.5031 - acc: 0.816 - ETA: 6s - loss: 0.5095 - acc: 0.814 - ETA: 6s - loss: 0.5066 - acc: 0.815 - ETA: 6s - loss: 0.4990 - acc: 0.818 - ETA: 6s - loss: 0.5098 - acc: 0.816 - ETA: 6s - loss: 0.5091 - acc: 0.817 - ETA: 6s - loss: 0.5122 - acc: 0.815 - ETA: 6s - loss: 0.5104 - acc: 0.814 - ETA: 6s - loss: 0.5114 - acc: 0.813 - ETA: 6s - loss: 0.5142 - acc: 0.813 - ETA: 6s - loss: 0.5180 - acc: 0.812 - ETA: 6s - loss: 0.5153 - acc: 0.813 - ETA: 6s - loss: 0.5148 - acc: 0.812 - ETA: 6s - loss: 0.5142 - acc: 0.813 - ETA: 5s - loss: 0.5159 - acc: 0.813 - ETA: 5s - loss: 0.5222 - acc: 0.810 - ETA: 5s - loss: 0.5201 - acc: 0.811 - ETA: 5s - loss: 0.5168 - acc: 0.812 - ETA: 5s - loss: 0.5164 - acc: 0.813 - ETA: 5s - loss: 0.5167 - acc: 0.813 - ETA: 5s - loss: 0.5196 - acc: 0.813 - ETA: 5s - loss: 0.5181 - acc: 0.812 - ETA: 5s - loss: 0.5191 - acc: 0.812 - ETA: 5s - loss: 0.5238 - acc: 0.810 - ETA: 5s - loss: 0.5238 - acc: 0.809 - ETA: 5s - loss: 0.5218 - acc: 0.810 - ETA: 5s - loss: 0.5286 - acc: 0.808 - ETA: 5s - loss: 0.5282 - acc: 0.808 - ETA: 5s - loss: 0.5303 - acc: 0.809 - ETA: 5s - loss: 0.5339 - acc: 0.807 - ETA: 4s - loss: 0.5324 - acc: 0.808 - ETA: 4s - loss: 0.5278 - acc: 0.810 - ETA: 4s - loss: 0.5256 - acc: 0.811 - ETA: 4s - loss: 0.5231 - acc: 0.812 - ETA: 4s - loss: 0.5241 - acc: 0.812 - ETA: 4s - loss: 0.5218 - acc: 0.813 - ETA: 4s - loss: 0.5224 - acc: 0.814 - ETA: 4s - loss: 0.5202 - acc: 0.815 - ETA: 4s - loss: 0.5226 - acc: 0.813 - ETA: 4s - loss: 0.5203 - acc: 0.814 - ETA: 4s - loss: 0.5164 - acc: 0.816 - ETA: 4s - loss: 0.5177 - acc: 0.816 - ETA: 4s - loss: 0.5162 - acc: 0.817 - ETA: 4s - loss: 0.5150 - acc: 0.817 - ETA: 4s - loss: 0.5140 - acc: 0.818 - ETA: 4s - loss: 0.5129 - acc: 0.818 - ETA: 4s - loss: 0.5123 - acc: 0.819 - ETA: 3s - loss: 0.5139 - acc: 0.817 - ETA: 3s - loss: 0.5140 - acc: 0.818 - ETA: 3s - loss: 0.5118 - acc: 0.818 - ETA: 3s - loss: 0.5117 - acc: 0.818 - ETA: 3s - loss: 0.5133 - acc: 0.818 - ETA: 3s - loss: 0.5195 - acc: 0.816 - ETA: 3s - loss: 0.5179 - acc: 0.817 - ETA: 3s - loss: 0.5203 - acc: 0.815 - ETA: 3s - loss: 0.5234 - acc: 0.814 - ETA: 3s - loss: 0.5213 - acc: 0.815 - ETA: 3s - loss: 0.5205 - acc: 0.816 - ETA: 3s - loss: 0.5211 - acc: 0.815 - ETA: 3s - loss: 0.5210 - acc: 0.815 - ETA: 3s - loss: 0.5216 - acc: 0.814 - ETA: 3s - loss: 0.5237 - acc: 0.813 - ETA: 3s - loss: 0.5227 - acc: 0.813 - ETA: 2s - loss: 0.5207 - acc: 0.814 - ETA: 2s - loss: 0.5200 - acc: 0.814 - ETA: 2s - loss: 0.5204 - acc: 0.814 - ETA: 2s - loss: 0.5201 - acc: 0.814 - ETA: 2s - loss: 0.5222 - acc: 0.813 - ETA: 2s - loss: 0.5220 - acc: 0.813 - ETA: 2s - loss: 0.5217 - acc: 0.813 - ETA: 2s - loss: 0.5218 - acc: 0.812 - ETA: 2s - loss: 0.5206 - acc: 0.813 - ETA: 2s - loss: 0.5204 - acc: 0.813 - ETA: 2s - loss: 0.5195 - acc: 0.813 - ETA: 2s - loss: 0.5212 - acc: 0.812 - ETA: 2s - loss: 0.5217 - acc: 0.812 - ETA: 2s - loss: 0.5195 - acc: 0.813 - ETA: 2s - loss: 0.5218 - acc: 0.813 - ETA: 1s - loss: 0.5213 - acc: 0.813 - ETA: 1s - loss: 0.5214 - acc: 0.813 - ETA: 1s - loss: 0.5223 - acc: 0.812 - ETA: 1s - loss: 0.5231 - acc: 0.812 - ETA: 1s - loss: 0.5230 - acc: 0.812 - ETA: 1s - loss: 0.5224 - acc: 0.812 - ETA: 1s - loss: 0.5207 - acc: 0.813 - ETA: 1s - loss: 0.5215 - acc: 0.812 - ETA: 1s - loss: 0.5227 - acc: 0.813 - ETA: 1s - loss: 0.5226 - acc: 0.813 - ETA: 1s - loss: 0.5206 - acc: 0.814 - ETA: 1s - loss: 0.5183 - acc: 0.814 - ETA: 1s - loss: 0.5178 - acc: 0.814 - ETA: 1s - loss: 0.5193 - acc: 0.814 - ETA: 1s - loss: 0.5188 - acc: 0.814 - ETA: 0s - loss: 0.5184 - acc: 0.814 - ETA: 0s - loss: 0.5203 - acc: 0.813 - ETA: 0s - loss: 0.5203 - acc: 0.813 - ETA: 0s - loss: 0.5195 - acc: 0.813 - ETA: 0s - loss: 0.5193 - acc: 0.813 - ETA: 0s - loss: 0.5199 - acc: 0.813 - ETA: 0s - loss: 0.5207 - acc: 0.813 - ETA: 0s - loss: 0.5190 - acc: 0.814 - ETA: 0s - loss: 0.5194 - acc: 0.814 - ETA: 0s - loss: 0.5206 - acc: 0.813 - ETA: 0s - loss: 0.5211 - acc: 0.813 - ETA: 0s - loss: 0.5205 - acc: 0.813 - ETA: 0s - loss: 0.5231 - acc: 0.812 - ETA: 0s - loss: 0.5229 - acc: 0.812 - ETA: 0s - loss: 0.5220 - acc: 0.813 - 10s 2ms/step - loss: 0.5219 - acc: 0.8136\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4726/4726 [==============================] - ETA: 8s - loss: 0.3145 - acc: 0.937 - ETA: 9s - loss: 0.3564 - acc: 0.906 - ETA: 9s - loss: 0.4798 - acc: 0.875 - ETA: 9s - loss: 0.4386 - acc: 0.875 - ETA: 9s - loss: 0.4361 - acc: 0.875 - ETA: 8s - loss: 0.4105 - acc: 0.890 - ETA: 8s - loss: 0.4501 - acc: 0.861 - ETA: 8s - loss: 0.4685 - acc: 0.855 - ETA: 8s - loss: 0.4706 - acc: 0.854 - ETA: 8s - loss: 0.4756 - acc: 0.840 - ETA: 8s - loss: 0.4778 - acc: 0.835 - ETA: 8s - loss: 0.4892 - acc: 0.828 - ETA: 8s - loss: 0.4732 - acc: 0.831 - ETA: 8s - loss: 0.4628 - acc: 0.837 - ETA: 8s - loss: 0.4641 - acc: 0.835 - ETA: 8s - loss: 0.4619 - acc: 0.834 - ETA: 8s - loss: 0.4636 - acc: 0.834 - ETA: 8s - loss: 0.4698 - acc: 0.831 - ETA: 8s - loss: 0.4605 - acc: 0.837 - ETA: 8s - loss: 0.4654 - acc: 0.837 - ETA: 8s - loss: 0.4686 - acc: 0.834 - ETA: 8s - loss: 0.4774 - acc: 0.832 - ETA: 8s - loss: 0.4824 - acc: 0.830 - ETA: 7s - loss: 0.4735 - acc: 0.834 - ETA: 7s - loss: 0.4800 - acc: 0.833 - ETA: 7s - loss: 0.4808 - acc: 0.831 - ETA: 7s - loss: 0.4794 - acc: 0.831 - ETA: 7s - loss: 0.4827 - acc: 0.831 - ETA: 7s - loss: 0.4836 - acc: 0.830 - ETA: 7s - loss: 0.4832 - acc: 0.829 - ETA: 7s - loss: 0.4843 - acc: 0.827 - ETA: 7s - loss: 0.4806 - acc: 0.829 - ETA: 7s - loss: 0.4759 - acc: 0.831 - ETA: 7s - loss: 0.4686 - acc: 0.834 - ETA: 7s - loss: 0.4689 - acc: 0.833 - ETA: 7s - loss: 0.4692 - acc: 0.834 - ETA: 7s - loss: 0.4680 - acc: 0.833 - ETA: 7s - loss: 0.4711 - acc: 0.833 - ETA: 6s - loss: 0.4705 - acc: 0.833 - ETA: 6s - loss: 0.4781 - acc: 0.829 - ETA: 6s - loss: 0.4792 - acc: 0.829 - ETA: 6s - loss: 0.4779 - acc: 0.830 - ETA: 6s - loss: 0.4809 - acc: 0.828 - ETA: 6s - loss: 0.4830 - acc: 0.828 - ETA: 6s - loss: 0.4861 - acc: 0.826 - ETA: 6s - loss: 0.4857 - acc: 0.825 - ETA: 6s - loss: 0.4854 - acc: 0.826 - ETA: 6s - loss: 0.4898 - acc: 0.823 - ETA: 6s - loss: 0.4870 - acc: 0.823 - ETA: 6s - loss: 0.4867 - acc: 0.824 - ETA: 6s - loss: 0.4869 - acc: 0.825 - ETA: 6s - loss: 0.4825 - acc: 0.828 - ETA: 6s - loss: 0.4836 - acc: 0.827 - ETA: 5s - loss: 0.4846 - acc: 0.826 - ETA: 5s - loss: 0.4822 - acc: 0.827 - ETA: 5s - loss: 0.4874 - acc: 0.827 - ETA: 5s - loss: 0.4847 - acc: 0.828 - ETA: 5s - loss: 0.4880 - acc: 0.827 - ETA: 5s - loss: 0.4912 - acc: 0.827 - ETA: 5s - loss: 0.4905 - acc: 0.827 - ETA: 5s - loss: 0.4860 - acc: 0.828 - ETA: 5s - loss: 0.4916 - acc: 0.828 - ETA: 5s - loss: 0.4898 - acc: 0.829 - ETA: 5s - loss: 0.4923 - acc: 0.828 - ETA: 5s - loss: 0.4908 - acc: 0.829 - ETA: 5s - loss: 0.4913 - acc: 0.829 - ETA: 5s - loss: 0.4942 - acc: 0.827 - ETA: 5s - loss: 0.4931 - acc: 0.827 - ETA: 5s - loss: 0.4936 - acc: 0.826 - ETA: 4s - loss: 0.4927 - acc: 0.827 - ETA: 4s - loss: 0.4901 - acc: 0.828 - ETA: 4s - loss: 0.4928 - acc: 0.827 - ETA: 4s - loss: 0.4945 - acc: 0.826 - ETA: 4s - loss: 0.4969 - acc: 0.826 - ETA: 4s - loss: 0.4972 - acc: 0.826 - ETA: 4s - loss: 0.4955 - acc: 0.826 - ETA: 4s - loss: 0.4942 - acc: 0.826 - ETA: 4s - loss: 0.4933 - acc: 0.827 - ETA: 4s - loss: 0.4953 - acc: 0.827 - ETA: 4s - loss: 0.4925 - acc: 0.828 - ETA: 4s - loss: 0.4907 - acc: 0.828 - ETA: 4s - loss: 0.4929 - acc: 0.828 - ETA: 4s - loss: 0.4915 - acc: 0.829 - ETA: 4s - loss: 0.4906 - acc: 0.829 - ETA: 3s - loss: 0.4924 - acc: 0.829 - ETA: 3s - loss: 0.4932 - acc: 0.829 - ETA: 3s - loss: 0.4946 - acc: 0.829 - ETA: 3s - loss: 0.4965 - acc: 0.829 - ETA: 3s - loss: 0.4955 - acc: 0.829 - ETA: 3s - loss: 0.4943 - acc: 0.829 - ETA: 3s - loss: 0.4934 - acc: 0.830 - ETA: 3s - loss: 0.4930 - acc: 0.830 - ETA: 3s - loss: 0.4931 - acc: 0.830 - ETA: 3s - loss: 0.4922 - acc: 0.831 - ETA: 3s - loss: 0.4916 - acc: 0.831 - ETA: 3s - loss: 0.4919 - acc: 0.831 - ETA: 3s - loss: 0.4907 - acc: 0.831 - ETA: 3s - loss: 0.4904 - acc: 0.831 - ETA: 3s - loss: 0.4915 - acc: 0.830 - ETA: 3s - loss: 0.4885 - acc: 0.831 - ETA: 2s - loss: 0.4878 - acc: 0.832 - ETA: 2s - loss: 0.4870 - acc: 0.832 - ETA: 2s - loss: 0.4837 - acc: 0.833 - ETA: 2s - loss: 0.4880 - acc: 0.832 - ETA: 2s - loss: 0.4887 - acc: 0.832 - ETA: 2s - loss: 0.4908 - acc: 0.832 - ETA: 2s - loss: 0.4889 - acc: 0.832 - ETA: 2s - loss: 0.4884 - acc: 0.833 - ETA: 2s - loss: 0.4889 - acc: 0.833 - ETA: 2s - loss: 0.4913 - acc: 0.832 - ETA: 2s - loss: 0.4909 - acc: 0.832 - ETA: 2s - loss: 0.4902 - acc: 0.832 - ETA: 2s - loss: 0.4909 - acc: 0.831 - ETA: 2s - loss: 0.4933 - acc: 0.831 - ETA: 2s - loss: 0.4923 - acc: 0.831 - ETA: 2s - loss: 0.4920 - acc: 0.830 - ETA: 1s - loss: 0.4908 - acc: 0.830 - ETA: 1s - loss: 0.4915 - acc: 0.830 - ETA: 1s - loss: 0.4917 - acc: 0.829 - ETA: 1s - loss: 0.4912 - acc: 0.829 - ETA: 1s - loss: 0.4917 - acc: 0.830 - ETA: 1s - loss: 0.4924 - acc: 0.829 - ETA: 1s - loss: 0.4935 - acc: 0.829 - ETA: 1s - loss: 0.4930 - acc: 0.829 - ETA: 1s - loss: 0.4933 - acc: 0.829 - ETA: 1s - loss: 0.4965 - acc: 0.828 - ETA: 1s - loss: 0.4944 - acc: 0.829 - ETA: 1s - loss: 0.4944 - acc: 0.829 - ETA: 1s - loss: 0.4938 - acc: 0.828 - ETA: 1s - loss: 0.4931 - acc: 0.829 - ETA: 1s - loss: 0.4931 - acc: 0.829 - ETA: 0s - loss: 0.4931 - acc: 0.829 - ETA: 0s - loss: 0.4921 - acc: 0.830 - ETA: 0s - loss: 0.4905 - acc: 0.830 - ETA: 0s - loss: 0.4930 - acc: 0.830 - ETA: 0s - loss: 0.4948 - acc: 0.830 - ETA: 0s - loss: 0.4943 - acc: 0.829 - ETA: 0s - loss: 0.4946 - acc: 0.829 - ETA: 0s - loss: 0.4935 - acc: 0.830 - ETA: 0s - loss: 0.4934 - acc: 0.830 - ETA: 0s - loss: 0.4927 - acc: 0.830 - ETA: 0s - loss: 0.4923 - acc: 0.830 - ETA: 0s - loss: 0.4916 - acc: 0.830 - ETA: 0s - loss: 0.4964 - acc: 0.829 - ETA: 0s - loss: 0.4963 - acc: 0.829 - ETA: 0s - loss: 0.4964 - acc: 0.829 - ETA: 0s - loss: 0.4958 - acc: 0.829 - 9s 2ms/step - loss: 0.4960 - acc: 0.8301\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4726/4726 [==============================] - ETA: 9s - loss: 0.5060 - acc: 0.781 - ETA: 9s - loss: 0.4682 - acc: 0.812 - ETA: 9s - loss: 0.5189 - acc: 0.833 - ETA: 9s - loss: 0.4875 - acc: 0.859 - ETA: 8s - loss: 0.4741 - acc: 0.862 - ETA: 8s - loss: 0.4670 - acc: 0.859 - ETA: 8s - loss: 0.4569 - acc: 0.857 - ETA: 8s - loss: 0.4520 - acc: 0.859 - ETA: 8s - loss: 0.4191 - acc: 0.871 - ETA: 8s - loss: 0.4152 - acc: 0.871 - ETA: 8s - loss: 0.4184 - acc: 0.863 - ETA: 8s - loss: 0.4324 - acc: 0.854 - ETA: 8s - loss: 0.4217 - acc: 0.853 - ETA: 8s - loss: 0.4339 - acc: 0.850 - ETA: 8s - loss: 0.4466 - acc: 0.843 - ETA: 8s - loss: 0.4410 - acc: 0.845 - ETA: 8s - loss: 0.4488 - acc: 0.836 - ETA: 8s - loss: 0.4500 - acc: 0.836 - ETA: 8s - loss: 0.4540 - acc: 0.833 - ETA: 8s - loss: 0.4482 - acc: 0.837 - ETA: 8s - loss: 0.4342 - acc: 0.843 - ETA: 7s - loss: 0.4298 - acc: 0.845 - ETA: 7s - loss: 0.4270 - acc: 0.847 - ETA: 7s - loss: 0.4174 - acc: 0.852 - ETA: 7s - loss: 0.4129 - acc: 0.855 - ETA: 7s - loss: 0.4184 - acc: 0.852 - ETA: 7s - loss: 0.4148 - acc: 0.851 - ETA: 7s - loss: 0.4101 - acc: 0.853 - ETA: 7s - loss: 0.4163 - acc: 0.850 - ETA: 7s - loss: 0.4215 - acc: 0.847 - ETA: 7s - loss: 0.4240 - acc: 0.846 - ETA: 7s - loss: 0.4268 - acc: 0.846 - ETA: 7s - loss: 0.4360 - acc: 0.844 - ETA: 7s - loss: 0.4332 - acc: 0.845 - ETA: 7s - loss: 0.4335 - acc: 0.846 - ETA: 7s - loss: 0.4314 - acc: 0.847 - ETA: 7s - loss: 0.4452 - acc: 0.842 - ETA: 6s - loss: 0.4460 - acc: 0.841 - ETA: 6s - loss: 0.4506 - acc: 0.841 - ETA: 6s - loss: 0.4459 - acc: 0.843 - ETA: 6s - loss: 0.4437 - acc: 0.845 - ETA: 6s - loss: 0.4442 - acc: 0.845 - ETA: 6s - loss: 0.4407 - acc: 0.847 - ETA: 6s - loss: 0.4484 - acc: 0.845 - ETA: 6s - loss: 0.4498 - acc: 0.845 - ETA: 6s - loss: 0.4500 - acc: 0.845 - ETA: 6s - loss: 0.4487 - acc: 0.846 - ETA: 6s - loss: 0.4450 - acc: 0.847 - ETA: 6s - loss: 0.4465 - acc: 0.846 - ETA: 6s - loss: 0.4471 - acc: 0.846 - ETA: 6s - loss: 0.4511 - acc: 0.845 - ETA: 6s - loss: 0.4520 - acc: 0.844 - ETA: 6s - loss: 0.4522 - acc: 0.843 - ETA: 5s - loss: 0.4521 - acc: 0.843 - ETA: 5s - loss: 0.4510 - acc: 0.844 - ETA: 5s - loss: 0.4499 - acc: 0.844 - ETA: 5s - loss: 0.4519 - acc: 0.844 - ETA: 5s - loss: 0.4542 - acc: 0.842 - ETA: 5s - loss: 0.4530 - acc: 0.842 - ETA: 5s - loss: 0.4518 - acc: 0.842 - ETA: 5s - loss: 0.4519 - acc: 0.842 - ETA: 5s - loss: 0.4528 - acc: 0.843 - ETA: 5s - loss: 0.4546 - acc: 0.843 - ETA: 5s - loss: 0.4533 - acc: 0.843 - ETA: 5s - loss: 0.4557 - acc: 0.841 - ETA: 5s - loss: 0.4625 - acc: 0.839 - ETA: 5s - loss: 0.4609 - acc: 0.839 - ETA: 5s - loss: 0.4585 - acc: 0.839 - ETA: 5s - loss: 0.4574 - acc: 0.839 - ETA: 4s - loss: 0.4594 - acc: 0.837 - ETA: 4s - loss: 0.4593 - acc: 0.838 - ETA: 4s - loss: 0.4588 - acc: 0.839 - ETA: 4s - loss: 0.4558 - acc: 0.839 - ETA: 4s - loss: 0.4574 - acc: 0.839 - ETA: 4s - loss: 0.4579 - acc: 0.838 - ETA: 4s - loss: 0.4548 - acc: 0.840 - ETA: 4s - loss: 0.4593 - acc: 0.838 - ETA: 4s - loss: 0.4569 - acc: 0.839 - ETA: 4s - loss: 0.4569 - acc: 0.839 - ETA: 4s - loss: 0.4598 - acc: 0.838 - ETA: 4s - loss: 0.4631 - acc: 0.838 - ETA: 4s - loss: 0.4610 - acc: 0.839 - ETA: 4s - loss: 0.4583 - acc: 0.840 - ETA: 4s - loss: 0.4591 - acc: 0.840 - ETA: 3s - loss: 0.4593 - acc: 0.839 - ETA: 3s - loss: 0.4590 - acc: 0.839 - ETA: 3s - loss: 0.4562 - acc: 0.841 - ETA: 3s - loss: 0.4591 - acc: 0.839 - ETA: 3s - loss: 0.4576 - acc: 0.839 - ETA: 3s - loss: 0.4593 - acc: 0.838 - ETA: 3s - loss: 0.4582 - acc: 0.838 - ETA: 3s - loss: 0.4586 - acc: 0.838 - ETA: 3s - loss: 0.4594 - acc: 0.838 - ETA: 3s - loss: 0.4587 - acc: 0.838 - ETA: 3s - loss: 0.4589 - acc: 0.838 - ETA: 3s - loss: 0.4615 - acc: 0.838 - ETA: 3s - loss: 0.4597 - acc: 0.838 - ETA: 3s - loss: 0.4596 - acc: 0.838 - ETA: 3s - loss: 0.4580 - acc: 0.838 - ETA: 3s - loss: 0.4593 - acc: 0.838 - ETA: 2s - loss: 0.4599 - acc: 0.838 - ETA: 2s - loss: 0.4642 - acc: 0.837 - ETA: 2s - loss: 0.4636 - acc: 0.836 - ETA: 2s - loss: 0.4621 - acc: 0.837 - ETA: 2s - loss: 0.4611 - acc: 0.838 - ETA: 2s - loss: 0.4590 - acc: 0.839 - ETA: 2s - loss: 0.4607 - acc: 0.838 - ETA: 2s - loss: 0.4627 - acc: 0.837 - ETA: 2s - loss: 0.4633 - acc: 0.837 - ETA: 2s - loss: 0.4632 - acc: 0.837 - ETA: 2s - loss: 0.4663 - acc: 0.836 - ETA: 2s - loss: 0.4660 - acc: 0.836 - ETA: 2s - loss: 0.4647 - acc: 0.837 - ETA: 2s - loss: 0.4661 - acc: 0.837 - ETA: 2s - loss: 0.4655 - acc: 0.837 - ETA: 2s - loss: 0.4662 - acc: 0.837 - ETA: 1s - loss: 0.4675 - acc: 0.836 - ETA: 1s - loss: 0.4653 - acc: 0.837 - ETA: 1s - loss: 0.4631 - acc: 0.838 - ETA: 1s - loss: 0.4650 - acc: 0.838 - ETA: 1s - loss: 0.4664 - acc: 0.837 - ETA: 1s - loss: 0.4653 - acc: 0.837 - ETA: 1s - loss: 0.4656 - acc: 0.837 - ETA: 1s - loss: 0.4656 - acc: 0.837 - ETA: 1s - loss: 0.4666 - acc: 0.837 - ETA: 1s - loss: 0.4661 - acc: 0.837 - ETA: 1s - loss: 0.4664 - acc: 0.837 - ETA: 1s - loss: 0.4658 - acc: 0.837 - ETA: 1s - loss: 0.4679 - acc: 0.837 - ETA: 1s - loss: 0.4681 - acc: 0.837 - ETA: 1s - loss: 0.4674 - acc: 0.836 - ETA: 1s - loss: 0.4687 - acc: 0.836 - ETA: 0s - loss: 0.4673 - acc: 0.836 - ETA: 0s - loss: 0.4676 - acc: 0.836 - ETA: 0s - loss: 0.4664 - acc: 0.836 - ETA: 0s - loss: 0.4652 - acc: 0.837 - ETA: 0s - loss: 0.4674 - acc: 0.836 - ETA: 0s - loss: 0.4690 - acc: 0.835 - ETA: 0s - loss: 0.4693 - acc: 0.835 - ETA: 0s - loss: 0.4713 - acc: 0.834 - ETA: 0s - loss: 0.4710 - acc: 0.834 - ETA: 0s - loss: 0.4705 - acc: 0.834 - ETA: 0s - loss: 0.4702 - acc: 0.834 - ETA: 0s - loss: 0.4689 - acc: 0.835 - ETA: 0s - loss: 0.4685 - acc: 0.835 - ETA: 0s - loss: 0.4679 - acc: 0.835 - ETA: 0s - loss: 0.4709 - acc: 0.835 - 9s 2ms/step - loss: 0.4707 - acc: 0.8350\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4726/4726 [==============================] - ETA: 8s - loss: 0.1562 - acc: 0.937 - ETA: 8s - loss: 0.2021 - acc: 0.937 - ETA: 9s - loss: 0.2888 - acc: 0.895 - ETA: 9s - loss: 0.2852 - acc: 0.906 - ETA: 8s - loss: 0.3238 - acc: 0.893 - ETA: 8s - loss: 0.3353 - acc: 0.901 - ETA: 8s - loss: 0.3299 - acc: 0.901 - ETA: 8s - loss: 0.3292 - acc: 0.902 - ETA: 8s - loss: 0.3334 - acc: 0.895 - ETA: 8s - loss: 0.3382 - acc: 0.893 - ETA: 8s - loss: 0.3744 - acc: 0.889 - ETA: 8s - loss: 0.3781 - acc: 0.882 - ETA: 8s - loss: 0.3853 - acc: 0.875 - ETA: 8s - loss: 0.3935 - acc: 0.870 - ETA: 8s - loss: 0.3909 - acc: 0.868 - ETA: 8s - loss: 0.4076 - acc: 0.861 - ETA: 8s - loss: 0.4064 - acc: 0.864 - ETA: 8s - loss: 0.4133 - acc: 0.855 - ETA: 8s - loss: 0.4099 - acc: 0.856 - ETA: 8s - loss: 0.4087 - acc: 0.857 - ETA: 8s - loss: 0.4050 - acc: 0.861 - ETA: 8s - loss: 0.4088 - acc: 0.862 - ETA: 7s - loss: 0.4090 - acc: 0.861 - ETA: 7s - loss: 0.4076 - acc: 0.864 - ETA: 7s - loss: 0.4113 - acc: 0.863 - ETA: 7s - loss: 0.4085 - acc: 0.866 - ETA: 7s - loss: 0.4061 - acc: 0.865 - ETA: 7s - loss: 0.4106 - acc: 0.861 - ETA: 7s - loss: 0.4083 - acc: 0.861 - ETA: 7s - loss: 0.4051 - acc: 0.860 - ETA: 7s - loss: 0.4043 - acc: 0.858 - ETA: 7s - loss: 0.4067 - acc: 0.856 - ETA: 7s - loss: 0.4084 - acc: 0.856 - ETA: 7s - loss: 0.4160 - acc: 0.852 - ETA: 7s - loss: 0.4113 - acc: 0.854 - ETA: 7s - loss: 0.4116 - acc: 0.854 - ETA: 7s - loss: 0.4163 - acc: 0.853 - ETA: 6s - loss: 0.4163 - acc: 0.852 - ETA: 6s - loss: 0.4189 - acc: 0.851 - ETA: 6s - loss: 0.4228 - acc: 0.852 - ETA: 6s - loss: 0.4205 - acc: 0.853 - ETA: 6s - loss: 0.4217 - acc: 0.852 - ETA: 6s - loss: 0.4234 - acc: 0.852 - ETA: 6s - loss: 0.4189 - acc: 0.854 - ETA: 6s - loss: 0.4193 - acc: 0.853 - ETA: 6s - loss: 0.4233 - acc: 0.851 - ETA: 6s - loss: 0.4241 - acc: 0.851 - ETA: 6s - loss: 0.4236 - acc: 0.852 - ETA: 6s - loss: 0.4214 - acc: 0.854 - ETA: 6s - loss: 0.4200 - acc: 0.853 - ETA: 6s - loss: 0.4263 - acc: 0.853 - ETA: 6s - loss: 0.4232 - acc: 0.854 - ETA: 6s - loss: 0.4238 - acc: 0.853 - ETA: 6s - loss: 0.4252 - acc: 0.853 - ETA: 5s - loss: 0.4241 - acc: 0.854 - ETA: 5s - loss: 0.4212 - acc: 0.856 - ETA: 5s - loss: 0.4238 - acc: 0.855 - ETA: 5s - loss: 0.4224 - acc: 0.856 - ETA: 5s - loss: 0.4227 - acc: 0.855 - ETA: 5s - loss: 0.4227 - acc: 0.856 - ETA: 5s - loss: 0.4199 - acc: 0.857 - ETA: 5s - loss: 0.4195 - acc: 0.856 - ETA: 5s - loss: 0.4209 - acc: 0.856 - ETA: 5s - loss: 0.4225 - acc: 0.856 - ETA: 5s - loss: 0.4240 - acc: 0.855 - ETA: 5s - loss: 0.4249 - acc: 0.856 - ETA: 5s - loss: 0.4228 - acc: 0.857 - ETA: 5s - loss: 0.4250 - acc: 0.856 - ETA: 5s - loss: 0.4234 - acc: 0.857 - ETA: 4s - loss: 0.4265 - acc: 0.856 - ETA: 4s - loss: 0.4248 - acc: 0.857 - ETA: 4s - loss: 0.4258 - acc: 0.856 - ETA: 4s - loss: 0.4246 - acc: 0.857 - ETA: 4s - loss: 0.4219 - acc: 0.858 - ETA: 4s - loss: 0.4209 - acc: 0.858 - ETA: 4s - loss: 0.4227 - acc: 0.857 - ETA: 4s - loss: 0.4255 - acc: 0.856 - ETA: 4s - loss: 0.4264 - acc: 0.855 - ETA: 4s - loss: 0.4266 - acc: 0.854 - ETA: 4s - loss: 0.4259 - acc: 0.855 - ETA: 4s - loss: 0.4245 - acc: 0.855 - ETA: 4s - loss: 0.4254 - acc: 0.855 - ETA: 4s - loss: 0.4227 - acc: 0.856 - ETA: 4s - loss: 0.4227 - acc: 0.856 - ETA: 3s - loss: 0.4210 - acc: 0.857 - ETA: 3s - loss: 0.4213 - acc: 0.857 - ETA: 3s - loss: 0.4213 - acc: 0.857 - ETA: 3s - loss: 0.4233 - acc: 0.856 - ETA: 3s - loss: 0.4263 - acc: 0.855 - ETA: 3s - loss: 0.4273 - acc: 0.854 - ETA: 3s - loss: 0.4283 - acc: 0.853 - ETA: 3s - loss: 0.4304 - acc: 0.852 - ETA: 3s - loss: 0.4284 - acc: 0.853 - ETA: 3s - loss: 0.4289 - acc: 0.853 - ETA: 3s - loss: 0.4284 - acc: 0.853 - ETA: 3s - loss: 0.4304 - acc: 0.852 - ETA: 3s - loss: 0.4304 - acc: 0.852 - ETA: 3s - loss: 0.4300 - acc: 0.852 - ETA: 3s - loss: 0.4305 - acc: 0.851 - ETA: 3s - loss: 0.4327 - acc: 0.850 - ETA: 2s - loss: 0.4362 - acc: 0.849 - ETA: 2s - loss: 0.4358 - acc: 0.850 - ETA: 2s - loss: 0.4345 - acc: 0.851 - ETA: 2s - loss: 0.4327 - acc: 0.852 - ETA: 2s - loss: 0.4328 - acc: 0.851 - ETA: 2s - loss: 0.4352 - acc: 0.850 - ETA: 2s - loss: 0.4369 - acc: 0.850 - ETA: 2s - loss: 0.4379 - acc: 0.850 - ETA: 2s - loss: 0.4392 - acc: 0.849 - ETA: 2s - loss: 0.4394 - acc: 0.849 - ETA: 2s - loss: 0.4389 - acc: 0.849 - ETA: 2s - loss: 0.4383 - acc: 0.849 - ETA: 2s - loss: 0.4379 - acc: 0.849 - ETA: 2s - loss: 0.4381 - acc: 0.849 - ETA: 2s - loss: 0.4384 - acc: 0.848 - ETA: 2s - loss: 0.4401 - acc: 0.848 - ETA: 1s - loss: 0.4396 - acc: 0.847 - ETA: 1s - loss: 0.4398 - acc: 0.847 - ETA: 1s - loss: 0.4411 - acc: 0.847 - ETA: 1s - loss: 0.4422 - acc: 0.846 - ETA: 1s - loss: 0.4408 - acc: 0.847 - ETA: 1s - loss: 0.4409 - acc: 0.846 - ETA: 1s - loss: 0.4413 - acc: 0.846 - ETA: 1s - loss: 0.4414 - acc: 0.846 - ETA: 1s - loss: 0.4423 - acc: 0.846 - ETA: 1s - loss: 0.4413 - acc: 0.846 - ETA: 1s - loss: 0.4396 - acc: 0.846 - ETA: 1s - loss: 0.4403 - acc: 0.846 - ETA: 1s - loss: 0.4399 - acc: 0.846 - ETA: 1s - loss: 0.4406 - acc: 0.845 - ETA: 1s - loss: 0.4409 - acc: 0.845 - ETA: 0s - loss: 0.4414 - acc: 0.845 - ETA: 0s - loss: 0.4404 - acc: 0.846 - ETA: 0s - loss: 0.4410 - acc: 0.846 - ETA: 0s - loss: 0.4428 - acc: 0.845 - ETA: 0s - loss: 0.4456 - acc: 0.844 - ETA: 0s - loss: 0.4453 - acc: 0.845 - ETA: 0s - loss: 0.4460 - acc: 0.845 - ETA: 0s - loss: 0.4455 - acc: 0.846 - ETA: 0s - loss: 0.4457 - acc: 0.846 - ETA: 0s - loss: 0.4461 - acc: 0.845 - ETA: 0s - loss: 0.4454 - acc: 0.846 - ETA: 0s - loss: 0.4441 - acc: 0.846 - ETA: 0s - loss: 0.4429 - acc: 0.847 - ETA: 0s - loss: 0.4438 - acc: 0.846 - ETA: 0s - loss: 0.4443 - acc: 0.846 - ETA: 0s - loss: 0.4454 - acc: 0.846 - 9s 2ms/step - loss: 0.4448 - acc: 0.8464\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4726/4726 [==============================] - ETA: 8s - loss: 0.3295 - acc: 0.843 - ETA: 9s - loss: 0.2895 - acc: 0.875 - ETA: 9s - loss: 0.3277 - acc: 0.885 - ETA: 9s - loss: 0.3538 - acc: 0.875 - ETA: 9s - loss: 0.3945 - acc: 0.875 - ETA: 8s - loss: 0.3725 - acc: 0.885 - ETA: 8s - loss: 0.3736 - acc: 0.883 - ETA: 8s - loss: 0.3668 - acc: 0.890 - ETA: 8s - loss: 0.3767 - acc: 0.888 - ETA: 8s - loss: 0.3983 - acc: 0.875 - ETA: 8s - loss: 0.3892 - acc: 0.877 - ETA: 8s - loss: 0.3926 - acc: 0.869 - ETA: 8s - loss: 0.3997 - acc: 0.863 - ETA: 8s - loss: 0.4172 - acc: 0.857 - ETA: 8s - loss: 0.4045 - acc: 0.862 - ETA: 8s - loss: 0.3967 - acc: 0.863 - ETA: 8s - loss: 0.3884 - acc: 0.862 - ETA: 8s - loss: 0.3949 - acc: 0.857 - ETA: 8s - loss: 0.3846 - acc: 0.861 - ETA: 8s - loss: 0.3823 - acc: 0.862 - ETA: 8s - loss: 0.3713 - acc: 0.867 - ETA: 7s - loss: 0.3704 - acc: 0.866 - ETA: 7s - loss: 0.3691 - acc: 0.866 - ETA: 7s - loss: 0.3727 - acc: 0.867 - ETA: 7s - loss: 0.3704 - acc: 0.867 - ETA: 7s - loss: 0.3664 - acc: 0.867 - ETA: 7s - loss: 0.3616 - acc: 0.869 - ETA: 7s - loss: 0.3599 - acc: 0.868 - ETA: 7s - loss: 0.3616 - acc: 0.866 - ETA: 7s - loss: 0.3612 - acc: 0.866 - ETA: 7s - loss: 0.3626 - acc: 0.864 - ETA: 7s - loss: 0.3598 - acc: 0.865 - ETA: 7s - loss: 0.3625 - acc: 0.863 - ETA: 7s - loss: 0.3671 - acc: 0.862 - ETA: 7s - loss: 0.3702 - acc: 0.860 - ETA: 7s - loss: 0.3637 - acc: 0.863 - ETA: 7s - loss: 0.3679 - acc: 0.862 - ETA: 6s - loss: 0.3694 - acc: 0.862 - ETA: 6s - loss: 0.3691 - acc: 0.863 - ETA: 6s - loss: 0.3813 - acc: 0.858 - ETA: 6s - loss: 0.3781 - acc: 0.859 - ETA: 6s - loss: 0.3785 - acc: 0.860 - ETA: 6s - loss: 0.3793 - acc: 0.859 - ETA: 6s - loss: 0.3786 - acc: 0.860 - ETA: 6s - loss: 0.3766 - acc: 0.861 - ETA: 6s - loss: 0.3812 - acc: 0.860 - ETA: 6s - loss: 0.3839 - acc: 0.860 - ETA: 6s - loss: 0.3876 - acc: 0.859 - ETA: 6s - loss: 0.3848 - acc: 0.861 - ETA: 6s - loss: 0.3879 - acc: 0.860 - ETA: 6s - loss: 0.3949 - acc: 0.859 - ETA: 6s - loss: 0.4026 - acc: 0.857 - ETA: 5s - loss: 0.4057 - acc: 0.856 - ETA: 5s - loss: 0.4036 - acc: 0.856 - ETA: 5s - loss: 0.4108 - acc: 0.853 - ETA: 5s - loss: 0.4099 - acc: 0.853 - ETA: 5s - loss: 0.4128 - acc: 0.852 - ETA: 5s - loss: 0.4113 - acc: 0.853 - ETA: 5s - loss: 0.4093 - acc: 0.853 - ETA: 5s - loss: 0.4087 - acc: 0.854 - ETA: 5s - loss: 0.4091 - acc: 0.854 - ETA: 5s - loss: 0.4126 - acc: 0.853 - ETA: 5s - loss: 0.4147 - acc: 0.852 - ETA: 5s - loss: 0.4123 - acc: 0.853 - ETA: 5s - loss: 0.4123 - acc: 0.853 - ETA: 5s - loss: 0.4111 - acc: 0.853 - ETA: 5s - loss: 0.4097 - acc: 0.854 - ETA: 5s - loss: 0.4100 - acc: 0.854 - ETA: 5s - loss: 0.4074 - acc: 0.855 - ETA: 4s - loss: 0.4059 - acc: 0.857 - ETA: 4s - loss: 0.4038 - acc: 0.858 - ETA: 4s - loss: 0.4097 - acc: 0.857 - ETA: 4s - loss: 0.4124 - acc: 0.856 - ETA: 4s - loss: 0.4157 - acc: 0.854 - ETA: 4s - loss: 0.4146 - acc: 0.855 - ETA: 4s - loss: 0.4173 - acc: 0.854 - ETA: 4s - loss: 0.4176 - acc: 0.855 - ETA: 4s - loss: 0.4168 - acc: 0.856 - ETA: 4s - loss: 0.4173 - acc: 0.856 - ETA: 4s - loss: 0.4169 - acc: 0.857 - ETA: 4s - loss: 0.4148 - acc: 0.858 - ETA: 4s - loss: 0.4142 - acc: 0.858 - ETA: 4s - loss: 0.4153 - acc: 0.858 - ETA: 4s - loss: 0.4158 - acc: 0.857 - ETA: 3s - loss: 0.4128 - acc: 0.859 - ETA: 3s - loss: 0.4114 - acc: 0.859 - ETA: 3s - loss: 0.4128 - acc: 0.858 - ETA: 3s - loss: 0.4128 - acc: 0.858 - ETA: 3s - loss: 0.4140 - acc: 0.857 - ETA: 3s - loss: 0.4145 - acc: 0.857 - ETA: 3s - loss: 0.4122 - acc: 0.857 - ETA: 3s - loss: 0.4105 - acc: 0.858 - ETA: 3s - loss: 0.4133 - acc: 0.857 - ETA: 3s - loss: 0.4136 - acc: 0.857 - ETA: 3s - loss: 0.4158 - acc: 0.856 - ETA: 3s - loss: 0.4167 - acc: 0.855 - ETA: 3s - loss: 0.4182 - acc: 0.854 - ETA: 3s - loss: 0.4179 - acc: 0.854 - ETA: 3s - loss: 0.4205 - acc: 0.853 - ETA: 3s - loss: 0.4206 - acc: 0.852 - ETA: 2s - loss: 0.4181 - acc: 0.853 - ETA: 2s - loss: 0.4180 - acc: 0.853 - ETA: 2s - loss: 0.4191 - acc: 0.852 - ETA: 2s - loss: 0.4203 - acc: 0.851 - ETA: 2s - loss: 0.4212 - acc: 0.852 - ETA: 2s - loss: 0.4228 - acc: 0.851 - ETA: 2s - loss: 0.4235 - acc: 0.850 - ETA: 2s - loss: 0.4266 - acc: 0.849 - ETA: 2s - loss: 0.4270 - acc: 0.849 - ETA: 2s - loss: 0.4303 - acc: 0.848 - ETA: 2s - loss: 0.4313 - acc: 0.848 - ETA: 2s - loss: 0.4318 - acc: 0.847 - ETA: 2s - loss: 0.4318 - acc: 0.847 - ETA: 2s - loss: 0.4317 - acc: 0.848 - ETA: 2s - loss: 0.4322 - acc: 0.848 - ETA: 2s - loss: 0.4317 - acc: 0.848 - ETA: 1s - loss: 0.4316 - acc: 0.848 - ETA: 1s - loss: 0.4322 - acc: 0.848 - ETA: 1s - loss: 0.4319 - acc: 0.848 - ETA: 1s - loss: 0.4346 - acc: 0.847 - ETA: 1s - loss: 0.4334 - acc: 0.847 - ETA: 1s - loss: 0.4360 - acc: 0.846 - ETA: 1s - loss: 0.4362 - acc: 0.846 - ETA: 1s - loss: 0.4364 - acc: 0.846 - ETA: 1s - loss: 0.4362 - acc: 0.846 - ETA: 1s - loss: 0.4355 - acc: 0.846 - ETA: 1s - loss: 0.4357 - acc: 0.846 - ETA: 1s - loss: 0.4348 - acc: 0.846 - ETA: 1s - loss: 0.4342 - acc: 0.847 - ETA: 1s - loss: 0.4360 - acc: 0.847 - ETA: 1s - loss: 0.4356 - acc: 0.847 - ETA: 0s - loss: 0.4348 - acc: 0.847 - ETA: 0s - loss: 0.4350 - acc: 0.847 - ETA: 0s - loss: 0.4334 - acc: 0.848 - ETA: 0s - loss: 0.4330 - acc: 0.848 - ETA: 0s - loss: 0.4346 - acc: 0.848 - ETA: 0s - loss: 0.4351 - acc: 0.847 - ETA: 0s - loss: 0.4346 - acc: 0.847 - ETA: 0s - loss: 0.4339 - acc: 0.848 - ETA: 0s - loss: 0.4338 - acc: 0.848 - ETA: 0s - loss: 0.4339 - acc: 0.848 - ETA: 0s - loss: 0.4325 - acc: 0.849 - ETA: 0s - loss: 0.4328 - acc: 0.849 - ETA: 0s - loss: 0.4328 - acc: 0.849 - ETA: 0s - loss: 0.4308 - acc: 0.849 - ETA: 0s - loss: 0.4314 - acc: 0.849 - ETA: 0s - loss: 0.4297 - acc: 0.850 - 9s 2ms/step - loss: 0.4306 - acc: 0.8504\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4726/4726 [==============================] - ETA: 8s - loss: 0.4109 - acc: 0.812 - ETA: 8s - loss: 0.3646 - acc: 0.859 - ETA: 9s - loss: 0.4254 - acc: 0.822 - ETA: 8s - loss: 0.5016 - acc: 0.804 - ETA: 8s - loss: 0.5267 - acc: 0.806 - ETA: 8s - loss: 0.4743 - acc: 0.833 - ETA: 8s - loss: 0.4749 - acc: 0.830 - ETA: 8s - loss: 0.4731 - acc: 0.832 - ETA: 8s - loss: 0.4614 - acc: 0.836 - ETA: 8s - loss: 0.4398 - acc: 0.850 - ETA: 8s - loss: 0.4445 - acc: 0.838 - ETA: 8s - loss: 0.4369 - acc: 0.843 - ETA: 8s - loss: 0.4284 - acc: 0.846 - ETA: 8s - loss: 0.4209 - acc: 0.854 - ETA: 8s - loss: 0.4156 - acc: 0.854 - ETA: 8s - loss: 0.4039 - acc: 0.857 - ETA: 8s - loss: 0.4023 - acc: 0.856 - ETA: 8s - loss: 0.3977 - acc: 0.854 - ETA: 8s - loss: 0.4138 - acc: 0.853 - ETA: 8s - loss: 0.4083 - acc: 0.854 - ETA: 8s - loss: 0.4021 - acc: 0.858 - ETA: 7s - loss: 0.4057 - acc: 0.858 - ETA: 7s - loss: 0.3936 - acc: 0.864 - ETA: 7s - loss: 0.3996 - acc: 0.862 - ETA: 7s - loss: 0.3987 - acc: 0.862 - ETA: 7s - loss: 0.3949 - acc: 0.865 - ETA: 7s - loss: 0.3866 - acc: 0.868 - ETA: 7s - loss: 0.3874 - acc: 0.866 - ETA: 7s - loss: 0.3857 - acc: 0.868 - ETA: 7s - loss: 0.3903 - acc: 0.865 - ETA: 7s - loss: 0.3918 - acc: 0.865 - ETA: 7s - loss: 0.3860 - acc: 0.868 - ETA: 7s - loss: 0.3855 - acc: 0.867 - ETA: 7s - loss: 0.3841 - acc: 0.867 - ETA: 7s - loss: 0.3852 - acc: 0.867 - ETA: 7s - loss: 0.3883 - acc: 0.865 - ETA: 7s - loss: 0.3879 - acc: 0.866 - ETA: 7s - loss: 0.3828 - acc: 0.868 - ETA: 6s - loss: 0.3793 - acc: 0.869 - ETA: 6s - loss: 0.3772 - acc: 0.870 - ETA: 6s - loss: 0.3802 - acc: 0.871 - ETA: 6s - loss: 0.3809 - acc: 0.869 - ETA: 6s - loss: 0.3779 - acc: 0.870 - ETA: 6s - loss: 0.3813 - acc: 0.870 - ETA: 6s - loss: 0.3758 - acc: 0.872 - ETA: 6s - loss: 0.3782 - acc: 0.873 - ETA: 6s - loss: 0.3786 - acc: 0.872 - ETA: 6s - loss: 0.3758 - acc: 0.872 - ETA: 6s - loss: 0.3805 - acc: 0.869 - ETA: 6s - loss: 0.3827 - acc: 0.870 - ETA: 6s - loss: 0.3837 - acc: 0.871 - ETA: 6s - loss: 0.3845 - acc: 0.870 - ETA: 6s - loss: 0.3853 - acc: 0.869 - ETA: 5s - loss: 0.3836 - acc: 0.869 - ETA: 5s - loss: 0.3825 - acc: 0.869 - ETA: 5s - loss: 0.3803 - acc: 0.871 - ETA: 5s - loss: 0.3822 - acc: 0.870 - ETA: 5s - loss: 0.3800 - acc: 0.870 - ETA: 5s - loss: 0.3824 - acc: 0.869 - ETA: 5s - loss: 0.3851 - acc: 0.868 - ETA: 5s - loss: 0.3815 - acc: 0.869 - ETA: 5s - loss: 0.3798 - acc: 0.870 - ETA: 5s - loss: 0.3809 - acc: 0.870 - ETA: 5s - loss: 0.3828 - acc: 0.869 - ETA: 5s - loss: 0.3859 - acc: 0.868 - ETA: 5s - loss: 0.3894 - acc: 0.867 - ETA: 5s - loss: 0.3871 - acc: 0.868 - ETA: 5s - loss: 0.3875 - acc: 0.868 - ETA: 5s - loss: 0.3846 - acc: 0.870 - ETA: 4s - loss: 0.3840 - acc: 0.871 - ETA: 4s - loss: 0.3836 - acc: 0.870 - ETA: 4s - loss: 0.3847 - acc: 0.870 - ETA: 4s - loss: 0.3867 - acc: 0.869 - ETA: 4s - loss: 0.3869 - acc: 0.869 - ETA: 4s - loss: 0.3856 - acc: 0.870 - ETA: 4s - loss: 0.3829 - acc: 0.871 - ETA: 4s - loss: 0.3841 - acc: 0.871 - ETA: 4s - loss: 0.3848 - acc: 0.871 - ETA: 4s - loss: 0.3839 - acc: 0.872 - ETA: 4s - loss: 0.3830 - acc: 0.871 - ETA: 4s - loss: 0.3825 - acc: 0.871 - ETA: 4s - loss: 0.3818 - acc: 0.871 - ETA: 4s - loss: 0.3810 - acc: 0.872 - ETA: 4s - loss: 0.3804 - acc: 0.872 - ETA: 3s - loss: 0.3793 - acc: 0.872 - ETA: 3s - loss: 0.3826 - acc: 0.872 - ETA: 3s - loss: 0.3848 - acc: 0.872 - ETA: 3s - loss: 0.3866 - acc: 0.871 - ETA: 3s - loss: 0.3852 - acc: 0.872 - ETA: 3s - loss: 0.3845 - acc: 0.872 - ETA: 3s - loss: 0.3839 - acc: 0.871 - ETA: 3s - loss: 0.3831 - acc: 0.872 - ETA: 3s - loss: 0.3851 - acc: 0.872 - ETA: 3s - loss: 0.3857 - acc: 0.871 - ETA: 3s - loss: 0.3850 - acc: 0.871 - ETA: 3s - loss: 0.3858 - acc: 0.871 - ETA: 3s - loss: 0.3837 - acc: 0.872 - ETA: 3s - loss: 0.3829 - acc: 0.872 - ETA: 3s - loss: 0.3840 - acc: 0.871 - ETA: 3s - loss: 0.3856 - acc: 0.871 - ETA: 2s - loss: 0.3860 - acc: 0.871 - ETA: 2s - loss: 0.3854 - acc: 0.871 - ETA: 2s - loss: 0.3892 - acc: 0.870 - ETA: 2s - loss: 0.3868 - acc: 0.871 - ETA: 2s - loss: 0.3851 - acc: 0.871 - ETA: 2s - loss: 0.3871 - acc: 0.870 - ETA: 2s - loss: 0.3881 - acc: 0.870 - ETA: 2s - loss: 0.3872 - acc: 0.870 - ETA: 2s - loss: 0.3878 - acc: 0.869 - ETA: 2s - loss: 0.3910 - acc: 0.868 - ETA: 2s - loss: 0.3900 - acc: 0.868 - ETA: 2s - loss: 0.3899 - acc: 0.868 - ETA: 2s - loss: 0.3903 - acc: 0.868 - ETA: 2s - loss: 0.3910 - acc: 0.868 - ETA: 2s - loss: 0.3969 - acc: 0.865 - ETA: 2s - loss: 0.3980 - acc: 0.865 - ETA: 1s - loss: 0.3970 - acc: 0.865 - ETA: 1s - loss: 0.3964 - acc: 0.865 - ETA: 1s - loss: 0.3961 - acc: 0.865 - ETA: 1s - loss: 0.3971 - acc: 0.864 - ETA: 1s - loss: 0.3982 - acc: 0.864 - ETA: 1s - loss: 0.3990 - acc: 0.864 - ETA: 1s - loss: 0.3999 - acc: 0.863 - ETA: 1s - loss: 0.4004 - acc: 0.862 - ETA: 1s - loss: 0.3990 - acc: 0.863 - ETA: 1s - loss: 0.4011 - acc: 0.861 - ETA: 1s - loss: 0.4021 - acc: 0.861 - ETA: 1s - loss: 0.4031 - acc: 0.860 - ETA: 1s - loss: 0.4020 - acc: 0.860 - ETA: 1s - loss: 0.4038 - acc: 0.859 - ETA: 1s - loss: 0.4037 - acc: 0.859 - ETA: 0s - loss: 0.4035 - acc: 0.859 - ETA: 0s - loss: 0.4041 - acc: 0.860 - ETA: 0s - loss: 0.4051 - acc: 0.860 - ETA: 0s - loss: 0.4047 - acc: 0.860 - ETA: 0s - loss: 0.4055 - acc: 0.860 - ETA: 0s - loss: 0.4038 - acc: 0.861 - ETA: 0s - loss: 0.4038 - acc: 0.860 - ETA: 0s - loss: 0.4026 - acc: 0.861 - ETA: 0s - loss: 0.4008 - acc: 0.861 - ETA: 0s - loss: 0.4007 - acc: 0.861 - ETA: 0s - loss: 0.4002 - acc: 0.861 - ETA: 0s - loss: 0.3989 - acc: 0.862 - ETA: 0s - loss: 0.4001 - acc: 0.862 - ETA: 0s - loss: 0.3998 - acc: 0.862 - ETA: 0s - loss: 0.4010 - acc: 0.861 - ETA: 0s - loss: 0.4042 - acc: 0.860 - 9s 2ms/step - loss: 0.4038 - acc: 0.8612\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4726/4726 [==============================] - ETA: 8s - loss: 0.4480 - acc: 0.875 - ETA: 8s - loss: 0.3535 - acc: 0.875 - ETA: 8s - loss: 0.3465 - acc: 0.864 - ETA: 8s - loss: 0.3461 - acc: 0.867 - ETA: 8s - loss: 0.3981 - acc: 0.862 - ETA: 8s - loss: 0.3778 - acc: 0.869 - ETA: 8s - loss: 0.3644 - acc: 0.866 - ETA: 8s - loss: 0.3556 - acc: 0.878 - ETA: 8s - loss: 0.3463 - acc: 0.878 - ETA: 8s - loss: 0.3694 - acc: 0.871 - ETA: 8s - loss: 0.3696 - acc: 0.866 - ETA: 8s - loss: 0.3543 - acc: 0.872 - ETA: 8s - loss: 0.3549 - acc: 0.870 - ETA: 8s - loss: 0.3587 - acc: 0.868 - ETA: 8s - loss: 0.3601 - acc: 0.866 - ETA: 8s - loss: 0.3587 - acc: 0.869 - ETA: 8s - loss: 0.3645 - acc: 0.867 - ETA: 8s - loss: 0.3567 - acc: 0.869 - ETA: 8s - loss: 0.3545 - acc: 0.871 - ETA: 8s - loss: 0.3597 - acc: 0.868 - ETA: 8s - loss: 0.3652 - acc: 0.866 - ETA: 7s - loss: 0.3654 - acc: 0.867 - ETA: 7s - loss: 0.3606 - acc: 0.870 - ETA: 7s - loss: 0.3596 - acc: 0.868 - ETA: 7s - loss: 0.3555 - acc: 0.870 - ETA: 7s - loss: 0.3542 - acc: 0.871 - ETA: 7s - loss: 0.3546 - acc: 0.872 - ETA: 7s - loss: 0.3601 - acc: 0.871 - ETA: 7s - loss: 0.3593 - acc: 0.871 - ETA: 7s - loss: 0.3662 - acc: 0.870 - ETA: 7s - loss: 0.3651 - acc: 0.872 - ETA: 7s - loss: 0.3655 - acc: 0.872 - ETA: 7s - loss: 0.3747 - acc: 0.869 - ETA: 7s - loss: 0.3743 - acc: 0.868 - ETA: 7s - loss: 0.3713 - acc: 0.869 - ETA: 7s - loss: 0.3724 - acc: 0.869 - ETA: 7s - loss: 0.3786 - acc: 0.869 - ETA: 6s - loss: 0.3770 - acc: 0.869 - ETA: 6s - loss: 0.3744 - acc: 0.870 - ETA: 6s - loss: 0.3738 - acc: 0.869 - ETA: 6s - loss: 0.3744 - acc: 0.868 - ETA: 6s - loss: 0.3727 - acc: 0.869 - ETA: 6s - loss: 0.3741 - acc: 0.869 - ETA: 6s - loss: 0.3768 - acc: 0.867 - ETA: 6s - loss: 0.3760 - acc: 0.868 - ETA: 6s - loss: 0.3787 - acc: 0.866 - ETA: 6s - loss: 0.3769 - acc: 0.867 - ETA: 6s - loss: 0.3767 - acc: 0.868 - ETA: 6s - loss: 0.3764 - acc: 0.869 - ETA: 6s - loss: 0.3772 - acc: 0.868 - ETA: 6s - loss: 0.3802 - acc: 0.867 - ETA: 6s - loss: 0.3766 - acc: 0.869 - ETA: 6s - loss: 0.3784 - acc: 0.869 - ETA: 5s - loss: 0.3775 - acc: 0.869 - ETA: 5s - loss: 0.3773 - acc: 0.868 - ETA: 5s - loss: 0.3734 - acc: 0.870 - ETA: 5s - loss: 0.3734 - acc: 0.869 - ETA: 5s - loss: 0.3710 - acc: 0.870 - ETA: 5s - loss: 0.3736 - acc: 0.869 - ETA: 5s - loss: 0.3749 - acc: 0.868 - ETA: 5s - loss: 0.3749 - acc: 0.868 - ETA: 5s - loss: 0.3754 - acc: 0.868 - ETA: 5s - loss: 0.3781 - acc: 0.867 - ETA: 5s - loss: 0.3773 - acc: 0.867 - ETA: 5s - loss: 0.3747 - acc: 0.868 - ETA: 5s - loss: 0.3765 - acc: 0.867 - ETA: 5s - loss: 0.3783 - acc: 0.866 - ETA: 5s - loss: 0.3799 - acc: 0.866 - ETA: 5s - loss: 0.3800 - acc: 0.866 - ETA: 4s - loss: 0.3785 - acc: 0.867 - ETA: 4s - loss: 0.3842 - acc: 0.865 - ETA: 4s - loss: 0.3828 - acc: 0.865 - ETA: 4s - loss: 0.3842 - acc: 0.865 - ETA: 4s - loss: 0.3838 - acc: 0.865 - ETA: 4s - loss: 0.3830 - acc: 0.866 - ETA: 4s - loss: 0.3858 - acc: 0.866 - ETA: 4s - loss: 0.3868 - acc: 0.866 - ETA: 4s - loss: 0.3857 - acc: 0.866 - ETA: 4s - loss: 0.3836 - acc: 0.867 - ETA: 4s - loss: 0.3831 - acc: 0.866 - ETA: 4s - loss: 0.3831 - acc: 0.866 - ETA: 4s - loss: 0.3864 - acc: 0.865 - ETA: 4s - loss: 0.3845 - acc: 0.866 - ETA: 4s - loss: 0.3838 - acc: 0.866 - ETA: 3s - loss: 0.3841 - acc: 0.866 - ETA: 3s - loss: 0.3828 - acc: 0.867 - ETA: 3s - loss: 0.3822 - acc: 0.867 - ETA: 3s - loss: 0.3828 - acc: 0.866 - ETA: 3s - loss: 0.3828 - acc: 0.866 - ETA: 3s - loss: 0.3806 - acc: 0.867 - ETA: 3s - loss: 0.3820 - acc: 0.867 - ETA: 3s - loss: 0.3837 - acc: 0.866 - ETA: 3s - loss: 0.3818 - acc: 0.867 - ETA: 3s - loss: 0.3818 - acc: 0.867 - ETA: 3s - loss: 0.3836 - acc: 0.866 - ETA: 3s - loss: 0.3825 - acc: 0.867 - ETA: 3s - loss: 0.3838 - acc: 0.866 - ETA: 3s - loss: 0.3826 - acc: 0.867 - ETA: 3s - loss: 0.3821 - acc: 0.866 - ETA: 3s - loss: 0.3844 - acc: 0.866 - ETA: 2s - loss: 0.3832 - acc: 0.867 - ETA: 2s - loss: 0.3828 - acc: 0.866 - ETA: 2s - loss: 0.3827 - acc: 0.866 - ETA: 2s - loss: 0.3846 - acc: 0.866 - ETA: 2s - loss: 0.3851 - acc: 0.866 - ETA: 2s - loss: 0.3840 - acc: 0.867 - ETA: 2s - loss: 0.3835 - acc: 0.867 - ETA: 2s - loss: 0.3843 - acc: 0.867 - ETA: 2s - loss: 0.3832 - acc: 0.868 - ETA: 2s - loss: 0.3824 - acc: 0.868 - ETA: 2s - loss: 0.3833 - acc: 0.868 - ETA: 2s - loss: 0.3826 - acc: 0.868 - ETA: 2s - loss: 0.3816 - acc: 0.868 - ETA: 2s - loss: 0.3805 - acc: 0.869 - ETA: 2s - loss: 0.3791 - acc: 0.869 - ETA: 2s - loss: 0.3791 - acc: 0.869 - ETA: 1s - loss: 0.3785 - acc: 0.870 - ETA: 1s - loss: 0.3792 - acc: 0.870 - ETA: 1s - loss: 0.3788 - acc: 0.870 - ETA: 1s - loss: 0.3825 - acc: 0.869 - ETA: 1s - loss: 0.3807 - acc: 0.870 - ETA: 1s - loss: 0.3823 - acc: 0.869 - ETA: 1s - loss: 0.3823 - acc: 0.869 - ETA: 1s - loss: 0.3841 - acc: 0.869 - ETA: 1s - loss: 0.3835 - acc: 0.869 - ETA: 1s - loss: 0.3832 - acc: 0.870 - ETA: 1s - loss: 0.3831 - acc: 0.869 - ETA: 1s - loss: 0.3863 - acc: 0.868 - ETA: 1s - loss: 0.3872 - acc: 0.868 - ETA: 1s - loss: 0.3865 - acc: 0.868 - ETA: 1s - loss: 0.3876 - acc: 0.867 - ETA: 0s - loss: 0.3869 - acc: 0.868 - ETA: 0s - loss: 0.3849 - acc: 0.869 - ETA: 0s - loss: 0.3845 - acc: 0.868 - ETA: 0s - loss: 0.3837 - acc: 0.869 - ETA: 0s - loss: 0.3847 - acc: 0.869 - ETA: 0s - loss: 0.3851 - acc: 0.869 - ETA: 0s - loss: 0.3845 - acc: 0.869 - ETA: 0s - loss: 0.3849 - acc: 0.869 - ETA: 0s - loss: 0.3860 - acc: 0.869 - ETA: 0s - loss: 0.3865 - acc: 0.868 - ETA: 0s - loss: 0.3865 - acc: 0.868 - ETA: 0s - loss: 0.3856 - acc: 0.868 - ETA: 0s - loss: 0.3851 - acc: 0.869 - ETA: 0s - loss: 0.3841 - acc: 0.869 - ETA: 0s - loss: 0.3832 - acc: 0.869 - ETA: 0s - loss: 0.3835 - acc: 0.869 - 9s 2ms/step - loss: 0.3843 - acc: 0.8686\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4726/4726 [==============================] - ETA: 9s - loss: 0.4553 - acc: 0.843 - ETA: 9s - loss: 0.2975 - acc: 0.921 - ETA: 9s - loss: 0.3384 - acc: 0.885 - ETA: 9s - loss: 0.3215 - acc: 0.882 - ETA: 9s - loss: 0.3913 - acc: 0.875 - ETA: 8s - loss: 0.4281 - acc: 0.880 - ETA: 8s - loss: 0.4198 - acc: 0.875 - ETA: 8s - loss: 0.3977 - acc: 0.878 - ETA: 8s - loss: 0.3977 - acc: 0.875 - ETA: 8s - loss: 0.4240 - acc: 0.865 - ETA: 8s - loss: 0.4112 - acc: 0.872 - ETA: 8s - loss: 0.3925 - acc: 0.882 - ETA: 8s - loss: 0.3778 - acc: 0.887 - ETA: 8s - loss: 0.3746 - acc: 0.886 - ETA: 8s - loss: 0.3638 - acc: 0.889 - ETA: 8s - loss: 0.3733 - acc: 0.884 - ETA: 8s - loss: 0.3832 - acc: 0.882 - ETA: 8s - loss: 0.3893 - acc: 0.878 - ETA: 8s - loss: 0.4071 - acc: 0.870 - ETA: 8s - loss: 0.3948 - acc: 0.871 - ETA: 8s - loss: 0.3922 - acc: 0.873 - ETA: 7s - loss: 0.4038 - acc: 0.869 - ETA: 7s - loss: 0.4019 - acc: 0.870 - ETA: 7s - loss: 0.4003 - acc: 0.869 - ETA: 7s - loss: 0.3898 - acc: 0.872 - ETA: 7s - loss: 0.3907 - acc: 0.871 - ETA: 7s - loss: 0.3835 - acc: 0.875 - ETA: 7s - loss: 0.3790 - acc: 0.877 - ETA: 7s - loss: 0.3795 - acc: 0.877 - ETA: 7s - loss: 0.3754 - acc: 0.878 - ETA: 7s - loss: 0.3712 - acc: 0.881 - ETA: 7s - loss: 0.3646 - acc: 0.883 - ETA: 7s - loss: 0.3705 - acc: 0.883 - ETA: 7s - loss: 0.3694 - acc: 0.882 - ETA: 7s - loss: 0.3668 - acc: 0.883 - ETA: 7s - loss: 0.3775 - acc: 0.881 - ETA: 7s - loss: 0.3769 - acc: 0.882 - ETA: 6s - loss: 0.3706 - acc: 0.884 - ETA: 6s - loss: 0.3685 - acc: 0.885 - ETA: 6s - loss: 0.3699 - acc: 0.883 - ETA: 6s - loss: 0.3631 - acc: 0.886 - ETA: 6s - loss: 0.3629 - acc: 0.886 - ETA: 6s - loss: 0.3649 - acc: 0.885 - ETA: 6s - loss: 0.3636 - acc: 0.884 - ETA: 6s - loss: 0.3629 - acc: 0.884 - ETA: 6s - loss: 0.3607 - acc: 0.885 - ETA: 6s - loss: 0.3570 - acc: 0.886 - ETA: 6s - loss: 0.3537 - acc: 0.887 - ETA: 6s - loss: 0.3514 - acc: 0.887 - ETA: 6s - loss: 0.3511 - acc: 0.886 - ETA: 6s - loss: 0.3533 - acc: 0.886 - ETA: 6s - loss: 0.3551 - acc: 0.884 - ETA: 6s - loss: 0.3517 - acc: 0.885 - ETA: 5s - loss: 0.3554 - acc: 0.884 - ETA: 5s - loss: 0.3563 - acc: 0.884 - ETA: 5s - loss: 0.3579 - acc: 0.883 - ETA: 5s - loss: 0.3565 - acc: 0.883 - ETA: 5s - loss: 0.3540 - acc: 0.884 - ETA: 5s - loss: 0.3516 - acc: 0.885 - ETA: 5s - loss: 0.3524 - acc: 0.885 - ETA: 5s - loss: 0.3509 - acc: 0.885 - ETA: 5s - loss: 0.3537 - acc: 0.884 - ETA: 5s - loss: 0.3541 - acc: 0.883 - ETA: 5s - loss: 0.3551 - acc: 0.882 - ETA: 5s - loss: 0.3542 - acc: 0.883 - ETA: 5s - loss: 0.3538 - acc: 0.882 - ETA: 5s - loss: 0.3513 - acc: 0.883 - ETA: 5s - loss: 0.3544 - acc: 0.882 - ETA: 5s - loss: 0.3545 - acc: 0.881 - ETA: 4s - loss: 0.3531 - acc: 0.882 - ETA: 4s - loss: 0.3518 - acc: 0.882 - ETA: 4s - loss: 0.3527 - acc: 0.882 - ETA: 4s - loss: 0.3524 - acc: 0.882 - ETA: 4s - loss: 0.3519 - acc: 0.883 - ETA: 4s - loss: 0.3531 - acc: 0.883 - ETA: 4s - loss: 0.3533 - acc: 0.882 - ETA: 4s - loss: 0.3520 - acc: 0.882 - ETA: 4s - loss: 0.3525 - acc: 0.881 - ETA: 4s - loss: 0.3523 - acc: 0.881 - ETA: 4s - loss: 0.3499 - acc: 0.882 - ETA: 4s - loss: 0.3511 - acc: 0.882 - ETA: 4s - loss: 0.3485 - acc: 0.883 - ETA: 4s - loss: 0.3486 - acc: 0.882 - ETA: 4s - loss: 0.3497 - acc: 0.882 - ETA: 3s - loss: 0.3503 - acc: 0.882 - ETA: 3s - loss: 0.3508 - acc: 0.882 - ETA: 3s - loss: 0.3519 - acc: 0.882 - ETA: 3s - loss: 0.3535 - acc: 0.881 - ETA: 3s - loss: 0.3541 - acc: 0.881 - ETA: 3s - loss: 0.3544 - acc: 0.881 - ETA: 3s - loss: 0.3537 - acc: 0.882 - ETA: 3s - loss: 0.3550 - acc: 0.882 - ETA: 3s - loss: 0.3560 - acc: 0.881 - ETA: 3s - loss: 0.3554 - acc: 0.881 - ETA: 3s - loss: 0.3554 - acc: 0.881 - ETA: 3s - loss: 0.3573 - acc: 0.880 - ETA: 3s - loss: 0.3570 - acc: 0.880 - ETA: 3s - loss: 0.3592 - acc: 0.880 - ETA: 3s - loss: 0.3599 - acc: 0.879 - ETA: 3s - loss: 0.3599 - acc: 0.879 - ETA: 2s - loss: 0.3602 - acc: 0.879 - ETA: 2s - loss: 0.3610 - acc: 0.879 - ETA: 2s - loss: 0.3598 - acc: 0.879 - ETA: 2s - loss: 0.3593 - acc: 0.880 - ETA: 2s - loss: 0.3601 - acc: 0.880 - ETA: 2s - loss: 0.3626 - acc: 0.878 - ETA: 2s - loss: 0.3634 - acc: 0.878 - ETA: 2s - loss: 0.3640 - acc: 0.878 - ETA: 2s - loss: 0.3642 - acc: 0.878 - ETA: 2s - loss: 0.3641 - acc: 0.877 - ETA: 2s - loss: 0.3647 - acc: 0.876 - ETA: 2s - loss: 0.3665 - acc: 0.875 - ETA: 2s - loss: 0.3654 - acc: 0.875 - ETA: 2s - loss: 0.3654 - acc: 0.875 - ETA: 2s - loss: 0.3636 - acc: 0.876 - ETA: 2s - loss: 0.3650 - acc: 0.876 - ETA: 1s - loss: 0.3653 - acc: 0.876 - ETA: 1s - loss: 0.3661 - acc: 0.876 - ETA: 1s - loss: 0.3648 - acc: 0.876 - ETA: 1s - loss: 0.3645 - acc: 0.876 - ETA: 1s - loss: 0.3656 - acc: 0.876 - ETA: 1s - loss: 0.3657 - acc: 0.875 - ETA: 1s - loss: 0.3680 - acc: 0.874 - ETA: 1s - loss: 0.3667 - acc: 0.874 - ETA: 1s - loss: 0.3656 - acc: 0.875 - ETA: 1s - loss: 0.3656 - acc: 0.874 - ETA: 1s - loss: 0.3651 - acc: 0.875 - ETA: 1s - loss: 0.3647 - acc: 0.875 - ETA: 1s - loss: 0.3640 - acc: 0.876 - ETA: 1s - loss: 0.3659 - acc: 0.875 - ETA: 1s - loss: 0.3661 - acc: 0.874 - ETA: 0s - loss: 0.3653 - acc: 0.874 - ETA: 0s - loss: 0.3643 - acc: 0.875 - ETA: 0s - loss: 0.3642 - acc: 0.875 - ETA: 0s - loss: 0.3645 - acc: 0.875 - ETA: 0s - loss: 0.3638 - acc: 0.875 - ETA: 0s - loss: 0.3626 - acc: 0.876 - ETA: 0s - loss: 0.3632 - acc: 0.875 - ETA: 0s - loss: 0.3624 - acc: 0.875 - ETA: 0s - loss: 0.3617 - acc: 0.876 - ETA: 0s - loss: 0.3606 - acc: 0.876 - ETA: 0s - loss: 0.3606 - acc: 0.876 - ETA: 0s - loss: 0.3600 - acc: 0.877 - ETA: 0s - loss: 0.3590 - acc: 0.877 - ETA: 0s - loss: 0.3580 - acc: 0.877 - ETA: 0s - loss: 0.3573 - acc: 0.878 - ETA: 0s - loss: 0.3570 - acc: 0.878 - 9s 2ms/step - loss: 0.3581 - acc: 0.8781\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4726/4726 [==============================] - ETA: 9s - loss: 0.1731 - acc: 0.937 - ETA: 9s - loss: 0.2718 - acc: 0.921 - ETA: 9s - loss: 0.2341 - acc: 0.927 - ETA: 9s - loss: 0.2523 - acc: 0.929 - ETA: 9s - loss: 0.2688 - acc: 0.925 - ETA: 9s - loss: 0.2669 - acc: 0.927 - ETA: 9s - loss: 0.2777 - acc: 0.919 - ETA: 9s - loss: 0.3175 - acc: 0.906 - ETA: 9s - loss: 0.2907 - acc: 0.916 - ETA: 9s - loss: 0.2821 - acc: 0.921 - ETA: 9s - loss: 0.2926 - acc: 0.911 - ETA: 9s - loss: 0.2961 - acc: 0.908 - ETA: 9s - loss: 0.2856 - acc: 0.915 - ETA: 9s - loss: 0.2980 - acc: 0.917 - ETA: 9s - loss: 0.2962 - acc: 0.916 - ETA: 9s - loss: 0.3202 - acc: 0.906 - ETA: 8s - loss: 0.3278 - acc: 0.900 - ETA: 8s - loss: 0.3179 - acc: 0.902 - ETA: 8s - loss: 0.3136 - acc: 0.904 - ETA: 8s - loss: 0.3203 - acc: 0.900 - ETA: 8s - loss: 0.3133 - acc: 0.901 - ETA: 8s - loss: 0.3168 - acc: 0.900 - ETA: 8s - loss: 0.3204 - acc: 0.899 - ETA: 8s - loss: 0.3253 - acc: 0.895 - ETA: 8s - loss: 0.3308 - acc: 0.896 - ETA: 8s - loss: 0.3304 - acc: 0.896 - ETA: 8s - loss: 0.3316 - acc: 0.894 - ETA: 8s - loss: 0.3236 - acc: 0.897 - ETA: 8s - loss: 0.3255 - acc: 0.897 - ETA: 7s - loss: 0.3233 - acc: 0.896 - ETA: 7s - loss: 0.3256 - acc: 0.896 - ETA: 7s - loss: 0.3249 - acc: 0.897 - ETA: 7s - loss: 0.3325 - acc: 0.897 - ETA: 7s - loss: 0.3366 - acc: 0.896 - ETA: 7s - loss: 0.3350 - acc: 0.895 - ETA: 7s - loss: 0.3304 - acc: 0.898 - ETA: 7s - loss: 0.3323 - acc: 0.897 - ETA: 7s - loss: 0.3331 - acc: 0.894 - ETA: 7s - loss: 0.3294 - acc: 0.895 - ETA: 7s - loss: 0.3250 - acc: 0.897 - ETA: 7s - loss: 0.3243 - acc: 0.897 - ETA: 7s - loss: 0.3255 - acc: 0.896 - ETA: 7s - loss: 0.3280 - acc: 0.896 - ETA: 7s - loss: 0.3292 - acc: 0.895 - ETA: 7s - loss: 0.3290 - acc: 0.895 - ETA: 7s - loss: 0.3270 - acc: 0.896 - ETA: 7s - loss: 0.3281 - acc: 0.895 - ETA: 7s - loss: 0.3264 - acc: 0.897 - ETA: 6s - loss: 0.3256 - acc: 0.897 - ETA: 6s - loss: 0.3226 - acc: 0.898 - ETA: 6s - loss: 0.3229 - acc: 0.899 - ETA: 6s - loss: 0.3258 - acc: 0.897 - ETA: 6s - loss: 0.3232 - acc: 0.899 - ETA: 6s - loss: 0.3243 - acc: 0.899 - ETA: 6s - loss: 0.3239 - acc: 0.900 - ETA: 6s - loss: 0.3222 - acc: 0.901 - ETA: 6s - loss: 0.3209 - acc: 0.901 - ETA: 6s - loss: 0.3188 - acc: 0.902 - ETA: 6s - loss: 0.3181 - acc: 0.902 - ETA: 6s - loss: 0.3174 - acc: 0.902 - ETA: 6s - loss: 0.3196 - acc: 0.901 - ETA: 5s - loss: 0.3210 - acc: 0.900 - ETA: 5s - loss: 0.3207 - acc: 0.900 - ETA: 5s - loss: 0.3214 - acc: 0.899 - ETA: 5s - loss: 0.3201 - acc: 0.900 - ETA: 5s - loss: 0.3194 - acc: 0.900 - ETA: 5s - loss: 0.3181 - acc: 0.900 - ETA: 5s - loss: 0.3164 - acc: 0.900 - ETA: 5s - loss: 0.3157 - acc: 0.900 - ETA: 5s - loss: 0.3162 - acc: 0.900 - ETA: 5s - loss: 0.3180 - acc: 0.900 - ETA: 5s - loss: 0.3189 - acc: 0.900 - ETA: 5s - loss: 0.3189 - acc: 0.899 - ETA: 5s - loss: 0.3197 - acc: 0.899 - ETA: 5s - loss: 0.3185 - acc: 0.899 - ETA: 4s - loss: 0.3204 - acc: 0.898 - ETA: 4s - loss: 0.3192 - acc: 0.898 - ETA: 4s - loss: 0.3179 - acc: 0.898 - ETA: 4s - loss: 0.3179 - acc: 0.898 - ETA: 4s - loss: 0.3168 - acc: 0.898 - ETA: 4s - loss: 0.3177 - acc: 0.898 - ETA: 4s - loss: 0.3167 - acc: 0.899 - ETA: 4s - loss: 0.3173 - acc: 0.898 - ETA: 4s - loss: 0.3171 - acc: 0.898 - ETA: 4s - loss: 0.3170 - acc: 0.897 - ETA: 4s - loss: 0.3183 - acc: 0.896 - ETA: 4s - loss: 0.3215 - acc: 0.894 - ETA: 4s - loss: 0.3229 - acc: 0.893 - ETA: 4s - loss: 0.3235 - acc: 0.893 - ETA: 3s - loss: 0.3254 - acc: 0.893 - ETA: 3s - loss: 0.3293 - acc: 0.891 - ETA: 3s - loss: 0.3291 - acc: 0.891 - ETA: 3s - loss: 0.3269 - acc: 0.891 - ETA: 3s - loss: 0.3306 - acc: 0.891 - ETA: 3s - loss: 0.3310 - acc: 0.890 - ETA: 3s - loss: 0.3336 - acc: 0.890 - ETA: 3s - loss: 0.3330 - acc: 0.890 - ETA: 3s - loss: 0.3339 - acc: 0.890 - ETA: 3s - loss: 0.3332 - acc: 0.890 - ETA: 3s - loss: 0.3316 - acc: 0.891 - ETA: 3s - loss: 0.3308 - acc: 0.891 - ETA: 3s - loss: 0.3306 - acc: 0.890 - ETA: 3s - loss: 0.3308 - acc: 0.891 - ETA: 2s - loss: 0.3294 - acc: 0.891 - ETA: 2s - loss: 0.3310 - acc: 0.891 - ETA: 2s - loss: 0.3307 - acc: 0.890 - ETA: 2s - loss: 0.3290 - acc: 0.891 - ETA: 2s - loss: 0.3283 - acc: 0.891 - ETA: 2s - loss: 0.3273 - acc: 0.892 - ETA: 2s - loss: 0.3259 - acc: 0.892 - ETA: 2s - loss: 0.3262 - acc: 0.892 - ETA: 2s - loss: 0.3251 - acc: 0.893 - ETA: 2s - loss: 0.3241 - acc: 0.893 - ETA: 2s - loss: 0.3237 - acc: 0.893 - ETA: 2s - loss: 0.3257 - acc: 0.892 - ETA: 2s - loss: 0.3261 - acc: 0.891 - ETA: 2s - loss: 0.3249 - acc: 0.892 - ETA: 2s - loss: 0.3244 - acc: 0.891 - ETA: 1s - loss: 0.3267 - acc: 0.890 - ETA: 1s - loss: 0.3253 - acc: 0.891 - ETA: 1s - loss: 0.3246 - acc: 0.891 - ETA: 1s - loss: 0.3271 - acc: 0.890 - ETA: 1s - loss: 0.3303 - acc: 0.889 - ETA: 1s - loss: 0.3329 - acc: 0.888 - ETA: 1s - loss: 0.3320 - acc: 0.889 - ETA: 1s - loss: 0.3317 - acc: 0.889 - ETA: 1s - loss: 0.3300 - acc: 0.889 - ETA: 1s - loss: 0.3308 - acc: 0.889 - ETA: 1s - loss: 0.3299 - acc: 0.889 - ETA: 1s - loss: 0.3296 - acc: 0.889 - ETA: 1s - loss: 0.3310 - acc: 0.889 - ETA: 1s - loss: 0.3334 - acc: 0.889 - ETA: 0s - loss: 0.3331 - acc: 0.889 - ETA: 0s - loss: 0.3328 - acc: 0.889 - ETA: 0s - loss: 0.3318 - acc: 0.889 - ETA: 0s - loss: 0.3313 - acc: 0.889 - ETA: 0s - loss: 0.3306 - acc: 0.889 - ETA: 0s - loss: 0.3323 - acc: 0.889 - ETA: 0s - loss: 0.3320 - acc: 0.889 - ETA: 0s - loss: 0.3320 - acc: 0.889 - ETA: 0s - loss: 0.3344 - acc: 0.888 - ETA: 0s - loss: 0.3363 - acc: 0.887 - ETA: 0s - loss: 0.3368 - acc: 0.887 - ETA: 0s - loss: 0.3367 - acc: 0.887 - ETA: 0s - loss: 0.3386 - acc: 0.887 - ETA: 0s - loss: 0.3380 - acc: 0.887 - ETA: 0s - loss: 0.3377 - acc: 0.887 - 10s 2ms/step - loss: 0.3371 - acc: 0.8876\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4726/4726 [==============================] - ETA: 10s - loss: 0.2783 - acc: 0.90 - ETA: 10s - loss: 0.2973 - acc: 0.89 - ETA: 9s - loss: 0.3599 - acc: 0.8958 - ETA: 9s - loss: 0.3392 - acc: 0.898 - ETA: 9s - loss: 0.3414 - acc: 0.900 - ETA: 9s - loss: 0.3082 - acc: 0.911 - ETA: 9s - loss: 0.2970 - acc: 0.919 - ETA: 9s - loss: 0.2813 - acc: 0.925 - ETA: 9s - loss: 0.2967 - acc: 0.920 - ETA: 9s - loss: 0.2908 - acc: 0.921 - ETA: 9s - loss: 0.3047 - acc: 0.909 - ETA: 9s - loss: 0.3296 - acc: 0.898 - ETA: 8s - loss: 0.3334 - acc: 0.899 - ETA: 8s - loss: 0.3309 - acc: 0.901 - ETA: 8s - loss: 0.3301 - acc: 0.900 - ETA: 8s - loss: 0.3276 - acc: 0.898 - ETA: 8s - loss: 0.3245 - acc: 0.898 - ETA: 8s - loss: 0.3217 - acc: 0.895 - ETA: 8s - loss: 0.3165 - acc: 0.896 - ETA: 8s - loss: 0.3333 - acc: 0.892 - ETA: 8s - loss: 0.3349 - acc: 0.889 - ETA: 8s - loss: 0.3339 - acc: 0.890 - ETA: 8s - loss: 0.3323 - acc: 0.889 - ETA: 8s - loss: 0.3312 - acc: 0.888 - ETA: 8s - loss: 0.3257 - acc: 0.888 - ETA: 7s - loss: 0.3235 - acc: 0.887 - ETA: 7s - loss: 0.3190 - acc: 0.887 - ETA: 7s - loss: 0.3128 - acc: 0.890 - ETA: 7s - loss: 0.3123 - acc: 0.893 - ETA: 7s - loss: 0.3066 - acc: 0.894 - ETA: 7s - loss: 0.3088 - acc: 0.893 - ETA: 7s - loss: 0.3045 - acc: 0.894 - ETA: 7s - loss: 0.3043 - acc: 0.893 - ETA: 7s - loss: 0.3008 - acc: 0.894 - ETA: 7s - loss: 0.3026 - acc: 0.894 - ETA: 7s - loss: 0.2984 - acc: 0.897 - ETA: 7s - loss: 0.2960 - acc: 0.898 - ETA: 7s - loss: 0.2955 - acc: 0.898 - ETA: 7s - loss: 0.2947 - acc: 0.898 - ETA: 7s - loss: 0.2952 - acc: 0.898 - ETA: 7s - loss: 0.2918 - acc: 0.900 - ETA: 7s - loss: 0.2942 - acc: 0.899 - ETA: 6s - loss: 0.2950 - acc: 0.899 - ETA: 6s - loss: 0.2954 - acc: 0.897 - ETA: 6s - loss: 0.2968 - acc: 0.898 - ETA: 6s - loss: 0.2934 - acc: 0.899 - ETA: 6s - loss: 0.2893 - acc: 0.900 - ETA: 6s - loss: 0.2899 - acc: 0.900 - ETA: 6s - loss: 0.2888 - acc: 0.900 - ETA: 6s - loss: 0.2900 - acc: 0.900 - ETA: 6s - loss: 0.2925 - acc: 0.899 - ETA: 6s - loss: 0.2917 - acc: 0.899 - ETA: 6s - loss: 0.2890 - acc: 0.900 - ETA: 6s - loss: 0.2914 - acc: 0.899 - ETA: 6s - loss: 0.2886 - acc: 0.900 - ETA: 6s - loss: 0.2855 - acc: 0.901 - ETA: 6s - loss: 0.2866 - acc: 0.899 - ETA: 5s - loss: 0.2855 - acc: 0.899 - ETA: 5s - loss: 0.2873 - acc: 0.898 - ETA: 5s - loss: 0.2854 - acc: 0.899 - ETA: 5s - loss: 0.2848 - acc: 0.900 - ETA: 5s - loss: 0.2853 - acc: 0.900 - ETA: 5s - loss: 0.2896 - acc: 0.899 - ETA: 5s - loss: 0.2888 - acc: 0.899 - ETA: 5s - loss: 0.2886 - acc: 0.900 - ETA: 5s - loss: 0.2870 - acc: 0.900 - ETA: 5s - loss: 0.2854 - acc: 0.900 - ETA: 5s - loss: 0.2883 - acc: 0.899 - ETA: 5s - loss: 0.2864 - acc: 0.900 - ETA: 5s - loss: 0.2846 - acc: 0.901 - ETA: 5s - loss: 0.2862 - acc: 0.900 - ETA: 5s - loss: 0.2843 - acc: 0.901 - ETA: 4s - loss: 0.2838 - acc: 0.902 - ETA: 4s - loss: 0.2855 - acc: 0.900 - ETA: 4s - loss: 0.2874 - acc: 0.900 - ETA: 4s - loss: 0.2913 - acc: 0.898 - ETA: 4s - loss: 0.2919 - acc: 0.898 - ETA: 4s - loss: 0.2921 - acc: 0.898 - ETA: 4s - loss: 0.2930 - acc: 0.898 - ETA: 4s - loss: 0.2926 - acc: 0.898 - ETA: 4s - loss: 0.2939 - acc: 0.897 - ETA: 4s - loss: 0.2964 - acc: 0.896 - ETA: 4s - loss: 0.2957 - acc: 0.896 - ETA: 4s - loss: 0.2987 - acc: 0.895 - ETA: 4s - loss: 0.3021 - acc: 0.894 - ETA: 4s - loss: 0.3022 - acc: 0.894 - ETA: 4s - loss: 0.3008 - acc: 0.895 - ETA: 3s - loss: 0.2987 - acc: 0.896 - ETA: 3s - loss: 0.2990 - acc: 0.896 - ETA: 3s - loss: 0.2983 - acc: 0.896 - ETA: 3s - loss: 0.2991 - acc: 0.897 - ETA: 3s - loss: 0.2995 - acc: 0.897 - ETA: 3s - loss: 0.3016 - acc: 0.896 - ETA: 3s - loss: 0.3001 - acc: 0.896 - ETA: 3s - loss: 0.2996 - acc: 0.897 - ETA: 3s - loss: 0.3028 - acc: 0.896 - ETA: 3s - loss: 0.3017 - acc: 0.897 - ETA: 3s - loss: 0.3004 - acc: 0.898 - ETA: 3s - loss: 0.2990 - acc: 0.898 - ETA: 3s - loss: 0.2988 - acc: 0.898 - ETA: 3s - loss: 0.2986 - acc: 0.898 - ETA: 3s - loss: 0.3010 - acc: 0.897 - ETA: 2s - loss: 0.3020 - acc: 0.896 - ETA: 2s - loss: 0.3010 - acc: 0.897 - ETA: 2s - loss: 0.3003 - acc: 0.897 - ETA: 2s - loss: 0.3017 - acc: 0.897 - ETA: 2s - loss: 0.3030 - acc: 0.896 - ETA: 2s - loss: 0.3041 - acc: 0.896 - ETA: 2s - loss: 0.3028 - acc: 0.896 - ETA: 2s - loss: 0.3023 - acc: 0.897 - ETA: 2s - loss: 0.3040 - acc: 0.897 - ETA: 2s - loss: 0.3069 - acc: 0.895 - ETA: 2s - loss: 0.3063 - acc: 0.895 - ETA: 2s - loss: 0.3051 - acc: 0.895 - ETA: 2s - loss: 0.3046 - acc: 0.895 - ETA: 2s - loss: 0.3036 - acc: 0.896 - ETA: 2s - loss: 0.3037 - acc: 0.896 - ETA: 1s - loss: 0.3038 - acc: 0.896 - ETA: 1s - loss: 0.3054 - acc: 0.896 - ETA: 1s - loss: 0.3063 - acc: 0.895 - ETA: 1s - loss: 0.3060 - acc: 0.895 - ETA: 1s - loss: 0.3075 - acc: 0.894 - ETA: 1s - loss: 0.3102 - acc: 0.894 - ETA: 1s - loss: 0.3110 - acc: 0.893 - ETA: 1s - loss: 0.3127 - acc: 0.893 - ETA: 1s - loss: 0.3134 - acc: 0.892 - ETA: 1s - loss: 0.3137 - acc: 0.893 - ETA: 1s - loss: 0.3153 - acc: 0.892 - ETA: 1s - loss: 0.3157 - acc: 0.892 - ETA: 1s - loss: 0.3160 - acc: 0.892 - ETA: 1s - loss: 0.3156 - acc: 0.891 - ETA: 1s - loss: 0.3182 - acc: 0.891 - ETA: 0s - loss: 0.3177 - acc: 0.891 - ETA: 0s - loss: 0.3162 - acc: 0.892 - ETA: 0s - loss: 0.3172 - acc: 0.891 - ETA: 0s - loss: 0.3165 - acc: 0.891 - ETA: 0s - loss: 0.3166 - acc: 0.892 - ETA: 0s - loss: 0.3162 - acc: 0.892 - ETA: 0s - loss: 0.3152 - acc: 0.892 - ETA: 0s - loss: 0.3150 - acc: 0.892 - ETA: 0s - loss: 0.3156 - acc: 0.892 - ETA: 0s - loss: 0.3178 - acc: 0.891 - ETA: 0s - loss: 0.3175 - acc: 0.892 - ETA: 0s - loss: 0.3168 - acc: 0.892 - ETA: 0s - loss: 0.3155 - acc: 0.892 - ETA: 0s - loss: 0.3153 - acc: 0.892 - ETA: 0s - loss: 0.3154 - acc: 0.892 - 10s 2ms/step - loss: 0.3152 - acc: 0.8925\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4726/4726 [==============================] - ETA: 9s - loss: 0.2639 - acc: 0.937 - ETA: 9s - loss: 0.2374 - acc: 0.937 - ETA: 9s - loss: 0.2947 - acc: 0.937 - ETA: 9s - loss: 0.2601 - acc: 0.937 - ETA: 9s - loss: 0.3026 - acc: 0.912 - ETA: 9s - loss: 0.2810 - acc: 0.921 - ETA: 9s - loss: 0.3261 - acc: 0.910 - ETA: 9s - loss: 0.3130 - acc: 0.910 - ETA: 9s - loss: 0.3105 - acc: 0.902 - ETA: 9s - loss: 0.2982 - acc: 0.909 - ETA: 9s - loss: 0.2992 - acc: 0.909 - ETA: 8s - loss: 0.3013 - acc: 0.908 - ETA: 8s - loss: 0.2928 - acc: 0.913 - ETA: 8s - loss: 0.3008 - acc: 0.912 - ETA: 8s - loss: 0.3175 - acc: 0.908 - ETA: 8s - loss: 0.3141 - acc: 0.910 - ETA: 8s - loss: 0.3166 - acc: 0.908 - ETA: 8s - loss: 0.3198 - acc: 0.906 - ETA: 8s - loss: 0.3104 - acc: 0.907 - ETA: 8s - loss: 0.3054 - acc: 0.907 - ETA: 8s - loss: 0.2968 - acc: 0.910 - ETA: 8s - loss: 0.2961 - acc: 0.913 - ETA: 8s - loss: 0.2897 - acc: 0.915 - ETA: 8s - loss: 0.2900 - acc: 0.912 - ETA: 7s - loss: 0.2840 - acc: 0.915 - ETA: 7s - loss: 0.2836 - acc: 0.914 - ETA: 7s - loss: 0.2790 - acc: 0.916 - ETA: 7s - loss: 0.2767 - acc: 0.916 - ETA: 7s - loss: 0.2762 - acc: 0.917 - ETA: 7s - loss: 0.2794 - acc: 0.915 - ETA: 7s - loss: 0.2767 - acc: 0.915 - ETA: 7s - loss: 0.2743 - acc: 0.915 - ETA: 7s - loss: 0.2811 - acc: 0.912 - ETA: 7s - loss: 0.2827 - acc: 0.913 - ETA: 7s - loss: 0.2858 - acc: 0.911 - ETA: 7s - loss: 0.2818 - acc: 0.913 - ETA: 7s - loss: 0.2781 - acc: 0.914 - ETA: 7s - loss: 0.2754 - acc: 0.914 - ETA: 7s - loss: 0.2761 - acc: 0.914 - ETA: 7s - loss: 0.2718 - acc: 0.915 - ETA: 7s - loss: 0.2691 - acc: 0.916 - ETA: 6s - loss: 0.2677 - acc: 0.916 - ETA: 6s - loss: 0.2730 - acc: 0.915 - ETA: 6s - loss: 0.2728 - acc: 0.914 - ETA: 6s - loss: 0.2697 - acc: 0.916 - ETA: 6s - loss: 0.2676 - acc: 0.917 - ETA: 6s - loss: 0.2659 - acc: 0.916 - ETA: 6s - loss: 0.2682 - acc: 0.915 - ETA: 6s - loss: 0.2689 - acc: 0.914 - ETA: 6s - loss: 0.2688 - acc: 0.914 - ETA: 6s - loss: 0.2671 - acc: 0.914 - ETA: 6s - loss: 0.2672 - acc: 0.914 - ETA: 6s - loss: 0.2634 - acc: 0.916 - ETA: 6s - loss: 0.2684 - acc: 0.914 - ETA: 6s - loss: 0.2675 - acc: 0.913 - ETA: 6s - loss: 0.2739 - acc: 0.911 - ETA: 5s - loss: 0.2747 - acc: 0.911 - ETA: 5s - loss: 0.2737 - acc: 0.912 - ETA: 5s - loss: 0.2762 - acc: 0.910 - ETA: 5s - loss: 0.2745 - acc: 0.910 - ETA: 5s - loss: 0.2808 - acc: 0.909 - ETA: 5s - loss: 0.2839 - acc: 0.908 - ETA: 5s - loss: 0.2867 - acc: 0.907 - ETA: 5s - loss: 0.2898 - acc: 0.907 - ETA: 5s - loss: 0.2917 - acc: 0.907 - ETA: 5s - loss: 0.2979 - acc: 0.906 - ETA: 5s - loss: 0.3003 - acc: 0.905 - ETA: 5s - loss: 0.2979 - acc: 0.905 - ETA: 5s - loss: 0.2998 - acc: 0.904 - ETA: 5s - loss: 0.2997 - acc: 0.904 - ETA: 5s - loss: 0.2979 - acc: 0.904 - ETA: 4s - loss: 0.2966 - acc: 0.905 - ETA: 4s - loss: 0.2975 - acc: 0.905 - ETA: 4s - loss: 0.2997 - acc: 0.905 - ETA: 4s - loss: 0.2974 - acc: 0.905 - ETA: 4s - loss: 0.2977 - acc: 0.905 - ETA: 4s - loss: 0.3008 - acc: 0.904 - ETA: 4s - loss: 0.3008 - acc: 0.904 - ETA: 4s - loss: 0.2998 - acc: 0.905 - ETA: 4s - loss: 0.3010 - acc: 0.903 - ETA: 4s - loss: 0.3022 - acc: 0.902 - ETA: 4s - loss: 0.3050 - acc: 0.901 - ETA: 4s - loss: 0.3057 - acc: 0.901 - ETA: 4s - loss: 0.3047 - acc: 0.902 - ETA: 4s - loss: 0.3021 - acc: 0.903 - ETA: 4s - loss: 0.3008 - acc: 0.904 - ETA: 3s - loss: 0.2994 - acc: 0.904 - ETA: 3s - loss: 0.2999 - acc: 0.904 - ETA: 3s - loss: 0.3007 - acc: 0.903 - ETA: 3s - loss: 0.3044 - acc: 0.902 - ETA: 3s - loss: 0.3062 - acc: 0.901 - ETA: 3s - loss: 0.3066 - acc: 0.901 - ETA: 3s - loss: 0.3060 - acc: 0.900 - ETA: 3s - loss: 0.3043 - acc: 0.901 - ETA: 3s - loss: 0.3030 - acc: 0.901 - ETA: 3s - loss: 0.3035 - acc: 0.901 - ETA: 3s - loss: 0.3015 - acc: 0.902 - ETA: 3s - loss: 0.3036 - acc: 0.901 - ETA: 3s - loss: 0.3061 - acc: 0.900 - ETA: 3s - loss: 0.3049 - acc: 0.901 - ETA: 3s - loss: 0.3059 - acc: 0.901 - ETA: 3s - loss: 0.3080 - acc: 0.901 - ETA: 2s - loss: 0.3084 - acc: 0.900 - ETA: 2s - loss: 0.3070 - acc: 0.901 - ETA: 2s - loss: 0.3081 - acc: 0.901 - ETA: 2s - loss: 0.3081 - acc: 0.901 - ETA: 2s - loss: 0.3069 - acc: 0.901 - ETA: 2s - loss: 0.3071 - acc: 0.901 - ETA: 2s - loss: 0.3065 - acc: 0.901 - ETA: 2s - loss: 0.3051 - acc: 0.902 - ETA: 2s - loss: 0.3047 - acc: 0.902 - ETA: 2s - loss: 0.3061 - acc: 0.902 - ETA: 2s - loss: 0.3045 - acc: 0.903 - ETA: 2s - loss: 0.3053 - acc: 0.903 - ETA: 2s - loss: 0.3057 - acc: 0.902 - ETA: 2s - loss: 0.3056 - acc: 0.902 - ETA: 2s - loss: 0.3044 - acc: 0.903 - ETA: 1s - loss: 0.3056 - acc: 0.902 - ETA: 1s - loss: 0.3045 - acc: 0.903 - ETA: 1s - loss: 0.3046 - acc: 0.903 - ETA: 1s - loss: 0.3033 - acc: 0.903 - ETA: 1s - loss: 0.3019 - acc: 0.903 - ETA: 1s - loss: 0.3017 - acc: 0.904 - ETA: 1s - loss: 0.3011 - acc: 0.904 - ETA: 1s - loss: 0.3020 - acc: 0.903 - ETA: 1s - loss: 0.3008 - acc: 0.903 - ETA: 1s - loss: 0.3023 - acc: 0.903 - ETA: 1s - loss: 0.3016 - acc: 0.903 - ETA: 1s - loss: 0.3027 - acc: 0.902 - ETA: 1s - loss: 0.3032 - acc: 0.902 - ETA: 1s - loss: 0.3024 - acc: 0.902 - ETA: 1s - loss: 0.3015 - acc: 0.903 - ETA: 0s - loss: 0.3022 - acc: 0.903 - ETA: 0s - loss: 0.3015 - acc: 0.903 - ETA: 0s - loss: 0.3030 - acc: 0.902 - ETA: 0s - loss: 0.3025 - acc: 0.903 - ETA: 0s - loss: 0.3009 - acc: 0.903 - ETA: 0s - loss: 0.3003 - acc: 0.904 - ETA: 0s - loss: 0.2999 - acc: 0.904 - ETA: 0s - loss: 0.2999 - acc: 0.904 - ETA: 0s - loss: 0.2991 - acc: 0.904 - ETA: 0s - loss: 0.2987 - acc: 0.904 - ETA: 0s - loss: 0.3012 - acc: 0.904 - ETA: 0s - loss: 0.3005 - acc: 0.904 - ETA: 0s - loss: 0.3002 - acc: 0.904 - ETA: 0s - loss: 0.3007 - acc: 0.903 - ETA: 0s - loss: 0.3000 - acc: 0.903 - 10s 2ms/step - loss: 0.2999 - acc: 0.9039\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4726/4726 [==============================] - ETA: 9s - loss: 0.2963 - acc: 0.875 - ETA: 9s - loss: 0.2099 - acc: 0.921 - ETA: 9s - loss: 0.2307 - acc: 0.916 - ETA: 9s - loss: 0.2564 - acc: 0.898 - ETA: 9s - loss: 0.2640 - acc: 0.887 - ETA: 9s - loss: 0.2639 - acc: 0.890 - ETA: 9s - loss: 0.2900 - acc: 0.892 - ETA: 9s - loss: 0.2729 - acc: 0.906 - ETA: 9s - loss: 0.3027 - acc: 0.902 - ETA: 9s - loss: 0.3104 - acc: 0.896 - ETA: 9s - loss: 0.3139 - acc: 0.892 - ETA: 9s - loss: 0.3070 - acc: 0.893 - ETA: 9s - loss: 0.3044 - acc: 0.894 - ETA: 9s - loss: 0.2862 - acc: 0.901 - ETA: 8s - loss: 0.2941 - acc: 0.902 - ETA: 8s - loss: 0.2885 - acc: 0.904 - ETA: 8s - loss: 0.2841 - acc: 0.904 - ETA: 8s - loss: 0.2915 - acc: 0.901 - ETA: 8s - loss: 0.2889 - acc: 0.901 - ETA: 8s - loss: 0.2801 - acc: 0.904 - ETA: 8s - loss: 0.2744 - acc: 0.907 - ETA: 8s - loss: 0.2749 - acc: 0.906 - ETA: 8s - loss: 0.2749 - acc: 0.909 - ETA: 8s - loss: 0.2713 - acc: 0.908 - ETA: 8s - loss: 0.2643 - acc: 0.912 - ETA: 8s - loss: 0.2698 - acc: 0.911 - ETA: 7s - loss: 0.2644 - acc: 0.912 - ETA: 7s - loss: 0.2607 - acc: 0.912 - ETA: 7s - loss: 0.2608 - acc: 0.911 - ETA: 7s - loss: 0.2587 - acc: 0.912 - ETA: 7s - loss: 0.2599 - acc: 0.912 - ETA: 7s - loss: 0.2582 - acc: 0.912 - ETA: 7s - loss: 0.2576 - acc: 0.912 - ETA: 7s - loss: 0.2647 - acc: 0.912 - ETA: 7s - loss: 0.2692 - acc: 0.910 - ETA: 7s - loss: 0.2699 - acc: 0.911 - ETA: 7s - loss: 0.2676 - acc: 0.913 - ETA: 7s - loss: 0.2701 - acc: 0.912 - ETA: 7s - loss: 0.2783 - acc: 0.909 - ETA: 7s - loss: 0.2751 - acc: 0.910 - ETA: 7s - loss: 0.2762 - acc: 0.910 - ETA: 6s - loss: 0.2782 - acc: 0.910 - ETA: 6s - loss: 0.2798 - acc: 0.910 - ETA: 6s - loss: 0.2817 - acc: 0.909 - ETA: 6s - loss: 0.2794 - acc: 0.911 - ETA: 6s - loss: 0.2781 - acc: 0.911 - ETA: 6s - loss: 0.2792 - acc: 0.910 - ETA: 6s - loss: 0.2769 - acc: 0.911 - ETA: 6s - loss: 0.2767 - acc: 0.911 - ETA: 6s - loss: 0.2788 - acc: 0.911 - ETA: 6s - loss: 0.2751 - acc: 0.913 - ETA: 6s - loss: 0.2729 - acc: 0.912 - ETA: 6s - loss: 0.2763 - acc: 0.912 - ETA: 6s - loss: 0.2759 - acc: 0.912 - ETA: 6s - loss: 0.2779 - acc: 0.911 - ETA: 6s - loss: 0.2764 - acc: 0.911 - ETA: 6s - loss: 0.2753 - acc: 0.912 - ETA: 5s - loss: 0.2728 - acc: 0.913 - ETA: 5s - loss: 0.2728 - acc: 0.913 - ETA: 5s - loss: 0.2745 - acc: 0.912 - ETA: 5s - loss: 0.2723 - acc: 0.912 - ETA: 5s - loss: 0.2707 - acc: 0.913 - ETA: 5s - loss: 0.2737 - acc: 0.911 - ETA: 5s - loss: 0.2764 - acc: 0.911 - ETA: 5s - loss: 0.2741 - acc: 0.911 - ETA: 5s - loss: 0.2750 - acc: 0.911 - ETA: 5s - loss: 0.2805 - acc: 0.908 - ETA: 5s - loss: 0.2836 - acc: 0.907 - ETA: 5s - loss: 0.2840 - acc: 0.907 - ETA: 5s - loss: 0.2827 - acc: 0.907 - ETA: 5s - loss: 0.2850 - acc: 0.907 - ETA: 4s - loss: 0.2829 - acc: 0.908 - ETA: 4s - loss: 0.2833 - acc: 0.907 - ETA: 4s - loss: 0.2836 - acc: 0.907 - ETA: 4s - loss: 0.2855 - acc: 0.907 - ETA: 4s - loss: 0.2836 - acc: 0.907 - ETA: 4s - loss: 0.2828 - acc: 0.908 - ETA: 4s - loss: 0.2813 - acc: 0.909 - ETA: 4s - loss: 0.2814 - acc: 0.909 - ETA: 4s - loss: 0.2801 - acc: 0.910 - ETA: 4s - loss: 0.2806 - acc: 0.909 - ETA: 4s - loss: 0.2803 - acc: 0.909 - ETA: 4s - loss: 0.2819 - acc: 0.908 - ETA: 4s - loss: 0.2800 - acc: 0.909 - ETA: 4s - loss: 0.2781 - acc: 0.909 - ETA: 4s - loss: 0.2814 - acc: 0.908 - ETA: 3s - loss: 0.2832 - acc: 0.908 - ETA: 3s - loss: 0.2839 - acc: 0.908 - ETA: 3s - loss: 0.2846 - acc: 0.908 - ETA: 3s - loss: 0.2851 - acc: 0.908 - ETA: 3s - loss: 0.2827 - acc: 0.909 - ETA: 3s - loss: 0.2833 - acc: 0.908 - ETA: 3s - loss: 0.2829 - acc: 0.908 - ETA: 3s - loss: 0.2853 - acc: 0.907 - ETA: 3s - loss: 0.2843 - acc: 0.907 - ETA: 3s - loss: 0.2884 - acc: 0.905 - ETA: 3s - loss: 0.2893 - acc: 0.905 - ETA: 3s - loss: 0.2902 - acc: 0.905 - ETA: 3s - loss: 0.2902 - acc: 0.905 - ETA: 3s - loss: 0.2889 - acc: 0.905 - ETA: 3s - loss: 0.2902 - acc: 0.905 - ETA: 2s - loss: 0.2914 - acc: 0.905 - ETA: 2s - loss: 0.2905 - acc: 0.905 - ETA: 2s - loss: 0.2902 - acc: 0.905 - ETA: 2s - loss: 0.2917 - acc: 0.905 - ETA: 2s - loss: 0.2906 - acc: 0.905 - ETA: 2s - loss: 0.2892 - acc: 0.906 - ETA: 2s - loss: 0.2884 - acc: 0.906 - ETA: 2s - loss: 0.2887 - acc: 0.906 - ETA: 2s - loss: 0.2877 - acc: 0.906 - ETA: 2s - loss: 0.2865 - acc: 0.906 - ETA: 2s - loss: 0.2853 - acc: 0.907 - ETA: 2s - loss: 0.2865 - acc: 0.906 - ETA: 2s - loss: 0.2883 - acc: 0.904 - ETA: 2s - loss: 0.2901 - acc: 0.904 - ETA: 2s - loss: 0.2897 - acc: 0.904 - ETA: 1s - loss: 0.2885 - acc: 0.904 - ETA: 1s - loss: 0.2909 - acc: 0.904 - ETA: 1s - loss: 0.2904 - acc: 0.904 - ETA: 1s - loss: 0.2920 - acc: 0.903 - ETA: 1s - loss: 0.2905 - acc: 0.904 - ETA: 1s - loss: 0.2899 - acc: 0.904 - ETA: 1s - loss: 0.2914 - acc: 0.903 - ETA: 1s - loss: 0.2908 - acc: 0.903 - ETA: 1s - loss: 0.2929 - acc: 0.903 - ETA: 1s - loss: 0.2918 - acc: 0.903 - ETA: 1s - loss: 0.2914 - acc: 0.903 - ETA: 1s - loss: 0.2907 - acc: 0.904 - ETA: 1s - loss: 0.2894 - acc: 0.904 - ETA: 1s - loss: 0.2900 - acc: 0.904 - ETA: 1s - loss: 0.2893 - acc: 0.904 - ETA: 1s - loss: 0.2893 - acc: 0.903 - ETA: 0s - loss: 0.2881 - acc: 0.904 - ETA: 0s - loss: 0.2887 - acc: 0.904 - ETA: 0s - loss: 0.2886 - acc: 0.903 - ETA: 0s - loss: 0.2881 - acc: 0.903 - ETA: 0s - loss: 0.2879 - acc: 0.904 - ETA: 0s - loss: 0.2867 - acc: 0.904 - ETA: 0s - loss: 0.2869 - acc: 0.904 - ETA: 0s - loss: 0.2873 - acc: 0.904 - ETA: 0s - loss: 0.2867 - acc: 0.904 - ETA: 0s - loss: 0.2852 - acc: 0.905 - ETA: 0s - loss: 0.2847 - acc: 0.905 - ETA: 0s - loss: 0.2852 - acc: 0.905 - ETA: 0s - loss: 0.2851 - acc: 0.905 - ETA: 0s - loss: 0.2845 - acc: 0.905 - ETA: 0s - loss: 0.2854 - acc: 0.905 - 10s 2ms/step - loss: 0.2863 - acc: 0.9052\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4726/4726 [==============================] - ETA: 9s - loss: 0.3494 - acc: 0.906 - ETA: 9s - loss: 0.3850 - acc: 0.859 - ETA: 9s - loss: 0.3170 - acc: 0.885 - ETA: 9s - loss: 0.3386 - acc: 0.882 - ETA: 9s - loss: 0.3344 - acc: 0.875 - ETA: 9s - loss: 0.3213 - acc: 0.869 - ETA: 9s - loss: 0.2944 - acc: 0.883 - ETA: 9s - loss: 0.2730 - acc: 0.890 - ETA: 9s - loss: 0.2836 - acc: 0.888 - ETA: 8s - loss: 0.2658 - acc: 0.900 - ETA: 8s - loss: 0.2492 - acc: 0.906 - ETA: 8s - loss: 0.2332 - acc: 0.914 - ETA: 8s - loss: 0.2261 - acc: 0.915 - ETA: 8s - loss: 0.2284 - acc: 0.912 - ETA: 8s - loss: 0.2368 - acc: 0.910 - ETA: 8s - loss: 0.2448 - acc: 0.910 - ETA: 8s - loss: 0.2450 - acc: 0.908 - ETA: 8s - loss: 0.2387 - acc: 0.909 - ETA: 8s - loss: 0.2391 - acc: 0.911 - ETA: 8s - loss: 0.2339 - acc: 0.912 - ETA: 8s - loss: 0.2271 - acc: 0.916 - ETA: 8s - loss: 0.2214 - acc: 0.919 - ETA: 8s - loss: 0.2172 - acc: 0.921 - ETA: 8s - loss: 0.2193 - acc: 0.920 - ETA: 7s - loss: 0.2178 - acc: 0.921 - ETA: 7s - loss: 0.2162 - acc: 0.921 - ETA: 7s - loss: 0.2204 - acc: 0.920 - ETA: 7s - loss: 0.2205 - acc: 0.919 - ETA: 7s - loss: 0.2233 - acc: 0.917 - ETA: 7s - loss: 0.2233 - acc: 0.917 - ETA: 7s - loss: 0.2231 - acc: 0.917 - ETA: 7s - loss: 0.2231 - acc: 0.918 - ETA: 7s - loss: 0.2236 - acc: 0.919 - ETA: 7s - loss: 0.2208 - acc: 0.921 - ETA: 7s - loss: 0.2219 - acc: 0.920 - ETA: 7s - loss: 0.2226 - acc: 0.921 - ETA: 7s - loss: 0.2226 - acc: 0.921 - ETA: 7s - loss: 0.2187 - acc: 0.923 - ETA: 7s - loss: 0.2179 - acc: 0.923 - ETA: 6s - loss: 0.2223 - acc: 0.921 - ETA: 6s - loss: 0.2202 - acc: 0.921 - ETA: 6s - loss: 0.2267 - acc: 0.920 - ETA: 6s - loss: 0.2248 - acc: 0.920 - ETA: 6s - loss: 0.2220 - acc: 0.921 - ETA: 6s - loss: 0.2189 - acc: 0.923 - ETA: 6s - loss: 0.2198 - acc: 0.923 - ETA: 6s - loss: 0.2240 - acc: 0.920 - ETA: 6s - loss: 0.2319 - acc: 0.918 - ETA: 6s - loss: 0.2355 - acc: 0.917 - ETA: 6s - loss: 0.2343 - acc: 0.917 - ETA: 6s - loss: 0.2346 - acc: 0.916 - ETA: 6s - loss: 0.2318 - acc: 0.918 - ETA: 6s - loss: 0.2322 - acc: 0.918 - ETA: 6s - loss: 0.2306 - acc: 0.918 - ETA: 6s - loss: 0.2288 - acc: 0.918 - ETA: 6s - loss: 0.2276 - acc: 0.919 - ETA: 5s - loss: 0.2254 - acc: 0.919 - ETA: 5s - loss: 0.2232 - acc: 0.920 - ETA: 5s - loss: 0.2250 - acc: 0.920 - ETA: 5s - loss: 0.2300 - acc: 0.918 - ETA: 5s - loss: 0.2299 - acc: 0.918 - ETA: 5s - loss: 0.2278 - acc: 0.918 - ETA: 5s - loss: 0.2276 - acc: 0.919 - ETA: 5s - loss: 0.2306 - acc: 0.918 - ETA: 5s - loss: 0.2318 - acc: 0.917 - ETA: 5s - loss: 0.2306 - acc: 0.917 - ETA: 5s - loss: 0.2306 - acc: 0.917 - ETA: 5s - loss: 0.2282 - acc: 0.918 - ETA: 5s - loss: 0.2315 - acc: 0.916 - ETA: 5s - loss: 0.2298 - acc: 0.917 - ETA: 5s - loss: 0.2305 - acc: 0.916 - ETA: 4s - loss: 0.2295 - acc: 0.916 - ETA: 4s - loss: 0.2295 - acc: 0.916 - ETA: 4s - loss: 0.2290 - acc: 0.916 - ETA: 4s - loss: 0.2289 - acc: 0.917 - ETA: 4s - loss: 0.2281 - acc: 0.917 - ETA: 4s - loss: 0.2303 - acc: 0.916 - ETA: 4s - loss: 0.2298 - acc: 0.916 - ETA: 4s - loss: 0.2288 - acc: 0.916 - ETA: 4s - loss: 0.2283 - acc: 0.917 - ETA: 4s - loss: 0.2287 - acc: 0.917 - ETA: 4s - loss: 0.2297 - acc: 0.916 - ETA: 4s - loss: 0.2307 - acc: 0.916 - ETA: 4s - loss: 0.2301 - acc: 0.916 - ETA: 4s - loss: 0.2329 - acc: 0.915 - ETA: 4s - loss: 0.2344 - acc: 0.916 - ETA: 3s - loss: 0.2353 - acc: 0.915 - ETA: 3s - loss: 0.2357 - acc: 0.915 - ETA: 3s - loss: 0.2383 - acc: 0.916 - ETA: 3s - loss: 0.2399 - acc: 0.916 - ETA: 3s - loss: 0.2398 - acc: 0.915 - ETA: 3s - loss: 0.2388 - acc: 0.916 - ETA: 3s - loss: 0.2386 - acc: 0.916 - ETA: 3s - loss: 0.2394 - acc: 0.916 - ETA: 3s - loss: 0.2408 - acc: 0.916 - ETA: 3s - loss: 0.2411 - acc: 0.916 - ETA: 3s - loss: 0.2424 - acc: 0.915 - ETA: 3s - loss: 0.2430 - acc: 0.915 - ETA: 3s - loss: 0.2422 - acc: 0.915 - ETA: 3s - loss: 0.2418 - acc: 0.915 - ETA: 3s - loss: 0.2426 - acc: 0.915 - ETA: 2s - loss: 0.2430 - acc: 0.915 - ETA: 2s - loss: 0.2444 - acc: 0.914 - ETA: 2s - loss: 0.2455 - acc: 0.914 - ETA: 2s - loss: 0.2445 - acc: 0.914 - ETA: 2s - loss: 0.2443 - acc: 0.914 - ETA: 2s - loss: 0.2442 - acc: 0.915 - ETA: 2s - loss: 0.2440 - acc: 0.915 - ETA: 2s - loss: 0.2438 - acc: 0.915 - ETA: 2s - loss: 0.2443 - acc: 0.915 - ETA: 2s - loss: 0.2449 - acc: 0.915 - ETA: 2s - loss: 0.2444 - acc: 0.915 - ETA: 2s - loss: 0.2441 - acc: 0.915 - ETA: 2s - loss: 0.2468 - acc: 0.914 - ETA: 2s - loss: 0.2454 - acc: 0.915 - ETA: 2s - loss: 0.2466 - acc: 0.915 - ETA: 1s - loss: 0.2475 - acc: 0.914 - ETA: 1s - loss: 0.2477 - acc: 0.914 - ETA: 1s - loss: 0.2485 - acc: 0.914 - ETA: 1s - loss: 0.2485 - acc: 0.915 - ETA: 1s - loss: 0.2496 - acc: 0.915 - ETA: 1s - loss: 0.2496 - acc: 0.914 - ETA: 1s - loss: 0.2501 - acc: 0.914 - ETA: 1s - loss: 0.2514 - acc: 0.914 - ETA: 1s - loss: 0.2518 - acc: 0.914 - ETA: 1s - loss: 0.2522 - acc: 0.914 - ETA: 1s - loss: 0.2530 - acc: 0.913 - ETA: 1s - loss: 0.2550 - acc: 0.913 - ETA: 1s - loss: 0.2547 - acc: 0.914 - ETA: 1s - loss: 0.2555 - acc: 0.913 - ETA: 1s - loss: 0.2544 - acc: 0.914 - ETA: 1s - loss: 0.2561 - acc: 0.914 - ETA: 0s - loss: 0.2561 - acc: 0.913 - ETA: 0s - loss: 0.2566 - acc: 0.913 - ETA: 0s - loss: 0.2573 - acc: 0.913 - ETA: 0s - loss: 0.2566 - acc: 0.913 - ETA: 0s - loss: 0.2557 - acc: 0.913 - ETA: 0s - loss: 0.2556 - acc: 0.913 - ETA: 0s - loss: 0.2545 - acc: 0.914 - ETA: 0s - loss: 0.2545 - acc: 0.914 - ETA: 0s - loss: 0.2540 - acc: 0.914 - ETA: 0s - loss: 0.2544 - acc: 0.914 - ETA: 0s - loss: 0.2551 - acc: 0.913 - ETA: 0s - loss: 0.2573 - acc: 0.913 - ETA: 0s - loss: 0.2571 - acc: 0.912 - ETA: 0s - loss: 0.2570 - acc: 0.912 - ETA: 0s - loss: 0.2568 - acc: 0.912 - 10s 2ms/step - loss: 0.2567 - acc: 0.9126\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4726/4726 [==============================] - ETA: 9s - loss: 0.2383 - acc: 0.937 - ETA: 9s - loss: 0.1826 - acc: 0.937 - ETA: 10s - loss: 0.2382 - acc: 0.91 - ETA: 10s - loss: 0.2120 - acc: 0.92 - ETA: 10s - loss: 0.2179 - acc: 0.91 - ETA: 9s - loss: 0.1941 - acc: 0.9271 - ETA: 9s - loss: 0.2152 - acc: 0.928 - ETA: 9s - loss: 0.2126 - acc: 0.929 - ETA: 9s - loss: 0.1984 - acc: 0.934 - ETA: 9s - loss: 0.2134 - acc: 0.931 - ETA: 9s - loss: 0.2139 - acc: 0.931 - ETA: 9s - loss: 0.2132 - acc: 0.932 - ETA: 9s - loss: 0.2123 - acc: 0.932 - ETA: 9s - loss: 0.2146 - acc: 0.930 - ETA: 9s - loss: 0.2107 - acc: 0.931 - ETA: 8s - loss: 0.2082 - acc: 0.931 - ETA: 8s - loss: 0.2092 - acc: 0.932 - ETA: 8s - loss: 0.2070 - acc: 0.932 - ETA: 8s - loss: 0.2063 - acc: 0.932 - ETA: 8s - loss: 0.2172 - acc: 0.926 - ETA: 8s - loss: 0.2152 - acc: 0.925 - ETA: 8s - loss: 0.2232 - acc: 0.921 - ETA: 8s - loss: 0.2211 - acc: 0.922 - ETA: 8s - loss: 0.2224 - acc: 0.924 - ETA: 8s - loss: 0.2340 - acc: 0.923 - ETA: 8s - loss: 0.2353 - acc: 0.921 - ETA: 8s - loss: 0.2279 - acc: 0.924 - ETA: 7s - loss: 0.2288 - acc: 0.925 - ETA: 7s - loss: 0.2304 - acc: 0.922 - ETA: 7s - loss: 0.2404 - acc: 0.916 - ETA: 7s - loss: 0.2424 - acc: 0.914 - ETA: 7s - loss: 0.2437 - acc: 0.913 - ETA: 7s - loss: 0.2422 - acc: 0.912 - ETA: 7s - loss: 0.2400 - acc: 0.913 - ETA: 7s - loss: 0.2409 - acc: 0.913 - ETA: 7s - loss: 0.2406 - acc: 0.913 - ETA: 7s - loss: 0.2415 - acc: 0.913 - ETA: 7s - loss: 0.2440 - acc: 0.912 - ETA: 7s - loss: 0.2444 - acc: 0.914 - ETA: 7s - loss: 0.2409 - acc: 0.915 - ETA: 7s - loss: 0.2516 - acc: 0.913 - ETA: 6s - loss: 0.2540 - acc: 0.912 - ETA: 6s - loss: 0.2518 - acc: 0.913 - ETA: 6s - loss: 0.2514 - acc: 0.914 - ETA: 6s - loss: 0.2494 - acc: 0.915 - ETA: 6s - loss: 0.2454 - acc: 0.916 - ETA: 6s - loss: 0.2430 - acc: 0.916 - ETA: 6s - loss: 0.2434 - acc: 0.916 - ETA: 6s - loss: 0.2433 - acc: 0.916 - ETA: 6s - loss: 0.2446 - acc: 0.915 - ETA: 6s - loss: 0.2504 - acc: 0.914 - ETA: 6s - loss: 0.2518 - acc: 0.912 - ETA: 6s - loss: 0.2488 - acc: 0.914 - ETA: 6s - loss: 0.2497 - acc: 0.914 - ETA: 6s - loss: 0.2522 - acc: 0.913 - ETA: 6s - loss: 0.2523 - acc: 0.913 - ETA: 5s - loss: 0.2517 - acc: 0.914 - ETA: 5s - loss: 0.2495 - acc: 0.914 - ETA: 5s - loss: 0.2530 - acc: 0.914 - ETA: 5s - loss: 0.2512 - acc: 0.914 - ETA: 5s - loss: 0.2499 - acc: 0.915 - ETA: 5s - loss: 0.2522 - acc: 0.914 - ETA: 5s - loss: 0.2515 - acc: 0.913 - ETA: 5s - loss: 0.2542 - acc: 0.912 - ETA: 5s - loss: 0.2531 - acc: 0.913 - ETA: 5s - loss: 0.2513 - acc: 0.914 - ETA: 5s - loss: 0.2527 - acc: 0.913 - ETA: 5s - loss: 0.2556 - acc: 0.913 - ETA: 5s - loss: 0.2565 - acc: 0.913 - ETA: 5s - loss: 0.2576 - acc: 0.913 - ETA: 5s - loss: 0.2575 - acc: 0.913 - ETA: 5s - loss: 0.2552 - acc: 0.914 - ETA: 4s - loss: 0.2540 - acc: 0.915 - ETA: 4s - loss: 0.2513 - acc: 0.916 - ETA: 4s - loss: 0.2492 - acc: 0.917 - ETA: 4s - loss: 0.2477 - acc: 0.917 - ETA: 4s - loss: 0.2484 - acc: 0.918 - ETA: 4s - loss: 0.2498 - acc: 0.917 - ETA: 4s - loss: 0.2477 - acc: 0.918 - ETA: 4s - loss: 0.2462 - acc: 0.918 - ETA: 4s - loss: 0.2455 - acc: 0.919 - ETA: 4s - loss: 0.2466 - acc: 0.918 - ETA: 4s - loss: 0.2462 - acc: 0.918 - ETA: 4s - loss: 0.2447 - acc: 0.919 - ETA: 4s - loss: 0.2425 - acc: 0.920 - ETA: 4s - loss: 0.2423 - acc: 0.920 - ETA: 4s - loss: 0.2403 - acc: 0.921 - ETA: 3s - loss: 0.2398 - acc: 0.920 - ETA: 3s - loss: 0.2404 - acc: 0.919 - ETA: 3s - loss: 0.2388 - acc: 0.920 - ETA: 3s - loss: 0.2383 - acc: 0.920 - ETA: 3s - loss: 0.2373 - acc: 0.921 - ETA: 3s - loss: 0.2386 - acc: 0.921 - ETA: 3s - loss: 0.2424 - acc: 0.920 - ETA: 3s - loss: 0.2429 - acc: 0.920 - ETA: 3s - loss: 0.2435 - acc: 0.919 - ETA: 3s - loss: 0.2423 - acc: 0.920 - ETA: 3s - loss: 0.2430 - acc: 0.919 - ETA: 3s - loss: 0.2425 - acc: 0.919 - ETA: 3s - loss: 0.2409 - acc: 0.920 - ETA: 3s - loss: 0.2398 - acc: 0.920 - ETA: 3s - loss: 0.2387 - acc: 0.921 - ETA: 2s - loss: 0.2383 - acc: 0.921 - ETA: 2s - loss: 0.2387 - acc: 0.921 - ETA: 2s - loss: 0.2377 - acc: 0.921 - ETA: 2s - loss: 0.2377 - acc: 0.921 - ETA: 2s - loss: 0.2374 - acc: 0.920 - ETA: 2s - loss: 0.2376 - acc: 0.920 - ETA: 2s - loss: 0.2375 - acc: 0.920 - ETA: 2s - loss: 0.2363 - acc: 0.921 - ETA: 2s - loss: 0.2390 - acc: 0.920 - ETA: 2s - loss: 0.2409 - acc: 0.919 - ETA: 2s - loss: 0.2416 - acc: 0.919 - ETA: 2s - loss: 0.2423 - acc: 0.919 - ETA: 2s - loss: 0.2413 - acc: 0.919 - ETA: 2s - loss: 0.2415 - acc: 0.919 - ETA: 2s - loss: 0.2419 - acc: 0.919 - ETA: 1s - loss: 0.2422 - acc: 0.919 - ETA: 1s - loss: 0.2432 - acc: 0.919 - ETA: 1s - loss: 0.2436 - acc: 0.919 - ETA: 1s - loss: 0.2427 - acc: 0.919 - ETA: 1s - loss: 0.2433 - acc: 0.919 - ETA: 1s - loss: 0.2435 - acc: 0.919 - ETA: 1s - loss: 0.2429 - acc: 0.919 - ETA: 1s - loss: 0.2444 - acc: 0.919 - ETA: 1s - loss: 0.2442 - acc: 0.918 - ETA: 1s - loss: 0.2434 - acc: 0.919 - ETA: 1s - loss: 0.2446 - acc: 0.919 - ETA: 1s - loss: 0.2458 - acc: 0.919 - ETA: 1s - loss: 0.2453 - acc: 0.919 - ETA: 1s - loss: 0.2445 - acc: 0.919 - ETA: 1s - loss: 0.2440 - acc: 0.920 - ETA: 0s - loss: 0.2441 - acc: 0.919 - ETA: 0s - loss: 0.2434 - acc: 0.920 - ETA: 0s - loss: 0.2432 - acc: 0.920 - ETA: 0s - loss: 0.2421 - acc: 0.920 - ETA: 0s - loss: 0.2422 - acc: 0.920 - ETA: 0s - loss: 0.2429 - acc: 0.919 - ETA: 0s - loss: 0.2429 - acc: 0.919 - ETA: 0s - loss: 0.2441 - acc: 0.918 - ETA: 0s - loss: 0.2435 - acc: 0.918 - ETA: 0s - loss: 0.2454 - acc: 0.917 - ETA: 0s - loss: 0.2470 - acc: 0.917 - ETA: 0s - loss: 0.2463 - acc: 0.918 - ETA: 0s - loss: 0.2473 - acc: 0.917 - ETA: 0s - loss: 0.2467 - acc: 0.918 - ETA: 0s - loss: 0.2466 - acc: 0.917 - 10s 2ms/step - loss: 0.2493 - acc: 0.9171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7733f2e8>"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1182/1182 [==============================] - ETA: 20 - ETA: 5 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 1s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.862387182143739, 0.7461928939052846]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0033361 , 0.00180081, 0.9900378 , 0.0048253 ]], dtype=float32)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(pad(transform(\"I am not happy\"),54, UNK=np.zeros(300)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4726, 54, 300)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00484337, 0.00183919, 0.96562874, 0.02768859]], dtype=float32)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(pad(transform('I am not happy'),54))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 54, 300)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(X,y=None):\n",
    "    X=pd.Series(X).apply(clean)\n",
    "    splits=word_splits(X)\n",
    "    numbers_series=splits.apply(vec_words)\n",
    "    num_docs=len(numbers_series)\n",
    "    X_1=[]\n",
    "    y_1=[]\n",
    "    for index in range(0, num_docs):\n",
    "        doc=numbers_series.iloc[index]\n",
    "        X_doc=[]\n",
    "        for word in doc:\n",
    "            X_doc.append(word)\n",
    "        X_1.append(np.array(X_doc))\n",
    "        if y is not None:\n",
    "            y_1.append(y.iloc[index])\n",
    "            \n",
    "    if y is not None:\n",
    "        y_1=transform_y(y_1)\n",
    "        return np.array(X_1), np.array(y_1)\n",
    "    else:\n",
    "        return np.array(X_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5908, 54, 300)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_lengths = [x.shape[0] for x in X]\n",
    "padded_x = pad(X, 54)\n",
    "padded_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 28, 41, 54]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_seqlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_sizes, bucket_ranges = np.histogram(sequence_lengths,\n",
    "                                                   bins=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 28, 41, 54]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_seqlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4716, 1082, 97, 13]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_bucketsizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 4716, 300]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[14,4716]+list(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[300]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04738307, 0.02606172, 0.56835777, 0.3581974 ],\n",
       "       [0.00389095, 0.00138126, 0.9091637 , 0.08556406]], dtype=float32)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, 'I am not happy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02563701, 0.01372149, 0.7387607 , 0.22188073]], dtype=float32)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(model.predict(transform(\"I am not happy\")), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y=transform(data['1'], data['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pad(X,54, UNK=np.zeros(300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['joy', 'joy', 'joy', 'joy', 'joy', 'joy', 'joy', 'joy', 'joy', 'joy', 'joy', 'joy']),\n",
       "       list(['sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness']),\n",
       "       list(['anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger']),\n",
       "       ...,\n",
       "       list(['fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear']),\n",
       "       list(['sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness']),\n",
       "       list(['joy', 'joy', 'joy', 'joy'])], dtype=object)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([[0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0]]),\n",
       "       array([[0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1]]),\n",
       "       array([[1, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 0, 0, 0]]),\n",
       "       ...,\n",
       "       array([[0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0]]),\n",
       "       array([[0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1]]),\n",
       "       array([[0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0]])], dtype=object)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_1=[]\n",
    "mappings={'anger': np.array([1,0,0,0]), 'fear': np.array([0,1,0,0]), 'joy': np.array([0,0,1,0]), 'sadness': np.array([0,0,0,1])}\n",
    "for entry in y:\n",
    "    y_entry=[]\n",
    "    for emot in entry:\n",
    "        y_entry.append(mappings[emot])\n",
    "    y_1.append(np.array(y_entry))\n",
    "y_1=np.array(y_1)\n",
    "y_1 \n",
    "y_2=[]\n",
    "for doc in y_1:\n",
    "    UNK=doc[0]\n",
    "    y_doc=pad(doc, 54, UNK)\n",
    "    y_2.append(np.array(y_doc))\n",
    "y_2=np.array(y_2)\n",
    "y_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence_input = Input(shape=(MAX_SENT_LENGTH,), dtype='int32')\n",
    "#sentence_input = Input(shape=(None,), dtype='int32')\n",
    "#embedded_sequences = embedding_layer(sentence_input)\n",
    "#l_lstm = Bidirectional(GRU(100, return_sequences=True))(embedded_sequences)\n",
    "sentence_input= Input(shape=(None, 300))\n",
    "l_lstm = Bidirectional(GRU(100, return_sequences=True))(sentence_input)\n",
    "l_dense = TimeDistributed(Dense(200))(l_lstm)\n",
    "l_att = AttLayer()(l_dense)\n",
    "sentEncoder = Model(sentence_input, l_att)\n",
    " \n",
    "#review_input = Input(shape=(MAX_SENTS,MAX_SENT_LENGTH), dtype='int32')\n",
    "review_input = Input(shape=(7,None), dtype='int32')\n",
    "review_encoder = TimeDistributed(sentEncoder)(review_input)\n",
    "l_lstm_sent = Bidirectional(GRU(100, return_sequences=True))(review_encoder)\n",
    "l_dense_sent = TimeDistributed(Dense(200))(l_lstm_sent)\n",
    "l_att_sent = AttLayer()(l_dense_sent)\n",
    "preds = Dense(2, activation='softmax')(l_att_sent)\n",
    "model = Model(review_input, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "han=Sequential()\n",
    "han.add(Bidirectional(GRU(units=100, return_sequences=True), input_shape=(6,300)))\n",
    "han.add(TimeDistributed(Dense(200)))\n",
    "han.add(AttLayer())\n",
    "classifier.add(Dropout(0.3))\n",
    "classifier.add(Dense(units=4, activation='softmax'))\n",
    "classifier.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>anger, fear, joy, sadness</h1>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
