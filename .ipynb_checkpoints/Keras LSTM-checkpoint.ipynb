{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicholas\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\Nicholas\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import collections\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, Dropout, SpatialDropout1D, TimeDistributed, Reshape, Lambda\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical, np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import model_from_json, Model\n",
    "import keras.backend as K\n",
    "from keras.layers import LSTM, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pdb\n",
    "from gensim.models import KeyedVectors\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from matplotlib import pyplot\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>This step takes forever</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_model = KeyedVectors.load_word2vec_format('wiki-news-300d-1M.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicholas\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{',': <gensim.models.keyedvectors.Vocab at 0x2e1852e8>,\n",
       " 'the': <gensim.models.keyedvectors.Vocab at 0x2e185048>,\n",
       " '.': <gensim.models.keyedvectors.Vocab at 0x2e185358>,\n",
       " 'and': <gensim.models.keyedvectors.Vocab at 0x2e185080>,\n",
       " 'of': <gensim.models.keyedvectors.Vocab at 0x2e1853c8>,\n",
       " 'to': <gensim.models.keyedvectors.Vocab at 0x2e1850f0>,\n",
       " 'in': <gensim.models.keyedvectors.Vocab at 0x2e185438>,\n",
       " 'a': <gensim.models.keyedvectors.Vocab at 0x2e185160>,\n",
       " '\"': <gensim.models.keyedvectors.Vocab at 0x2e185470>,\n",
       " ':': <gensim.models.keyedvectors.Vocab at 0x2e185198>,\n",
       " ')': <gensim.models.keyedvectors.Vocab at 0x2e1854a8>,\n",
       " 'that': <gensim.models.keyedvectors.Vocab at 0x2e1851d0>,\n",
       " '(': <gensim.models.keyedvectors.Vocab at 0x2e185518>,\n",
       " 'is': <gensim.models.keyedvectors.Vocab at 0x2e185208>,\n",
       " 'for': <gensim.models.keyedvectors.Vocab at 0x2e185588>,\n",
       " 'on': <gensim.models.keyedvectors.Vocab at 0x2e185278>,\n",
       " '*': <gensim.models.keyedvectors.Vocab at 0x2e1855f8>,\n",
       " 'with': <gensim.models.keyedvectors.Vocab at 0x2e1852b0>,\n",
       " 'as': <gensim.models.keyedvectors.Vocab at 0x2e185668>,\n",
       " 'it': <gensim.models.keyedvectors.Vocab at 0x2e18c630>,\n",
       " 'The': <gensim.models.keyedvectors.Vocab at 0x2e1856d8>,\n",
       " 'or': <gensim.models.keyedvectors.Vocab at 0x2e18c6a0>,\n",
       " 'was': <gensim.models.keyedvectors.Vocab at 0x2e185748>,\n",
       " \"'\": <gensim.models.keyedvectors.Vocab at 0x2e18c710>,\n",
       " \"'s\": <gensim.models.keyedvectors.Vocab at 0x2e185780>,\n",
       " 'by': <gensim.models.keyedvectors.Vocab at 0x2e18c780>,\n",
       " 'from': <gensim.models.keyedvectors.Vocab at 0x2e1857f0>,\n",
       " 'at': <gensim.models.keyedvectors.Vocab at 0x2e18c7f0>,\n",
       " 'I': <gensim.models.keyedvectors.Vocab at 0x2e185860>,\n",
       " 'this': <gensim.models.keyedvectors.Vocab at 0x2e18c828>,\n",
       " 'you': <gensim.models.keyedvectors.Vocab at 0x2e1858d0>,\n",
       " '/': <gensim.models.keyedvectors.Vocab at 0x2e18c898>,\n",
       " 'are': <gensim.models.keyedvectors.Vocab at 0x2e185908>,\n",
       " '=': <gensim.models.keyedvectors.Vocab at 0x2e18c908>,\n",
       " 'not': <gensim.models.keyedvectors.Vocab at 0x2e185940>,\n",
       " '-': <gensim.models.keyedvectors.Vocab at 0x2e18c978>,\n",
       " 'have': <gensim.models.keyedvectors.Vocab at 0x2e185978>,\n",
       " '?': <gensim.models.keyedvectors.Vocab at 0x2e18c9e8>,\n",
       " 'be': <gensim.models.keyedvectors.Vocab at 0x2e1859b0>,\n",
       " 'which': <gensim.models.keyedvectors.Vocab at 0x2e18ca58>,\n",
       " ';': <gensim.models.keyedvectors.Vocab at 0x2e185a20>,\n",
       " 'all': <gensim.models.keyedvectors.Vocab at 0x2e18ca90>,\n",
       " 'his': <gensim.models.keyedvectors.Vocab at 0x2e185a90>,\n",
       " 'has': <gensim.models.keyedvectors.Vocab at 0x2e18cb00>,\n",
       " 'one': <gensim.models.keyedvectors.Vocab at 0x2e185b00>,\n",
       " 'their': <gensim.models.keyedvectors.Vocab at 0x2e18cb70>,\n",
       " 'about': <gensim.models.keyedvectors.Vocab at 0x2e185b70>,\n",
       " 'but': <gensim.models.keyedvectors.Vocab at 0x2e18cbe0>,\n",
       " 'an': <gensim.models.keyedvectors.Vocab at 0x2e185be0>,\n",
       " '|': <gensim.models.keyedvectors.Vocab at 0x2e18cc50>,\n",
       " 'said': <gensim.models.keyedvectors.Vocab at 0x2e185c18>,\n",
       " 'more': <gensim.models.keyedvectors.Vocab at 0x2e18ccc0>,\n",
       " 'page': <gensim.models.keyedvectors.Vocab at 0x2e185c88>,\n",
       " 'he': <gensim.models.keyedvectors.Vocab at 0x2e18cd30>,\n",
       " 'your': <gensim.models.keyedvectors.Vocab at 0x2e185cf8>,\n",
       " 'will': <gensim.models.keyedvectors.Vocab at 0x2e18cda0>,\n",
       " 'its': <gensim.models.keyedvectors.Vocab at 0x2e185d68>,\n",
       " 'so': <gensim.models.keyedvectors.Vocab at 0x2e18ce10>,\n",
       " 'were': <gensim.models.keyedvectors.Vocab at 0x2e185dd8>,\n",
       " 'had': <gensim.models.keyedvectors.Vocab at 0x2e18ce80>,\n",
       " 'also': <gensim.models.keyedvectors.Vocab at 0x2e185e48>,\n",
       " 'only': <gensim.models.keyedvectors.Vocab at 0x2e18cef0>,\n",
       " 'if': <gensim.models.keyedvectors.Vocab at 0x2e185eb8>,\n",
       " 'time': <gensim.models.keyedvectors.Vocab at 0x2e18cf60>,\n",
       " 'some': <gensim.models.keyedvectors.Vocab at 0x2e185f28>,\n",
       " 'people': <gensim.models.keyedvectors.Vocab at 0x2e18cfd0>,\n",
       " 'like': <gensim.models.keyedvectors.Vocab at 0x2e185f98>,\n",
       " 'who': <gensim.models.keyedvectors.Vocab at 0x2e18d080>,\n",
       " 'them': <gensim.models.keyedvectors.Vocab at 0x2e18c048>,\n",
       " 'other': <gensim.models.keyedvectors.Vocab at 0x2e18d0f0>,\n",
       " 'they': <gensim.models.keyedvectors.Vocab at 0x2e18c0b8>,\n",
       " 'when': <gensim.models.keyedvectors.Vocab at 0x2e18d160>,\n",
       " 'Wikipedia': <gensim.models.keyedvectors.Vocab at 0x2e18c128>,\n",
       " 'article': <gensim.models.keyedvectors.Vocab at 0x2e18d198>,\n",
       " 'what': <gensim.models.keyedvectors.Vocab at 0x2e18c198>,\n",
       " '#': <gensim.models.keyedvectors.Vocab at 0x2e18d208>,\n",
       " 'just': <gensim.models.keyedvectors.Vocab at 0x2e18c1d0>,\n",
       " '!': <gensim.models.keyedvectors.Vocab at 0x2e18d278>,\n",
       " 'any': <gensim.models.keyedvectors.Vocab at 0x2e18c208>,\n",
       " 'after': <gensim.models.keyedvectors.Vocab at 0x2e18d2e8>,\n",
       " 'there': <gensim.models.keyedvectors.Vocab at 0x2e18c278>,\n",
       " 'would': <gensim.models.keyedvectors.Vocab at 0x2e18d358>,\n",
       " 'can': <gensim.models.keyedvectors.Vocab at 0x2e18c2e8>,\n",
       " 'In': <gensim.models.keyedvectors.Vocab at 0x2e18d3c8>,\n",
       " 'her': <gensim.models.keyedvectors.Vocab at 0x2e18c358>,\n",
       " 'talk': <gensim.models.keyedvectors.Vocab at 0x2e18d438>,\n",
       " 'use': <gensim.models.keyedvectors.Vocab at 0x2e18c3c8>,\n",
       " 'then': <gensim.models.keyedvectors.Vocab at 0x2e18d4a8>,\n",
       " 'into': <gensim.models.keyedvectors.Vocab at 0x2e18c438>,\n",
       " 'up': <gensim.models.keyedvectors.Vocab at 0x2e18d518>,\n",
       " '...': <gensim.models.keyedvectors.Vocab at 0x2e18c4a8>,\n",
       " 'we': <gensim.models.keyedvectors.Vocab at 0x2e18d588>,\n",
       " 'over': <gensim.models.keyedvectors.Vocab at 0x2e18c518>,\n",
       " 'my': <gensim.models.keyedvectors.Vocab at 0x2e18d5f8>,\n",
       " 'out': <gensim.models.keyedvectors.Vocab at 0x2e18c588>,\n",
       " 'here': <gensim.models.keyedvectors.Vocab at 0x2e18b6d8>,\n",
       " 'now': <gensim.models.keyedvectors.Vocab at 0x2e18d630>,\n",
       " 'because': <gensim.models.keyedvectors.Vocab at 0x2e18b748>,\n",
       " 'do': <gensim.models.keyedvectors.Vocab at 0x2e18d6a0>,\n",
       " 'work': <gensim.models.keyedvectors.Vocab at 0x2e18b7b8>,\n",
       " 'than': <gensim.models.keyedvectors.Vocab at 0x2e18d710>,\n",
       " 'no': <gensim.models.keyedvectors.Vocab at 0x2e18b828>,\n",
       " 'UTC': <gensim.models.keyedvectors.Vocab at 0x2e18d780>,\n",
       " 'me': <gensim.models.keyedvectors.Vocab at 0x2e18b898>,\n",
       " 'A': <gensim.models.keyedvectors.Vocab at 0x2e18d7f0>,\n",
       " 'two': <gensim.models.keyedvectors.Vocab at 0x2e18b8d0>,\n",
       " 'our': <gensim.models.keyedvectors.Vocab at 0x2e18d860>,\n",
       " 'been': <gensim.models.keyedvectors.Vocab at 0x2e18b940>,\n",
       " 'new': <gensim.models.keyedvectors.Vocab at 0x2e18d8d0>,\n",
       " 'where': <gensim.models.keyedvectors.Vocab at 0x2e18b9b0>,\n",
       " '–': <gensim.models.keyedvectors.Vocab at 0x2e18d940>,\n",
       " 'first': <gensim.models.keyedvectors.Vocab at 0x2e18b9e8>,\n",
       " 'such': <gensim.models.keyedvectors.Vocab at 0x2e18d9b0>,\n",
       " 'made': <gensim.models.keyedvectors.Vocab at 0x2e18ba58>,\n",
       " '--': <gensim.models.keyedvectors.Vocab at 0x2e18da20>,\n",
       " 'If': <gensim.models.keyedvectors.Vocab at 0x2e18bac8>,\n",
       " \"'t\": <gensim.models.keyedvectors.Vocab at 0x2e18da90>,\n",
       " 'both': <gensim.models.keyedvectors.Vocab at 0x2e18bb38>,\n",
       " 'before': <gensim.models.keyedvectors.Vocab at 0x2e18db00>,\n",
       " 'way': <gensim.models.keyedvectors.Vocab at 0x2e18bba8>,\n",
       " '1': <gensim.models.keyedvectors.Vocab at 0x2e18db70>,\n",
       " 'through': <gensim.models.keyedvectors.Vocab at 0x2e18bbe0>,\n",
       " 'information': <gensim.models.keyedvectors.Vocab at 0x2e18dbe0>,\n",
       " 'him': <gensim.models.keyedvectors.Vocab at 0x2e18bc18>,\n",
       " 'being': <gensim.models.keyedvectors.Vocab at 0x2e18dc50>,\n",
       " 'many': <gensim.models.keyedvectors.Vocab at 0x2e18bc88>,\n",
       " 'most': <gensim.models.keyedvectors.Vocab at 0x2e18dcc0>,\n",
       " 'But': <gensim.models.keyedvectors.Vocab at 0x2e18bcf8>,\n",
       " 'those': <gensim.models.keyedvectors.Vocab at 0x2e18dd30>,\n",
       " 'while': <gensim.models.keyedvectors.Vocab at 0x2e18bd68>,\n",
       " 'name': <gensim.models.keyedvectors.Vocab at 0x2e18dda0>,\n",
       " 'This': <gensim.models.keyedvectors.Vocab at 0x2e18bdd8>,\n",
       " 'should': <gensim.models.keyedvectors.Vocab at 0x2e18de10>,\n",
       " 'how': <gensim.models.keyedvectors.Vocab at 0x2e18be48>,\n",
       " 'even': <gensim.models.keyedvectors.Vocab at 0x2e18de80>,\n",
       " 'these': <gensim.models.keyedvectors.Vocab at 0x2e18beb8>,\n",
       " 'see': <gensim.models.keyedvectors.Vocab at 0x2e18def0>,\n",
       " 'It': <gensim.models.keyedvectors.Vocab at 0x2e18bf28>,\n",
       " 'make': <gensim.models.keyedvectors.Vocab at 0x2e18df60>,\n",
       " 'may': <gensim.models.keyedvectors.Vocab at 0x2e18bf98>,\n",
       " '2': <gensim.models.keyedvectors.Vocab at 0x2e18dfd0>,\n",
       " 'under': <gensim.models.keyedvectors.Vocab at 0x2e18bfd0>,\n",
       " '—': <gensim.models.keyedvectors.Vocab at 0x2e18b080>,\n",
       " 's': <gensim.models.keyedvectors.Vocab at 0x2e18e048>,\n",
       " 'year': <gensim.models.keyedvectors.Vocab at 0x2e18b0b8>,\n",
       " '10': <gensim.models.keyedvectors.Vocab at 0x2e18e0b8>,\n",
       " 'state': <gensim.models.keyedvectors.Vocab at 0x2e18b128>,\n",
       " 'since': <gensim.models.keyedvectors.Vocab at 0x2e18e128>,\n",
       " 'years': <gensim.models.keyedvectors.Vocab at 0x2e18b198>,\n",
       " '”': <gensim.models.keyedvectors.Vocab at 0x2e18e198>,\n",
       " 'edit': <gensim.models.keyedvectors.Vocab at 0x2e18b1d0>,\n",
       " 'right': <gensim.models.keyedvectors.Vocab at 0x2e18e208>,\n",
       " 'did': <gensim.models.keyedvectors.Vocab at 0x2e18b240>,\n",
       " 'used': <gensim.models.keyedvectors.Vocab at 0x2e18e278>,\n",
       " 'government': <gensim.models.keyedvectors.Vocab at 0x2e18b2b0>,\n",
       " 'case': <gensim.models.keyedvectors.Vocab at 0x2e18e2b0>,\n",
       " 'articles': <gensim.models.keyedvectors.Vocab at 0x2e18b320>,\n",
       " 'get': <gensim.models.keyedvectors.Vocab at 0x2e18e2e8>,\n",
       " 'between': <gensim.models.keyedvectors.Vocab at 0x2e18b390>,\n",
       " 'she': <gensim.models.keyedvectors.Vocab at 0x2e18e358>,\n",
       " '“': <gensim.models.keyedvectors.Vocab at 0x2e18b400>,\n",
       " '}': <gensim.models.keyedvectors.Vocab at 0x2e18e390>,\n",
       " 'think': <gensim.models.keyedvectors.Vocab at 0x2e18b438>,\n",
       " '20': <gensim.models.keyedvectors.Vocab at 0x2e18e400>,\n",
       " 'during': <gensim.models.keyedvectors.Vocab at 0x2e18b4a8>,\n",
       " 'another': <gensim.models.keyedvectors.Vocab at 0x2e18e470>,\n",
       " 'And': <gensim.models.keyedvectors.Vocab at 0x2e18b518>,\n",
       " '11': <gensim.models.keyedvectors.Vocab at 0x2e18e4e0>,\n",
       " '3': <gensim.models.keyedvectors.Vocab at 0x2e18b588>,\n",
       " 'could': <gensim.models.keyedvectors.Vocab at 0x2e18e518>,\n",
       " 'using': <gensim.models.keyedvectors.Vocab at 0x2e18b5f8>,\n",
       " 'He': <gensim.models.keyedvectors.Vocab at 0x2e18e588>,\n",
       " 'without': <gensim.models.keyedvectors.Vocab at 0x2e18b668>,\n",
       " 'good': <gensim.models.keyedvectors.Vocab at 0x2e18e5f8>,\n",
       " 'place': <gensim.models.keyedvectors.Vocab at 0x2e18e748>,\n",
       " 'support': <gensim.models.keyedvectors.Vocab at 0x2e18e668>,\n",
       " 'back': <gensim.models.keyedvectors.Vocab at 0x2e18e7b8>,\n",
       " 'again': <gensim.models.keyedvectors.Vocab at 0x2e18e6d8>,\n",
       " 'against': <gensim.models.keyedvectors.Vocab at 0x2e18e828>,\n",
       " '12': <gensim.models.keyedvectors.Vocab at 0x2e1817b8>,\n",
       " '15': <gensim.models.keyedvectors.Vocab at 0x2e18e898>,\n",
       " 'system': <gensim.models.keyedvectors.Vocab at 0x2e181828>,\n",
       " 'called': <gensim.models.keyedvectors.Vocab at 0x2e18e908>,\n",
       " 'much': <gensim.models.keyedvectors.Vocab at 0x2e181898>,\n",
       " 'still': <gensim.models.keyedvectors.Vocab at 0x2e18e978>,\n",
       " '18': <gensim.models.keyedvectors.Vocab at 0x2e181908>,\n",
       " '%': <gensim.models.keyedvectors.Vocab at 0x2e18e9e8>,\n",
       " '16': <gensim.models.keyedvectors.Vocab at 0x2e181940>,\n",
       " 'change': <gensim.models.keyedvectors.Vocab at 0x2e18ea58>,\n",
       " 'say': <gensim.models.keyedvectors.Vocab at 0x2e1819b0>,\n",
       " 'point': <gensim.models.keyedvectors.Vocab at 0x2e18eac8>,\n",
       " 'us': <gensim.models.keyedvectors.Vocab at 0x2e181a20>,\n",
       " 'group': <gensim.models.keyedvectors.Vocab at 0x2e18eb38>,\n",
       " 'day': <gensim.models.keyedvectors.Vocab at 0x2e181a90>,\n",
       " 'three': <gensim.models.keyedvectors.Vocab at 0x2e18eba8>,\n",
       " '17': <gensim.models.keyedvectors.Vocab at 0x2e181b00>,\n",
       " '14': <gensim.models.keyedvectors.Vocab at 0x2e18ec18>,\n",
       " 'know': <gensim.models.keyedvectors.Vocab at 0x2e181b70>,\n",
       " 'help': <gensim.models.keyedvectors.Vocab at 0x2e18ec88>,\n",
       " 'As': <gensim.models.keyedvectors.Vocab at 0x2e181be0>,\n",
       " 'last': <gensim.models.keyedvectors.Vocab at 0x2e18ecf8>,\n",
       " '21': <gensim.models.keyedvectors.Vocab at 0x2e181c50>,\n",
       " 'each': <gensim.models.keyedvectors.Vocab at 0x2e18ed68>,\n",
       " 'around': <gensim.models.keyedvectors.Vocab at 0x2e181cc0>,\n",
       " '2008': <gensim.models.keyedvectors.Vocab at 0x2e18edd8>,\n",
       " 'edits': <gensim.models.keyedvectors.Vocab at 0x2e181d30>,\n",
       " 'says': <gensim.models.keyedvectors.Vocab at 0x2e18ee48>,\n",
       " '’': <gensim.models.keyedvectors.Vocab at 0x2e181da0>,\n",
       " '13': <gensim.models.keyedvectors.Vocab at 0x2e18ee80>,\n",
       " '19': <gensim.models.keyedvectors.Vocab at 0x2e181e10>,\n",
       " 'life': <gensim.models.keyedvectors.Vocab at 0x2e18eef0>,\n",
       " 'link': <gensim.models.keyedvectors.Vocab at 0x2e181e80>,\n",
       " '22': <gensim.models.keyedvectors.Vocab at 0x2e18ef60>,\n",
       " 'too': <gensim.models.keyedvectors.Vocab at 0x2e181ef0>,\n",
       " 'left': <gensim.models.keyedvectors.Vocab at 0x2e18efd0>,\n",
       " '2009': <gensim.models.keyedvectors.Vocab at 0x2e181f60>,\n",
       " 'very': <gensim.models.keyedvectors.Vocab at 0x2e181080>,\n",
       " 'students': <gensim.models.keyedvectors.Vocab at 0x2e181fd0>,\n",
       " 'team': <gensim.models.keyedvectors.Vocab at 0x2e1810b8>,\n",
       " 'sources': <gensim.models.keyedvectors.Vocab at 0x2e18a080>,\n",
       " 'off': <gensim.models.keyedvectors.Vocab at 0x2e181128>,\n",
       " '2007': <gensim.models.keyedvectors.Vocab at 0x2e18a0f0>,\n",
       " 'well': <gensim.models.keyedvectors.Vocab at 0x2e181198>,\n",
       " '4': <gensim.models.keyedvectors.Vocab at 0x2e18a160>,\n",
       " 'down': <gensim.models.keyedvectors.Vocab at 0x2e1811d0>,\n",
       " 'section': <gensim.models.keyedvectors.Vocab at 0x2e18a1d0>,\n",
       " 'take': <gensim.models.keyedvectors.Vocab at 0x2e181240>,\n",
       " 'does': <gensim.models.keyedvectors.Vocab at 0x2e18a240>,\n",
       " 'really': <gensim.models.keyedvectors.Vocab at 0x2e1812b0>,\n",
       " '23': <gensim.models.keyedvectors.Vocab at 0x2e18a2b0>,\n",
       " 'discussion': <gensim.models.keyedvectors.Vocab at 0x2e181320>,\n",
       " 'either': <gensim.models.keyedvectors.Vocab at 0x2e18a2e8>,\n",
       " 'show': <gensim.models.keyedvectors.Vocab at 0x2e181390>,\n",
       " 'public': <gensim.models.keyedvectors.Vocab at 0x2e18a358>,\n",
       " '2010': <gensim.models.keyedvectors.Vocab at 0x2e181400>,\n",
       " 'including': <gensim.models.keyedvectors.Vocab at 0x2e18a3c8>,\n",
       " 'set': <gensim.models.keyedvectors.Vocab at 0x2e181438>,\n",
       " 'game': <gensim.models.keyedvectors.Vocab at 0x2e18a438>,\n",
       " 'policy': <gensim.models.keyedvectors.Vocab at 0x2e1814a8>,\n",
       " 'later': <gensim.models.keyedvectors.Vocab at 0x2e18a4a8>,\n",
       " 'need': <gensim.models.keyedvectors.Vocab at 0x2e181518>,\n",
       " 'program': <gensim.models.keyedvectors.Vocab at 0x2e18a518>,\n",
       " 'others': <gensim.models.keyedvectors.Vocab at 0x2e181588>,\n",
       " 'source': <gensim.models.keyedvectors.Vocab at 0x2e18a588>,\n",
       " 'research': <gensim.models.keyedvectors.Vocab at 0x2e1815f8>,\n",
       " '+': <gensim.models.keyedvectors.Vocab at 0x2e18a5c0>,\n",
       " 'area': <gensim.models.keyedvectors.Vocab at 0x2e181630>,\n",
       " 'children': <gensim.models.keyedvectors.Vocab at 0x2e18a630>,\n",
       " 'why': <gensim.models.keyedvectors.Vocab at 0x2e181668>,\n",
       " 'family': <gensim.models.keyedvectors.Vocab at 0x2e18a6a0>,\n",
       " 'making': <gensim.models.keyedvectors.Vocab at 0x2e1816d8>,\n",
       " 'deletion': <gensim.models.keyedvectors.Vocab at 0x2e18a710>,\n",
       " 'something': <gensim.models.keyedvectors.Vocab at 0x2e181710>,\n",
       " 'content': <gensim.models.keyedvectors.Vocab at 0x2e18a748>,\n",
       " 'school': <gensim.models.keyedvectors.Vocab at 0x2e18a7f0>,\n",
       " 'added': <gensim.models.keyedvectors.Vocab at 0x2e18a7b8>,\n",
       " 'found': <gensim.models.keyedvectors.Vocab at 0x2e18a860>,\n",
       " 'until': <gensim.models.keyedvectors.Vocab at 0x2e183860>,\n",
       " 'within': <gensim.models.keyedvectors.Vocab at 0x2e18a8d0>,\n",
       " 'following': <gensim.models.keyedvectors.Vocab at 0x2e1838d0>,\n",
       " 'better': <gensim.models.keyedvectors.Vocab at 0x2e18a908>,\n",
       " '5': <gensim.models.keyedvectors.Vocab at 0x2e183940>,\n",
       " 'process': <gensim.models.keyedvectors.Vocab at 0x2e18a940>,\n",
       " '&': <gensim.models.keyedvectors.Vocab at 0x2e1839b0>,\n",
       " 'history': <gensim.models.keyedvectors.Vocab at 0x2e18a978>,\n",
       " 'You': <gensim.models.keyedvectors.Vocab at 0x2e183a20>,\n",
       " 'given': <gensim.models.keyedvectors.Vocab at 0x2e18a9e8>,\n",
       " '2011': <gensim.models.keyedvectors.Vocab at 0x2e183a90>,\n",
       " 'question': <gensim.models.keyedvectors.Vocab at 0x2e18aa58>,\n",
       " 'women': <gensim.models.keyedvectors.Vocab at 0x2e183ac8>,\n",
       " 'For': <gensim.models.keyedvectors.Vocab at 0x2e18aac8>,\n",
       " 'country': <gensim.models.keyedvectors.Vocab at 0x2e183b38>,\n",
       " 'company': <gensim.models.keyedvectors.Vocab at 0x2e18ab38>,\n",
       " 'data': <gensim.models.keyedvectors.Vocab at 0x2e183ba8>,\n",
       " 'part': <gensim.models.keyedvectors.Vocab at 0x2e18aba8>,\n",
       " 'include': <gensim.models.keyedvectors.Vocab at 0x2e183c18>,\n",
       " 'site': <gensim.models.keyedvectors.Vocab at 0x2e18ac18>,\n",
       " 'pages': <gensim.models.keyedvectors.Vocab at 0x2e183c88>,\n",
       " 'home': <gensim.models.keyedvectors.Vocab at 0x2e18ac88>,\n",
       " 'business': <gensim.models.keyedvectors.Vocab at 0x2e183cf8>,\n",
       " '$': <gensim.models.keyedvectors.Vocab at 0x2e18acc0>,\n",
       " '2006': <gensim.models.keyedvectors.Vocab at 0x2e183d30>,\n",
       " 'having': <gensim.models.keyedvectors.Vocab at 0x2e18ad30>,\n",
       " 'American': <gensim.models.keyedvectors.Vocab at 0x2e183da0>,\n",
       " '2012': <gensim.models.keyedvectors.Vocab at 0x2e18ad68>,\n",
       " 'put': <gensim.models.keyedvectors.Vocab at 0x2e183e10>,\n",
       " 'issue': <gensim.models.keyedvectors.Vocab at 0x2e18add8>,\n",
       " 'different': <gensim.models.keyedvectors.Vocab at 0x2e183e80>,\n",
       " 'world': <gensim.models.keyedvectors.Vocab at 0x2e18ae10>,\n",
       " 'U.S.': <gensim.models.keyedvectors.Vocab at 0x2e183ef0>,\n",
       " 'New': <gensim.models.keyedvectors.Vocab at 0x2e18ae80>,\n",
       " 'things': <gensim.models.keyedvectors.Vocab at 0x2e183f60>,\n",
       " 'list': <gensim.models.keyedvectors.Vocab at 0x2e18aef0>,\n",
       " 'power': <gensim.models.keyedvectors.Vocab at 0x2e183fd0>,\n",
       " 'above': <gensim.models.keyedvectors.Vocab at 0x2e18af60>,\n",
       " 'best': <gensim.models.keyedvectors.Vocab at 0x2e189080>,\n",
       " 'future': <gensim.models.keyedvectors.Vocab at 0x2e18afd0>,\n",
       " 'read': <gensim.models.keyedvectors.Vocab at 0x2e1890f0>,\n",
       " 'report': <gensim.models.keyedvectors.Vocab at 0x2e183080>,\n",
       " 'project': <gensim.models.keyedvectors.Vocab at 0x2e189160>,\n",
       " 'find': <gensim.models.keyedvectors.Vocab at 0x2e1830f0>,\n",
       " 'problem': <gensim.models.keyedvectors.Vocab at 0x2e1891d0>,\n",
       " 'book': <gensim.models.keyedvectors.Vocab at 0x2e183160>,\n",
       " 'though': <gensim.models.keyedvectors.Vocab at 0x2e189240>,\n",
       " 'law': <gensim.models.keyedvectors.Vocab at 0x2e1831d0>,\n",
       " 'today': <gensim.models.keyedvectors.Vocab at 0x2e1892b0>,\n",
       " 'We': <gensim.models.keyedvectors.Vocab at 0x2e183240>,\n",
       " 'four': <gensim.models.keyedvectors.Vocab at 0x2e189320>,\n",
       " 'links': <gensim.models.keyedvectors.Vocab at 0x2e1832b0>,\n",
       " 'community': <gensim.models.keyedvectors.Vocab at 0x2e189390>,\n",
       " 'several': <gensim.models.keyedvectors.Vocab at 0x2e1832e8>,\n",
       " 'film': <gensim.models.keyedvectors.Vocab at 0x2e189400>,\n",
       " 'So': <gensim.models.keyedvectors.Vocab at 0x2e183358>,\n",
       " '30': <gensim.models.keyedvectors.Vocab at 0x2e189470>,\n",
       " 'free': <gensim.models.keyedvectors.Vocab at 0x2e1833c8>,\n",
       " 'money': <gensim.models.keyedvectors.Vocab at 0x2e1894e0>,\n",
       " 'line': <gensim.models.keyedvectors.Vocab at 0x2e183438>,\n",
       " 'service': <gensim.models.keyedvectors.Vocab at 0x2e189550>,\n",
       " 'actually': <gensim.models.keyedvectors.Vocab at 0x2e1834a8>,\n",
       " '2013': <gensim.models.keyedvectors.Vocab at 0x2e189588>,\n",
       " 'second': <gensim.models.keyedvectors.Vocab at 0x2e183518>,\n",
       " 'go': <gensim.models.keyedvectors.Vocab at 0x2e1895f8>,\n",
       " 'deleted': <gensim.models.keyedvectors.Vocab at 0x2e183588>,\n",
       " 'editing': <gensim.models.keyedvectors.Vocab at 0x2e189668>,\n",
       " 'often': <gensim.models.keyedvectors.Vocab at 0x2e1835f8>,\n",
       " 'every': <gensim.models.keyedvectors.Vocab at 0x2e1896d8>,\n",
       " '00': <gensim.models.keyedvectors.Vocab at 0x2e183668>,\n",
       " 'course': <gensim.models.keyedvectors.Vocab at 0x2e189748>,\n",
       " 'season': <gensim.models.keyedvectors.Vocab at 0x2e1836d8>,\n",
       " 'possible': <gensim.models.keyedvectors.Vocab at 0x2e1897b8>,\n",
       " 'That': <gensim.models.keyedvectors.Vocab at 0x2e183710>,\n",
       " 'US': <gensim.models.keyedvectors.Vocab at 0x2e189828>,\n",
       " 'war': <gensim.models.keyedvectors.Vocab at 0x2e183780>,\n",
       " 'title': <gensim.models.keyedvectors.Vocab at 0x2e189940>,\n",
       " 'local': <gensim.models.keyedvectors.Vocab at 0x2e1837f0>,\n",
       " 'once': <gensim.models.keyedvectors.Vocab at 0x2e189a20>,\n",
       " 'study': <gensim.models.keyedvectors.Vocab at 0x2e1898d0>,\n",
       " 'whether': <gensim.models.keyedvectors.Vocab at 0x2e189b70>,\n",
       " 'University': <gensim.models.keyedvectors.Vocab at 0x2e189978>,\n",
       " 'yet': <gensim.models.keyedvectors.Vocab at 0x2e189ba8>,\n",
       " '6': <gensim.models.keyedvectors.Vocab at 0x2e189a58>,\n",
       " '2014': <gensim.models.keyedvectors.Vocab at 0x2e189c50>,\n",
       " 'already': <gensim.models.keyedvectors.Vocab at 0x2e189b00>,\n",
       " 'issues': <gensim.models.keyedvectors.Vocab at 0x2e189d30>,\n",
       " 'got': <gensim.models.keyedvectors.Vocab at 0x2e189be0>,\n",
       " 'man': <gensim.models.keyedvectors.Vocab at 0x2e189dd8>,\n",
       " 'Please': <gensim.models.keyedvectors.Vocab at 0x2e189cc0>,\n",
       " 'services': <gensim.models.keyedvectors.Vocab at 0x2e189eb8>,\n",
       " 'look': <gensim.models.keyedvectors.Vocab at 0x2e189cf8>,\n",
       " 'questions': <gensim.models.keyedvectors.Vocab at 0x2e189f98>,\n",
       " 'On': <gensim.models.keyedvectors.Vocab at 0x2e189da0>,\n",
       " 'When': <gensim.models.keyedvectors.Vocab at 0x2e1840b8>,\n",
       " 'removed': <gensim.models.keyedvectors.Vocab at 0x2e189e80>,\n",
       " 'men': <gensim.models.keyedvectors.Vocab at 0x2e184160>,\n",
       " 'They': <gensim.models.keyedvectors.Vocab at 0x2e189f60>,\n",
       " 'form': <gensim.models.keyedvectors.Vocab at 0x2e184208>,\n",
       " 'water': <gensim.models.keyedvectors.Vocab at 0x2e184048>,\n",
       " 'view': <gensim.models.keyedvectors.Vocab at 0x2e1842b0>,\n",
       " 'English': <gensim.models.keyedvectors.Vocab at 0x2e184198>,\n",
       " '25': <gensim.models.keyedvectors.Vocab at 0x2e184358>,\n",
       " 'review': <gensim.models.keyedvectors.Vocab at 0x2e1842e8>,\n",
       " 'person': <gensim.models.keyedvectors.Vocab at 0x2e1844a8>,\n",
       " 'important': <gensim.models.keyedvectors.Vocab at 0x2e1843c8>,\n",
       " 'changes': <gensim.models.keyedvectors.Vocab at 0x2e1844e0>,\n",
       " 'further': <gensim.models.keyedvectors.Vocab at 0x2e184470>,\n",
       " 'What': <gensim.models.keyedvectors.Vocab at 0x2e1845c0>,\n",
       " 'own': <gensim.models.keyedvectors.Vocab at 0x2e184550>,\n",
       " 'States': <gensim.models.keyedvectors.Vocab at 0x2e1846a0>,\n",
       " 'present': <gensim.models.keyedvectors.Vocab at 0x2e184630>,\n",
       " 'welcome': <gensim.models.keyedvectors.Vocab at 0x2e184780>,\n",
       " 'might': <gensim.models.keyedvectors.Vocab at 0x2e184710>,\n",
       " 'development': <gensim.models.keyedvectors.Vocab at 0x2e184828>,\n",
       " 'done': <gensim.models.keyedvectors.Vocab at 0x2e1847b8>,\n",
       " 'must': <gensim.models.keyedvectors.Vocab at 0x2e184908>,\n",
       " 'someone': <gensim.models.keyedvectors.Vocab at 0x2e184898>,\n",
       " 'told': <gensim.models.keyedvectors.Vocab at 0x2e1849e8>,\n",
       " 'early': <gensim.models.keyedvectors.Vocab at 0x2e184978>,\n",
       " 'British': <gensim.models.keyedvectors.Vocab at 0x2e184ac8>,\n",
       " 'material': <gensim.models.keyedvectors.Vocab at 0x2e184a58>,\n",
       " 'position': <gensim.models.keyedvectors.Vocab at 0x2e184b70>,\n",
       " 'means': <gensim.models.keyedvectors.Vocab at 0x2e184b00>,\n",
       " 'created': <gensim.models.keyedvectors.Vocab at 0x2e184c50>,\n",
       " 'please': <gensim.models.keyedvectors.Vocab at 0x2e184be0>,\n",
       " 'thing': <gensim.models.keyedvectors.Vocab at 0x2e184d30>,\n",
       " 'text': <gensim.models.keyedvectors.Vocab at 0x2e184cc0>,\n",
       " 'high': <gensim.models.keyedvectors.Vocab at 0x2e184e10>,\n",
       " 'itself': <gensim.models.keyedvectors.Vocab at 0x2e184da0>,\n",
       " 'long': <gensim.models.keyedvectors.Vocab at 0x2e184ef0>,\n",
       " 'number': <gensim.models.keyedvectors.Vocab at 0x2e184e80>,\n",
       " 'started': <gensim.models.keyedvectors.Vocab at 0x2e184fd0>,\n",
       " '2015': <gensim.models.keyedvectors.Vocab at 0x2e184f60>,\n",
       " 'won': <gensim.models.keyedvectors.Vocab at 0x2e1920f0>,\n",
       " '24': <gensim.models.keyedvectors.Vocab at 0x2e192080>,\n",
       " 'great': <gensim.models.keyedvectors.Vocab at 0x2e1921d0>,\n",
       " 'start': <gensim.models.keyedvectors.Vocab at 0x2e192160>,\n",
       " 'experience': <gensim.models.keyedvectors.Vocab at 0x2e1922b0>,\n",
       " 'China': <gensim.models.keyedvectors.Vocab at 0x2e192198>,\n",
       " 'party': <gensim.models.keyedvectors.Vocab at 0x2e192358>,\n",
       " 'May': <gensim.models.keyedvectors.Vocab at 0x2e192240>,\n",
       " 'current': <gensim.models.keyedvectors.Vocab at 0x2e192400>,\n",
       " 'building': <gensim.models.keyedvectors.Vocab at 0x2e192390>,\n",
       " 'play': <gensim.models.keyedvectors.Vocab at 0x2e1924a8>,\n",
       " '7': <gensim.models.keyedvectors.Vocab at 0x2e192470>,\n",
       " 'always': <gensim.models.keyedvectors.Vocab at 0x2e1924e0>,\n",
       " 'anything': <gensim.models.keyedvectors.Vocab at 0x2e192550>,\n",
       " 'want': <gensim.models.keyedvectors.Vocab at 0x2e192588>,\n",
       " 'fact': <gensim.models.keyedvectors.Vocab at 0x2e192630>,\n",
       " 'series': <gensim.models.keyedvectors.Vocab at 0x2e192668>,\n",
       " 'old': <gensim.models.keyedvectors.Vocab at 0x2e192710>,\n",
       " 'included': <gensim.models.keyedvectors.Vocab at 0x2e192748>,\n",
       " 'provide': <gensim.models.keyedvectors.Vocab at 0x2e1927b8>,\n",
       " 'among': <gensim.models.keyedvectors.Vocab at 0x2e192828>,\n",
       " '2005': <gensim.models.keyedvectors.Vocab at 0x2e192898>,\n",
       " 'story': <gensim.models.keyedvectors.Vocab at 0x2e192908>,\n",
       " 'police': <gensim.models.keyedvectors.Vocab at 0x2e192978>,\n",
       " 'There': <gensim.models.keyedvectors.Vocab at 0x2e1929e8>,\n",
       " 'media': <gensim.models.keyedvectors.Vocab at 0x2e192a58>,\n",
       " 'days': <gensim.models.keyedvectors.Vocab at 0x2e192ac8>,\n",
       " 'never': <gensim.models.keyedvectors.Vocab at 0x2e192b38>,\n",
       " 'probably': <gensim.models.keyedvectors.Vocab at 0x2e192ba8>,\n",
       " 'No': <gensim.models.keyedvectors.Vocab at 0x2e192b70>,\n",
       " 'add': <gensim.models.keyedvectors.Vocab at 0x2e192c88>,\n",
       " 'next': <gensim.models.keyedvectors.Vocab at 0x2e192c50>,\n",
       " 'death': <gensim.models.keyedvectors.Vocab at 0x2e192d68>,\n",
       " 'took': <gensim.models.keyedvectors.Vocab at 0x2e192d30>,\n",
       " 'market': <gensim.models.keyedvectors.Vocab at 0x2e192e48>,\n",
       " 'city': <gensim.models.keyedvectors.Vocab at 0x2e192e10>,\n",
       " 'field': <gensim.models.keyedvectors.Vocab at 0x2e192f28>,\n",
       " 'music': <gensim.models.keyedvectors.Vocab at 0x2e192ef0>,\n",
       " 'same': <gensim.models.keyedvectors.Vocab at 0x2e195048>,\n",
       " 'working': <gensim.models.keyedvectors.Vocab at 0x2e192f98>,\n",
       " 'language': <gensim.models.keyedvectors.Vocab at 0x2e195128>,\n",
       " 'problems': <gensim.models.keyedvectors.Vocab at 0x2e195080>,\n",
       " 'needs': <gensim.models.keyedvectors.Vocab at 0x2e1951d0>,\n",
       " 'reverted': <gensim.models.keyedvectors.Vocab at 0x2e195160>,\n",
       " 'England': <gensim.models.keyedvectors.Vocab at 0x2e195278>,\n",
       " 'less': <gensim.models.keyedvectors.Vocab at 0x2e195208>,\n",
       " 'control': <gensim.models.keyedvectors.Vocab at 0x2e195358>,\n",
       " 'London': <gensim.models.keyedvectors.Vocab at 0x2e1952e8>,\n",
       " 'run': <gensim.models.keyedvectors.Vocab at 0x2e195438>,\n",
       " 'image': <gensim.models.keyedvectors.Vocab at 0x2e1953c8>,\n",
       " 'record': <gensim.models.keyedvectors.Vocab at 0x2e195518>,\n",
       " 'believe': <gensim.models.keyedvectors.Vocab at 0x2e1954a8>,\n",
       " 'former': <gensim.models.keyedvectors.Vocab at 0x2e1955f8>,\n",
       " 'comment': <gensim.models.keyedvectors.Vocab at 0x2e195588>,\n",
       " 'general': <gensim.models.keyedvectors.Vocab at 0x2e195748>,\n",
       " 'don': <gensim.models.keyedvectors.Vocab at 0x2e195630>,\n",
       " 'end': <gensim.models.keyedvectors.Vocab at 0x2e195828>,\n",
       " 'After': <gensim.models.keyedvectors.Vocab at 0x2e1956d8>,\n",
       " 'All': <gensim.models.keyedvectors.Vocab at 0x2e195908>,\n",
       " 'education': <gensim.models.keyedvectors.Vocab at 0x2e1957b8>,\n",
       " 'recent': <gensim.models.keyedvectors.Vocab at 0x2e195940>,\n",
       " 'little': <gensim.models.keyedvectors.Vocab at 0x2e195898>,\n",
       " 'political': <gensim.models.keyedvectors.Vocab at 0x2e195a20>,\n",
       " 'known': <gensim.models.keyedvectors.Vocab at 0x2e1958d0>,\n",
       " 'open': <gensim.models.keyedvectors.Vocab at 0x2e195b00>,\n",
       " 'move': <gensim.models.keyedvectors.Vocab at 0x2e1959b0>,\n",
       " 'evidence': <gensim.models.keyedvectors.Vocab at 0x2e195be0>,\n",
       " 'thought': <gensim.models.keyedvectors.Vocab at 0x2e195a58>,\n",
       " 'test': <gensim.models.keyedvectors.Vocab at 0x2e195cc0>,\n",
       " 'message': <gensim.models.keyedvectors.Vocab at 0x2e195b38>,\n",
       " '8': <gensim.models.keyedvectors.Vocab at 0x2e195da0>,\n",
       " 'rather': <gensim.models.keyedvectors.Vocab at 0x2e195b70>,\n",
       " 'members': <gensim.models.keyedvectors.Vocab at 0x2e195ef0>,\n",
       " 'simply': <gensim.models.keyedvectors.Vocab at 0x2e195c50>,\n",
       " 'John': <gensim.models.keyedvectors.Vocab at 0x2e195f98>,\n",
       " 'week': <gensim.models.keyedvectors.Vocab at 0x2e195d30>,\n",
       " 'State': <gensim.models.keyedvectors.Vocab at 0x2e1930b8>,\n",
       " 'real': <gensim.models.keyedvectors.Vocab at 0x2e195e10>,\n",
       " 'small': <gensim.models.keyedvectors.Vocab at 0x2e193198>,\n",
       " 'user': <gensim.models.keyedvectors.Vocab at 0x2e195eb8>,\n",
       " 'available': <gensim.models.keyedvectors.Vocab at 0x2e193240>,\n",
       " 'reason': <gensim.models.keyedvectors.Vocab at 0x2e195f28>,\n",
       " 'staff': <gensim.models.keyedvectors.Vocab at 0x2e193320>,\n",
       " 'account': <gensim.models.keyedvectors.Vocab at 0x2e193048>,\n",
       " 'clear': <gensim.models.keyedvectors.Vocab at 0x2e193470>,\n",
       " 'Image': <gensim.models.keyedvectors.Vocab at 0x2e193128>,\n",
       " 'saying': <gensim.models.keyedvectors.Vocab at 0x2e193550>,\n",
       " 'plan': <gensim.models.keyedvectors.Vocab at 0x2e193278>,\n",
       " 'words': <gensim.models.keyedvectors.Vocab at 0x2e193668>,\n",
       " 'works': <gensim.models.keyedvectors.Vocab at 0x2e193358>,\n",
       " 'changed': <gensim.models.keyedvectors.Vocab at 0x2e193748>,\n",
       " 'doing': <gensim.models.keyedvectors.Vocab at 0x2e193400>,\n",
       " 'lead': <gensim.models.keyedvectors.Vocab at 0x2e193828>,\n",
       " 'million': <gensim.models.keyedvectors.Vocab at 0x2e1934a8>,\n",
       " 'house': <gensim.models.keyedvectors.Vocab at 0x2e193908>,\n",
       " 'give': <gensim.models.keyedvectors.Vocab at 0x2e193588>,\n",
       " 'term': <gensim.models.keyedvectors.Vocab at 0x2e1939e8>,\n",
       " 'full': <gensim.models.keyedvectors.Vocab at 0x2e193630>,\n",
       " '2016': <gensim.models.keyedvectors.Vocab at 0x2e193ac8>,\n",
       " 'keep': <gensim.models.keyedvectors.Vocab at 0x2e193710>,\n",
       " 'website': <gensim.models.keyedvectors.Vocab at 0x2e193ba8>,\n",
       " 'top': <gensim.models.keyedvectors.Vocab at 0x2e1937f0>,\n",
       " 'March': <gensim.models.keyedvectors.Vocab at 0x2e193c88>,\n",
       " 'enough': <gensim.models.keyedvectors.Vocab at 0x2e1938d0>,\n",
       " 'themselves': <gensim.models.keyedvectors.Vocab at 0x2e193d68>,\n",
       " 'action': <gensim.models.keyedvectors.Vocab at 0x2e193940>,\n",
       " '~': <gensim.models.keyedvectors.Vocab at 0x2e193e48>,\n",
       " ']': <gensim.models.keyedvectors.Vocab at 0x2e193978>,\n",
       " 'come': <gensim.models.keyedvectors.Vocab at 0x2e193ef0>,\n",
       " 'provided': <gensim.models.keyedvectors.Vocab at 0x2e193a58>,\n",
       " 'five': <gensim.models.keyedvectors.Vocab at 0x2e193f28>,\n",
       " 'near': <gensim.models.keyedvectors.Vocab at 0x2e193b38>,\n",
       " 'job': <gensim.models.keyedvectors.Vocab at 0x2e199048>,\n",
       " 'feel': <gensim.models.keyedvectors.Vocab at 0x2e193c18>,\n",
       " 'points': <gensim.models.keyedvectors.Vocab at 0x2e199198>,\n",
       " 'One': <gensim.models.keyedvectors.Vocab at 0x2e193cf8>,\n",
       " 'ever': <gensim.models.keyedvectors.Vocab at 0x2e199278>,\n",
       " 'leave': <gensim.models.keyedvectors.Vocab at 0x2e193dd8>,\n",
       " 'results': <gensim.models.keyedvectors.Vocab at 0x2e199358>,\n",
       " 'technology': <gensim.models.keyedvectors.Vocab at 0x2e193eb8>,\n",
       " 'At': <gensim.models.keyedvectors.Vocab at 0x2e199390>,\n",
       " 'date': <gensim.models.keyedvectors.Vocab at 0x2e193f98>,\n",
       " '29': <gensim.models.keyedvectors.Vocab at 0x2e199470>,\n",
       " 'Thank': <gensim.models.keyedvectors.Vocab at 0x2e1990b8>,\n",
       " 'With': <gensim.models.keyedvectors.Vocab at 0x2e199550>,\n",
       " 'subject': <gensim.models.keyedvectors.Vocab at 0x2e199160>,\n",
       " '9': <gensim.models.keyedvectors.Vocab at 0x2e199630>,\n",
       " '26': <gensim.models.keyedvectors.Vocab at 0x2e199208>,\n",
       " '27': <gensim.models.keyedvectors.Vocab at 0x2e199710>,\n",
       " 'became': <gensim.models.keyedvectors.Vocab at 0x2e1992e8>,\n",
       " 'times': <gensim.models.keyedvectors.Vocab at 0x2e1997f0>,\n",
       " '28': <gensim.models.keyedvectors.Vocab at 0x2e1993c8>,\n",
       " 'vote': <gensim.models.keyedvectors.Vocab at 0x2e1998d0>,\n",
       " 'countries': <gensim.models.keyedvectors.Vocab at 0x2e1994a8>,\n",
       " 'going': <gensim.models.keyedvectors.Vocab at 0x2e199978>,\n",
       " 'seen': <gensim.models.keyedvectors.Vocab at 0x2e199588>,\n",
       " 'outside': <gensim.models.keyedvectors.Vocab at 0x2e199a20>,\n",
       " 'taking': <gensim.models.keyedvectors.Vocab at 0x2e199668>,\n",
       " 'level': <gensim.models.keyedvectors.Vocab at 0x2e199b00>,\n",
       " 'word': <gensim.models.keyedvectors.Vocab at 0x2e199748>,\n",
       " 'national': <gensim.models.keyedvectors.Vocab at 0x2e199be0>,\n",
       " 'event': <gensim.models.keyedvectors.Vocab at 0x2e199780>,\n",
       " 'WP': <gensim.models.keyedvectors.Vocab at 0x2e199cc0>,\n",
       " 'health': <gensim.models.keyedvectors.Vocab at 0x2e199860>,\n",
       " 'call': <gensim.models.keyedvectors.Vocab at 0x2e199da0>,\n",
       " 'along': <gensim.models.keyedvectors.Vocab at 0x2e199940>,\n",
       " 'class': <gensim.models.keyedvectors.Vocab at 0x2e199e48>,\n",
       " 'America': <gensim.models.keyedvectors.Vocab at 0x2e199a90>,\n",
       " 'January': <gensim.models.keyedvectors.Vocab at 0x2e199f28>,\n",
       " 'large': <gensim.models.keyedvectors.Vocab at 0x2e199b70>,\n",
       " 'programs': <gensim.models.keyedvectors.Vocab at 0x2e19c048>,\n",
       " 'Talk': <gensim.models.keyedvectors.Vocab at 0x2e199ba8>,\n",
       " 'April': <gensim.models.keyedvectors.Vocab at 0x2e19c0f0>,\n",
       " 'major': <gensim.models.keyedvectors.Vocab at 0x2e199c88>,\n",
       " 'UK': <gensim.models.keyedvectors.Vocab at 0x2e19c1d0>,\n",
       " 'court': <gensim.models.keyedvectors.Vocab at 0x2e199d68>,\n",
       " 'together': <gensim.models.keyedvectors.Vocab at 0x2e19c2b0>,\n",
       " 'vandalism': <gensim.models.keyedvectors.Vocab at 0x2e199e10>,\n",
       " 'period': <gensim.models.keyedvectors.Vocab at 0x2e19c2e8>,\n",
       " 'getting': <gensim.models.keyedvectors.Vocab at 0x2e199ef0>,\n",
       " 'example': <gensim.models.keyedvectors.Vocab at 0x2e19c438>,\n",
       " '[': <gensim.models.keyedvectors.Vocab at 0x2e199fd0>,\n",
       " 'claim': <gensim.models.keyedvectors.Vocab at 0x2e19c470>,\n",
       " 'French': <gensim.models.keyedvectors.Vocab at 0x2e19c160>,\n",
       " 'Australia': <gensim.models.keyedvectors.Vocab at 0x2e19c550>,\n",
       " 'himself': <gensim.models.keyedvectors.Vocab at 0x2e19c198>,\n",
       " 'areas': <gensim.models.keyedvectors.Vocab at 0x2e19c5f8>,\n",
       " 'design': <gensim.models.keyedvectors.Vocab at 0x2e19c278>,\n",
       " 'writing': <gensim.models.keyedvectors.Vocab at 0x2e19c6d8>,\n",
       " 'interest': <gensim.models.keyedvectors.Vocab at 0x2e19c358>,\n",
       " 'body': <gensim.models.keyedvectors.Vocab at 0x2e19c780>,\n",
       " 'reported': <gensim.models.keyedvectors.Vocab at 0x2e19c400>,\n",
       " 'June': <gensim.models.keyedvectors.Vocab at 0x2e19c7b8>,\n",
       " 'population': <gensim.models.keyedvectors.Vocab at 0x2e19c4e0>,\n",
       " 'states': <gensim.models.keyedvectors.Vocab at 0x2e19c860>,\n",
       " 'companies': <gensim.models.keyedvectors.Vocab at 0x2e19c630>,\n",
       " 'wrong': <gensim.models.keyedvectors.Vocab at 0x2e19c898>,\n",
       " 't': <gensim.models.keyedvectors.Vocab at 0x2e19c710>,\n",
       " 'perhaps': <gensim.models.keyedvectors.Vocab at 0x2e19c940>,\n",
       " 'order': <gensim.models.keyedvectors.Vocab at 0x2e19c7f0>,\n",
       " 'came': <gensim.models.keyedvectors.Vocab at 0x2e19c9e8>,\n",
       " 'industry': <gensim.models.keyedvectors.Vocab at 0x2e19c8d0>,\n",
       " 'September': <gensim.models.keyedvectors.Vocab at 0x2e19ca58>,\n",
       " 'July': <gensim.models.keyedvectors.Vocab at 0x2e19c908>,\n",
       " 'Russia': <gensim.models.keyedvectors.Vocab at 0x2e19cb38>,\n",
       " 'land': <gensim.models.keyedvectors.Vocab at 0x2e19ca20>,\n",
       " 'office': <gensim.models.keyedvectors.Vocab at 0x2e19cbe0>,\n",
       " 'City': <gensim.models.keyedvectors.Vocab at 0x2e19cb00>,\n",
       " 'true': <gensim.models.keyedvectors.Vocab at 0x2e19ccc0>,\n",
       " 'face': <gensim.models.keyedvectors.Vocab at 0x2e19cc18>,\n",
       " 'address': <gensim.models.keyedvectors.Vocab at 0x2e19cda0>,\n",
       " 'sure': <gensim.models.keyedvectors.Vocab at 0x2e19ccf8>,\n",
       " '01': <gensim.models.keyedvectors.Vocab at 0x2e19ce80>,\n",
       " 'everyone': <gensim.models.keyedvectors.Vocab at 0x2e19cdd8>,\n",
       " 'began': <gensim.models.keyedvectors.Vocab at 0x2e19cef0>,\n",
       " 'president': <gensim.models.keyedvectors.Vocab at 0x2e19ceb8>,\n",
       " 'training': <gensim.models.keyedvectors.Vocab at 0x2e19cf28>,\n",
       " 'side': <gensim.models.keyedvectors.Vocab at 0x2e19cf60>,\n",
       " 'lost': <gensim.models.keyedvectors.Vocab at 0x2e19cfd0>,\n",
       " 'groups': <gensim.models.keyedvectors.Vocab at 0x2e19a0f0>,\n",
       " '2004': <gensim.models.keyedvectors.Vocab at 0x2e19a0b8>,\n",
       " 'care': <gensim.models.keyedvectors.Vocab at 0x2e19a1d0>,\n",
       " 'space': <gensim.models.keyedvectors.Vocab at 0x2e19a198>,\n",
       " 'model': <gensim.models.keyedvectors.Vocab at 0x2e19a278>,\n",
       " 'per': <gensim.models.keyedvectors.Vocab at 0x2e19a2e8>,\n",
       " 'August': <gensim.models.keyedvectors.Vocab at 0x2e19a358>,\n",
       " 'October': <gensim.models.keyedvectors.Vocab at 0x2e19a3c8>,\n",
       " 'California': <gensim.models.keyedvectors.Vocab at 0x2e19a438>,\n",
       " 'France': <gensim.models.keyedvectors.Vocab at 0x2e19a400>,\n",
       " 'region': <gensim.models.keyedvectors.Vocab at 0x2e19a518>,\n",
       " 'While': <gensim.models.keyedvectors.Vocab at 0x2e19a4e0>,\n",
       " 'School': <gensim.models.keyedvectors.Vocab at 0x2e19a5f8>,\n",
       " 'request': <gensim.models.keyedvectors.Vocab at 0x2e19a5c0>,\n",
       " 'military': <gensim.models.keyedvectors.Vocab at 0x2e19a6d8>,\n",
       " 'nothing': <gensim.models.keyedvectors.Vocab at 0x2e19a668>,\n",
       " 'food': <gensim.models.keyedvectors.Vocab at 0x2e19a780>,\n",
       " 'events': <gensim.models.keyedvectors.Vocab at 0x2e19a710>,\n",
       " 'House': <gensim.models.keyedvectors.Vocab at 0x2e19a8d0>,\n",
       " 'individual': <gensim.models.keyedvectors.Vocab at 0x2e19a7f0>,\n",
       " 'ask': <gensim.models.keyedvectors.Vocab at 0x2e19a908>,\n",
       " 'decision': <gensim.models.keyedvectors.Vocab at 0x2e19a898>,\n",
       " 'policies': <gensim.models.keyedvectors.Vocab at 0x2e19a9b0>,\n",
       " '02': <gensim.models.keyedvectors.Vocab at 0x2e19a940>,\n",
       " 'November': <gensim.models.keyedvectors.Vocab at 0x2e19aa90>,\n",
       " 'books': <gensim.models.keyedvectors.Vocab at 0x2e19a978>,\n",
       " 'received': <gensim.models.keyedvectors.Vocab at 0x2e19ab70>,\n",
       " 'album': <gensim.models.keyedvectors.Vocab at 0x2e19a9e8>,\n",
       " 'makes': <gensim.models.keyedvectors.Vocab at 0x2e19ac50>,\n",
       " 'matter': <gensim.models.keyedvectors.Vocab at 0x2e19aac8>,\n",
       " 'based': <gensim.models.keyedvectors.Vocab at 0x2e19ad30>,\n",
       " 'December': <gensim.models.keyedvectors.Vocab at 0x2e19aba8>,\n",
       " 'contributions': <gensim.models.keyedvectors.Vocab at 0x2e19add8>,\n",
       " '..': <gensim.models.keyedvectors.Vocab at 0x2e19abe0>,\n",
       " 'de': <gensim.models.keyedvectors.Vocab at 0x2e19aeb8>,\n",
       " 'mean': <gensim.models.keyedvectors.Vocab at 0x2e19acc0>,\n",
       " 'news': <gensim.models.keyedvectors.Vocab at 0x2e19af98>,\n",
       " 'written': <gensim.models.keyedvectors.Vocab at 0x2e19ada0>,\n",
       " 'images': <gensim.models.keyedvectors.Vocab at 0x2e1a10b8>,\n",
       " '31': <gensim.models.keyedvectors.Vocab at 0x2e19ae80>,\n",
       " 'systems': <gensim.models.keyedvectors.Vocab at 0x2e1a1198>,\n",
       " 'various': <gensim.models.keyedvectors.Vocab at 0x2e19af60>,\n",
       " 'few': <gensim.models.keyedvectors.Vocab at 0x2e1a1278>,\n",
       " 'held': <gensim.models.keyedvectors.Vocab at 0x2e1a1080>,\n",
       " 'below': <gensim.models.keyedvectors.Vocab at 0x2e1a1358>,\n",
       " 'tag': <gensim.models.keyedvectors.Vocab at 0x2e1a1160>,\n",
       " 'played': <gensim.models.keyedvectors.Vocab at 0x2e1a1438>,\n",
       " 'common': <gensim.models.keyedvectors.Vocab at 0x2e1a1240>,\n",
       " 'Europe': <gensim.models.keyedvectors.Vocab at 0x2e1a1518>,\n",
       " '03': <gensim.models.keyedvectors.Vocab at 0x2e1a1320>,\n",
       " 'performance': <gensim.models.keyedvectors.Vocab at 0x2e1a15f8>,\n",
       " 'She': <gensim.models.keyedvectors.Vocab at 0x2e1a1390>,\n",
       " 'regarding': <gensim.models.keyedvectors.Vocab at 0x2e1a16d8>,\n",
       " 'production': <gensim.models.keyedvectors.Vocab at 0x2e1a13c8>,\n",
       " 'shows': <gensim.models.keyedvectors.Vocab at 0x2e1a1748>,\n",
       " 'God': <gensim.models.keyedvectors.Vocab at 0x2e1a14a8>,\n",
       " 'India': <gensim.models.keyedvectors.Vocab at 0x2e1a1828>,\n",
       " 'meeting': <gensim.models.keyedvectors.Vocab at 0x2e1a1588>,\n",
       " 'away': <gensim.models.keyedvectors.Vocab at 0x2e1a1908>,\n",
       " 'comments': <gensim.models.keyedvectors.Vocab at 0x2e1a1668>,\n",
       " 'love': <gensim.models.keyedvectors.Vocab at 0x2e1a1940>,\n",
       " 'stop': <gensim.models.keyedvectors.Vocab at 0x2e1a17b8>,\n",
       " 'practice': <gensim.models.keyedvectors.Vocab at 0x2e1a1a20>,\n",
       " 'reference': <gensim.models.keyedvectors.Vocab at 0x2e1a17f0>,\n",
       " 'rules': <gensim.models.keyedvectors.Vocab at 0x2e1a1ac8>,\n",
       " 'head': <gensim.models.keyedvectors.Vocab at 0x2e1a18d0>,\n",
       " 'editors': <gensim.models.keyedvectors.Vocab at 0x2e1a1ba8>,\n",
       " 'users': <gensim.models.keyedvectors.Vocab at 0x2e1a19b0>,\n",
       " 'anyone': <gensim.models.keyedvectors.Vocab at 0x2e1a1c88>,\n",
       " 'let': <gensim.models.keyedvectors.Vocab at 0x2e1a1a90>,\n",
       " 'statement': <gensim.models.keyedvectors.Vocab at 0x2e1a1d68>,\n",
       " 'Thanks': <gensim.models.keyedvectors.Vocab at 0x2e1a1b38>,\n",
       " 'schools': <gensim.models.keyedvectors.Vocab at 0x2e1a1e48>,\n",
       " 'appropriate': <gensim.models.keyedvectors.Vocab at 0x2e1a1be0>,\n",
       " 'instead': <gensim.models.keyedvectors.Vocab at 0x2e1a1ef0>,\n",
       " 'campaign': <gensim.models.keyedvectors.Vocab at 0x2e1a1cc0>,\n",
       " '04': <gensim.models.keyedvectors.Vocab at 0x2e1a1f28>,\n",
       " 'almost': <gensim.models.keyedvectors.Vocab at 0x2e1a1da0>,\n",
       " 'Hello': <gensim.models.keyedvectors.Vocab at 0x2e1a1fd0>,\n",
       " 'February': <gensim.models.keyedvectors.Vocab at 0x2e1a1e80>,\n",
       " 'i': <gensim.models.keyedvectors.Vocab at 0x2e1a3080>,\n",
       " 'specific': <gensim.models.keyedvectors.Vocab at 0x2e1a1eb8>,\n",
       " '0': <gensim.models.keyedvectors.Vocab at 0x2e1a30b8>,\n",
       " 'players': <gensim.models.keyedvectors.Vocab at 0x2e1a1f60>,\n",
       " 'To': <gensim.models.keyedvectors.Vocab at 0x2e1a3198>,\n",
       " 'hit': <gensim.models.keyedvectors.Vocab at 0x2e1a30f0>,\n",
       " 'Obama': <gensim.models.keyedvectors.Vocab at 0x2e1a3278>,\n",
       " 'User': <gensim.models.keyedvectors.Vocab at 0x2e1a31d0>,\n",
       " 'President': <gensim.models.keyedvectors.Vocab at 0x2e1a33c8>,\n",
       " 'World': <gensim.models.keyedvectors.Vocab at 0x2e1a3208>,\n",
       " 'names': <gensim.models.keyedvectors.Vocab at 0x2e1a34a8>,\n",
       " 'past': <gensim.models.keyedvectors.Vocab at 0x2e1a32e8>,\n",
       " '05': <gensim.models.keyedvectors.Vocab at 0x2e1a3588>,\n",
       " 'night': <gensim.models.keyedvectors.Vocab at 0x2e1a3390>,\n",
       " 'least': <gensim.models.keyedvectors.Vocab at 0x2e1a3668>,\n",
       " 'age': <gensim.models.keyedvectors.Vocab at 0x2e1a3438>,\n",
       " 'note': <gensim.models.keyedvectors.Vocab at 0x2e1a3748>,\n",
       " 'social': <gensim.models.keyedvectors.Vocab at 0x2e1a3518>,\n",
       " 'management': <gensim.models.keyedvectors.Vocab at 0x2e1a3828>,\n",
       " 'considered': <gensim.models.keyedvectors.Vocab at 0x2e1a35c0>,\n",
       " 'standard': <gensim.models.keyedvectors.Vocab at 0x2e1a38d0>,\n",
       " 'months': <gensim.models.keyedvectors.Vocab at 0x2e1a35f8>,\n",
       " 'idea': <gensim.models.keyedvectors.Vocab at 0x2e1a3978>,\n",
       " 'deal': <gensim.models.keyedvectors.Vocab at 0x2e1a36d8>,\n",
       " 'attack': <gensim.models.keyedvectors.Vocab at 0x2e1a3a58>,\n",
       " 'student': <gensim.models.keyedvectors.Vocab at 0x2e1a37b8>,\n",
       " 'check': <gensim.models.keyedvectors.Vocab at 0x2e1a3b38>,\n",
       " 'post': <gensim.models.keyedvectors.Vocab at 0x2e1a3898>,\n",
       " 'Now': <gensim.models.keyedvectors.Vocab at 0x2e1a3c18>,\n",
       " 'behind': <gensim.models.keyedvectors.Vocab at 0x2e1a39e8>,\n",
       " 'adding': <gensim.models.keyedvectors.Vocab at 0x2e1a3cf8>,\n",
       " 'science': <gensim.models.keyedvectors.Vocab at 0x2e1a3ac8>,\n",
       " 'South': <gensim.models.keyedvectors.Vocab at 0x2e1a3dd8>,\n",
       " 'alt': <gensim.models.keyedvectors.Vocab at 0x2e1a3ba8>,\n",
       " 'references': <gensim.models.keyedvectors.Vocab at 0x2e1a3eb8>,\n",
       " '....': <gensim.models.keyedvectors.Vocab at 0x2e1a3be0>,\n",
       " 'Mr.': <gensim.models.keyedvectors.Vocab at 0x2e1a3f98>,\n",
       " 'security': <gensim.models.keyedvectors.Vocab at 0x2e1a3cc0>,\n",
       " 'Some': <gensim.models.keyedvectors.Vocab at 0x2e1a5048>,\n",
       " 'games': <gensim.models.keyedvectors.Vocab at 0x2e1a3d68>,\n",
       " 'situation': <gensim.models.keyedvectors.Vocab at 0x2e1a5128>,\n",
       " 'third': <gensim.models.keyedvectors.Vocab at 0x2e1a3e10>,\n",
       " 'race': <gensim.models.keyedvectors.Vocab at 0x2e1a5208>,\n",
       " 'cases': <gensim.models.keyedvectors.Vocab at 0x2e1a3ef0>,\n",
       " 'guidelines': <gensim.models.keyedvectors.Vocab at 0x2e1a52e8>,\n",
       " 'force': <gensim.models.keyedvectors.Vocab at 0x2e1a3f28>,\n",
       " 'German': <gensim.models.keyedvectors.Vocab at 0x2e1a53c8>,\n",
       " 'human': <gensim.models.keyedvectors.Vocab at 0x2e1a5080>,\n",
       " 'light': <gensim.models.keyedvectors.Vocab at 0x2e1a54a8>,\n",
       " \"'m\": <gensim.models.keyedvectors.Vocab at 0x2e1a5160>,\n",
       " 'version': <gensim.models.keyedvectors.Vocab at 0x2e1a5588>,\n",
       " 'organization': <gensim.models.keyedvectors.Vocab at 0x2e1a5240>,\n",
       " 'named': <gensim.models.keyedvectors.Vocab at 0x2e1a5630>,\n",
       " 'Germany': <gensim.models.keyedvectors.Vocab at 0x2e1a5320>,\n",
       " 'official': <gensim.models.keyedvectors.Vocab at 0x2e1a5710>,\n",
       " 'international': <gensim.models.keyedvectors.Vocab at 0x2e1a5358>,\n",
       " 'release': <gensim.models.keyedvectors.Vocab at 0x2e1a57b8>,\n",
       " 'role': <gensim.models.keyedvectors.Vocab at 0x2e1a5438>,\n",
       " 'block': <gensim.models.keyedvectors.Vocab at 0x2e1a5898>,\n",
       " 'published': <gensim.models.keyedvectors.Vocab at 0x2e1a5518>,\n",
       " 'character': <gensim.models.keyedvectors.Vocab at 0x2e1a58d0>,\n",
       " 'correct': <gensim.models.keyedvectors.Vocab at 0x2e1a55c0>,\n",
       " 'rule': <gensim.models.keyedvectors.Vocab at 0x2e1a5978>,\n",
       " 'song': <gensim.models.keyedvectors.Vocab at 0x2e1a56a0>,\n",
       " 'six': <gensim.models.keyedvectors.Vocab at 0x2e1a5a20>,\n",
       " 'visit': <gensim.models.keyedvectors.Vocab at 0x2e1a5748>,\n",
       " 'Mr': <gensim.models.keyedvectors.Vocab at 0x2e1a5ac8>,\n",
       " 'value': <gensim.models.keyedvectors.Vocab at 0x2e1a5828>,\n",
       " 'video': <gensim.models.keyedvectors.Vocab at 0x2e1a5ba8>,\n",
       " 'usually': <gensim.models.keyedvectors.Vocab at 0x2e1a5908>,\n",
       " 'big': <gensim.models.keyedvectors.Vocab at 0x2e1a5cf8>,\n",
       " 'taken': <gensim.models.keyedvectors.Vocab at 0x2e1a5a58>,\n",
       " 'hope': <gensim.models.keyedvectors.Vocab at 0x2e1a5dd8>,\n",
       " 'claims': <gensim.models.keyedvectors.Vocab at 0x2e1a5b38>,\n",
       " 'sometimes': <gensim.models.keyedvectors.Vocab at 0x2e1a5eb8>,\n",
       " 'needed': <gensim.models.keyedvectors.Vocab at 0x2e1a5be0>,\n",
       " 'activities': <gensim.models.keyedvectors.Vocab at 0x2e1a5f98>,\n",
       " 'Washington': <gensim.models.keyedvectors.Vocab at 0x2e1a5c18>,\n",
       " '@': <gensim.models.keyedvectors.Vocab at 0x2e1a5fd0>,\n",
       " 'everything': <gensim.models.keyedvectors.Vocab at 0x2e1a5c88>,\n",
       " 'club': <gensim.models.keyedvectors.Vocab at 0x2e1a90b8>,\n",
       " 'remove': <gensim.models.keyedvectors.Vocab at 0x2e1a5d68>,\n",
       " 'town': <gensim.models.keyedvectors.Vocab at 0x2e1a9198>,\n",
       " 'certain': <gensim.models.keyedvectors.Vocab at 0x2e1a5e48>,\n",
       " 'similar': <gensim.models.keyedvectors.Vocab at 0x2e1a9278>,\n",
       " 'uses': <gensim.models.keyedvectors.Vocab at 0x2e1a5f28>,\n",
       " 'close': <gensim.models.keyedvectors.Vocab at 0x2e1a9358>,\n",
       " 'player': <gensim.models.keyedvectors.Vocab at 0x2e1a9048>,\n",
       " \"'re\": <gensim.models.keyedvectors.Vocab at 0x2e1a9438>,\n",
       " 'rights': <gensim.models.keyedvectors.Vocab at 0x2e1a90f0>,\n",
       " 'North': <gensim.models.keyedvectors.Vocab at 0x2e1a9518>,\n",
       " 'Canada': <gensim.models.keyedvectors.Vocab at 0x2e1a91d0>,\n",
       " 'single': <gensim.models.keyedvectors.Vocab at 0x2e1a9630>,\n",
       " 'paper': <gensim.models.keyedvectors.Vocab at 0x2e1a92b0>,\n",
       " 'potential': <gensim.models.keyedvectors.Vocab at 0x2e1a96d8>,\n",
       " 'economy': <gensim.models.keyedvectors.Vocab at 0x2e1a92e8>,\n",
       " 'appear': <gensim.models.keyedvectors.Vocab at 0x2e1a97b8>,\n",
       " 'society': <gensim.models.keyedvectors.Vocab at 0x2e1a93c8>,\n",
       " 'proposed': <gensim.models.keyedvectors.Vocab at 0x2e1a9898>,\n",
       " 'West': <gensim.models.keyedvectors.Vocab at 0x2e1a9470>,\n",
       " 'resources': <gensim.models.keyedvectors.Vocab at 0x2e1a9978>,\n",
       " 'search': <gensim.models.keyedvectors.Vocab at 0x2e1a94a8>,\n",
       " 'cause': <gensim.models.keyedvectors.Vocab at 0x2e1a9a58>,\n",
       " 'win': <gensim.models.keyedvectors.Vocab at 0x2e1a9588>,\n",
       " 'National': <gensim.models.keyedvectors.Vocab at 0x2e1a9b38>,\n",
       " 'election': <gensim.models.keyedvectors.Vocab at 0x2e1a95f8>,\n",
       " 'hand': <gensim.models.keyedvectors.Vocab at 0x2e1a9b70>,\n",
       " 'editor': <gensim.models.keyedvectors.Vocab at 0x2e1a9748>,\n",
       " 'seems': <gensim.models.keyedvectors.Vocab at 0x2e1a9c50>,\n",
       " 'ago': <gensim.models.keyedvectors.Vocab at 0x2e1a9828>,\n",
       " 'consensus': <gensim.models.keyedvectors.Vocab at 0x2e1a9d30>,\n",
       " 'am': <gensim.models.keyedvectors.Vocab at 0x2e1a9860>,\n",
       " 'entry': <gensim.models.keyedvectors.Vocab at 0x2e1a9dd8>,\n",
       " 'result': <gensim.models.keyedvectors.Vocab at 0x2e1a9940>,\n",
       " '\\\\': <gensim.models.keyedvectors.Vocab at 0x2e1a9f28>,\n",
       " 'far': <gensim.models.keyedvectors.Vocab at 0x2e1a99e8>,\n",
       " 'style': <gensim.models.keyedvectors.Vocab at 0x2e1a6048>,\n",
       " 'wrote': <gensim.models.keyedvectors.Vocab at 0x2e1a9ac8>,\n",
       " 'personal': <gensim.models.keyedvectors.Vocab at 0x2e1a6128>,\n",
       " 'effect': <gensim.models.keyedvectors.Vocab at 0x2e1a9b00>,\n",
       " 'live': <gensim.models.keyedvectors.Vocab at 0x2e1a6278>,\n",
       " '2003': <gensim.models.keyedvectors.Vocab at 0x2e1a9be0>,\n",
       " 'online': <gensim.models.keyedvectors.Vocab at 0x2e1a6358>,\n",
       " 'Israel': <gensim.models.keyedvectors.Vocab at 0x2e1a9cc0>,\n",
       " 'includes': <gensim.models.keyedvectors.Vocab at 0x2e1a6438>,\n",
       " 'become': <gensim.models.keyedvectors.Vocab at 0x2e1a9d68>,\n",
       " 'growth': <gensim.models.keyedvectors.Vocab at 0x2e1a6518>,\n",
       " 'Japan': <gensim.models.keyedvectors.Vocab at 0x2e1a9e48>,\n",
       " 'share': <gensim.models.keyedvectors.Vocab at 0x2e1a65f8>,\n",
       " 'complete': <gensim.models.keyedvectors.Vocab at 0x2e1a9ef0>,\n",
       " 'young': <gensim.models.keyedvectors.Vocab at 0x2e1a66a0>,\n",
       " 'earlier': <gensim.models.keyedvectors.Vocab at 0x2e1a9fd0>,\n",
       " 'across': <gensim.models.keyedvectors.Vocab at 0x2e1a6780>,\n",
       " '06': <gensim.models.keyedvectors.Vocab at 0x2e1a60b8>,\n",
       " 'Hi': <gensim.models.keyedvectors.Vocab at 0x2e1a6860>,\n",
       " 'products': <gensim.models.keyedvectors.Vocab at 0x2e1a6198>,\n",
       " 'United': <gensim.models.keyedvectors.Vocab at 0x2e1a6898>,\n",
       " 'released': <gensim.models.keyedvectors.Vocab at 0x2e1a6240>,\n",
       " 'His': <gensim.models.keyedvectors.Vocab at 0x2e1a6940>,\n",
       " 'playing': <gensim.models.keyedvectors.Vocab at 0x2e1a6320>,\n",
       " 'car': <gensim.models.keyedvectors.Vocab at 0x2e1a6a20>,\n",
       " 'notable': <gensim.models.keyedvectors.Vocab at 0x2e1a6400>,\n",
       " 'Congress': <gensim.models.keyedvectors.Vocab at 0x2e1a6b00>,\n",
       " 'Although': <gensim.models.keyedvectors.Vocab at 0x2e1a64a8>,\n",
       " 'offer': <gensim.models.keyedvectors.Vocab at 0x2e1a6b38>,\n",
       " 'child': <gensim.models.keyedvectors.Vocab at 0x2e1a6588>,\n",
       " 'bad': <gensim.models.keyedvectors.Vocab at 0x2e1a6c18>,\n",
       " 'network': <gensim.models.keyedvectors.Vocab at 0x2e1a6630>,\n",
       " 'notice': <gensim.models.keyedvectors.Vocab at 0x2e1a6cf8>,\n",
       " 'energy': <gensim.models.keyedvectors.Vocab at 0x2e1a6710>,\n",
       " 'knowledge': <gensim.models.keyedvectors.Vocab at 0x2e1a6dd8>,\n",
       " 'European': <gensim.models.keyedvectors.Vocab at 0x2e1a6748>,\n",
       " 'sandbox': <gensim.models.keyedvectors.Vocab at 0x2e1a6e80>,\n",
       " '07': <gensim.models.keyedvectors.Vocab at 0x2e1a6828>,\n",
       " 'asked': <gensim.models.keyedvectors.Vocab at 0x2e1a6f60>,\n",
       " '09': <gensim.models.keyedvectors.Vocab at 0x2e1a6908>,\n",
       " 'sites': <gensim.models.keyedvectors.Vocab at 0x2e1af080>,\n",
       " 'pay': <gensim.models.keyedvectors.Vocab at 0x2e1a69e8>,\n",
       " '08': <gensim.models.keyedvectors.Vocab at 0x2e1af198>,\n",
       " 'understand': <gensim.models.keyedvectors.Vocab at 0x2e1a6ac8>,\n",
       " 'reports': <gensim.models.keyedvectors.Vocab at 0x2e1af1d0>,\n",
       " 'product': <gensim.models.keyedvectors.Vocab at 0x2e1a6ba8>,\n",
       " 'poor': <gensim.models.keyedvectors.Vocab at 0x2e1af278>,\n",
       " 'return': <gensim.models.keyedvectors.Vocab at 0x2e1a6c88>,\n",
       " 'short': <gensim.models.keyedvectors.Vocab at 0x2e1af358>,\n",
       " 'running': <gensim.models.keyedvectors.Vocab at 0x2e1a6d68>,\n",
       " 'constructive': <gensim.models.keyedvectors.Vocab at 0x2e1af438>,\n",
       " 'reading': <gensim.models.keyedvectors.Vocab at 0x2e1a6e10>,\n",
       " 'half': <gensim.models.keyedvectors.Vocab at 0x2e1af518>,\n",
       " 'currently': <gensim.models.keyedvectors.Vocab at 0x2e1a6ef0>,\n",
       " '2000': <gensim.models.keyedvectors.Vocab at 0x2e1af5c0>,\n",
       " 'required': <gensim.models.keyedvectors.Vocab at 0x2e1a6fd0>,\n",
       " 'culture': <gensim.models.keyedvectors.Vocab at 0x2e1af5f8>,\n",
       " 'software': <gensim.models.keyedvectors.Vocab at 0x2e1af0b8>,\n",
       " 'nor': <gensim.models.keyedvectors.Vocab at 0x2e1af668>,\n",
       " 'projects': <gensim.models.keyedvectors.Vocab at 0x2e1af160>,\n",
       " 'Scotland': <gensim.models.keyedvectors.Vocab at 0x2e1af6a0>,\n",
       " 'match': <gensim.models.keyedvectors.Vocab at 0x2e1af208>,\n",
       " 'cost': <gensim.models.keyedvectors.Vocab at 0x2e1af780>,\n",
       " 'upon': <gensim.models.keyedvectors.Vocab at 0x2e1af2e8>,\n",
       " 'benefits': <gensim.models.keyedvectors.Vocab at 0x2e1af860>,\n",
       " 'First': <gensim.models.keyedvectors.Vocab at 0x2e1af390>,\n",
       " 'success': <gensim.models.keyedvectors.Vocab at 0x2e1af9b0>,\n",
       " 'My': <gensim.models.keyedvectors.Vocab at 0x2e1af470>,\n",
       " 'established': <gensim.models.keyedvectors.Vocab at 0x2e1afa90>,\n",
       " 'David': <gensim.models.keyedvectors.Vocab at 0x2e1af4a8>,\n",
       " 'parents': <gensim.models.keyedvectors.Vocab at 0x2e1afb70>,\n",
       " 'private': <gensim.models.keyedvectors.Vocab at 0x2e1af588>,\n",
       " 'property': <gensim.models.keyedvectors.Vocab at 0x2e1afc18>,\n",
       " 'quality': <gensim.models.keyedvectors.Vocab at 0x2e1af630>,\n",
       " 'key': <gensim.models.keyedvectors.Vocab at 0x2e1afcf8>,\n",
       " 'whose': <gensim.models.keyedvectors.Vocab at 0x2e1af710>,\n",
       " 'sense': <gensim.models.keyedvectors.Vocab at 0x2e1afdd8>,\n",
       " 'theory': <gensim.models.keyedvectors.Vocab at 0x2e1af7f0>,\n",
       " 'numbers': <gensim.models.keyedvectors.Vocab at 0x2e1afeb8>,\n",
       " 'clearly': <gensim.models.keyedvectors.Vocab at 0x2e1af8d0>,\n",
       " 'Chinese': <gensim.models.keyedvectors.Vocab at 0x2e1aff98>,\n",
       " 'continue': <gensim.models.keyedvectors.Vocab at 0x2e1af978>,\n",
       " 'treatment': <gensim.models.keyedvectors.Vocab at 0x2e1b1080>,\n",
       " 'access': <gensim.models.keyedvectors.Vocab at 0x2e1afa20>,\n",
       " 'living': <gensim.models.keyedvectors.Vocab at 0x2e1b1160>,\n",
       " 'late': <gensim.models.keyedvectors.Vocab at 0x2e1afb00>,\n",
       " 'total': <gensim.models.keyedvectors.Vocab at 0x2e1b1240>,\n",
       " 'file': <gensim.models.keyedvectors.Vocab at 0x2e1afbe0>,\n",
       " 'band': <gensim.models.keyedvectors.Vocab at 0x2e1b1320>,\n",
       " 'month': <gensim.models.keyedvectors.Vocab at 0x2e1afcc0>,\n",
       " 'species': <gensim.models.keyedvectors.Vocab at 0x2e1b1400>,\n",
       " 'consider': <gensim.models.keyedvectors.Vocab at 0x2e1afda0>,\n",
       " 'By': <gensim.models.keyedvectors.Vocab at 0x2e1b14a8>,\n",
       " 'original': <gensim.models.keyedvectors.Vocab at 0x2e1afe80>,\n",
       " 'answer': <gensim.models.keyedvectors.Vocab at 0x2e1b14e0>,\n",
       " 'From': <gensim.models.keyedvectors.Vocab at 0x2e1aff28>,\n",
       " 'black': <gensim.models.keyedvectors.Vocab at 0x2e1b15f8>,\n",
       " 'conditions': <gensim.models.keyedvectors.Vocab at 0x2e1b1048>,\n",
       " 'air': <gensim.models.keyedvectors.Vocab at 0x2e1b1630>,\n",
       " 'involved': <gensim.models.keyedvectors.Vocab at 0x2e1b1128>,\n",
       " 'century': <gensim.models.keyedvectors.Vocab at 0x2e1b16d8>,\n",
       " 'leading': <gensim.models.keyedvectors.Vocab at 0x2e1b1208>,\n",
       " 'fire': <gensim.models.keyedvectors.Vocab at 0x2e1b1780>,\n",
       " '50': <gensim.models.keyedvectors.Vocab at 0x2e1b12e8>,\n",
       " 'art': <gensim.models.keyedvectors.Vocab at 0x2e1b1860>,\n",
       " '•': <gensim.models.keyedvectors.Vocab at 0x2e1b1390>,\n",
       " 'opinion': <gensim.models.keyedvectors.Vocab at 0x2e1b1908>,\n",
       " 'final': <gensim.models.keyedvectors.Vocab at 0x2e1b1470>,\n",
       " 'yourself': <gensim.models.keyedvectors.Vocab at 0x2e1b19e8>,\n",
       " 'gave': <gensim.models.keyedvectors.Vocab at 0x2e1b1518>,\n",
       " 'environment': <gensim.models.keyedvectors.Vocab at 0x2e1b1a90>,\n",
       " 'saw': <gensim.models.keyedvectors.Vocab at 0x2e1b1550>,\n",
       " 'debate': <gensim.models.keyedvectors.Vocab at 0x2e1b1b38>,\n",
       " 'costs': <gensim.models.keyedvectors.Vocab at 0x2e1b1668>,\n",
       " 'developed': <gensim.models.keyedvectors.Vocab at 0x2e1b1be0>,\n",
       " '100': <gensim.models.keyedvectors.Vocab at 0x2e1b16a0>,\n",
       " 'economic': <gensim.models.keyedvectors.Vocab at 0x2e1b1c88>,\n",
       " 'try': <gensim.models.keyedvectors.Vocab at 0x2e1b1748>,\n",
       " 'Britain': <gensim.models.keyedvectors.Vocab at 0x2e1b1d30>,\n",
       " 'therefore': <gensim.models.keyedvectors.Vocab at 0x2e1b1828>,\n",
       " 'category': <gensim.models.keyedvectors.Vocab at 0x2e1b1d68>,\n",
       " 'white': <gensim.models.keyedvectors.Vocab at 0x2e1b1898>,\n",
       " 'friends': <gensim.models.keyedvectors.Vocab at 0x2e1b1e48>,\n",
       " 'type': <gensim.models.keyedvectors.Vocab at 0x2e1b1978>,\n",
       " 'cut': <gensim.models.keyedvectors.Vocab at 0x2e1b1f60>,\n",
       " 'station': <gensim.models.keyedvectors.Vocab at 0x2e1b1a58>,\n",
       " 'church': <gensim.models.keyedvectors.Vocab at 0x2e1b5080>,\n",
       " 'template': <gensim.models.keyedvectors.Vocab at 0x2e1b1ba8>,\n",
       " 'Not': <gensim.models.keyedvectors.Vocab at 0x2e1b50b8>,\n",
       " 'myself': <gensim.models.keyedvectors.Vocab at 0x2e1b1cf8>,\n",
       " 'risk': <gensim.models.keyedvectors.Vocab at 0x2e1b5198>,\n",
       " 'mind': <gensim.models.keyedvectors.Vocab at 0x2e1b1dd8>,\n",
       " 'via': <gensim.models.keyedvectors.Vocab at 0x2e1b5278>,\n",
       " 'Texas': <gensim.models.keyedvectors.Vocab at 0x2e1b1ef0>,\n",
       " 'hours': <gensim.models.keyedvectors.Vocab at 0x2e1b5358>,\n",
       " 'War': <gensim.models.keyedvectors.Vocab at 0x2e1b1fd0>,\n",
       " 'generally': <gensim.models.keyedvectors.Vocab at 0x2e1b5400>,\n",
       " 'particular': <gensim.models.keyedvectors.Vocab at 0x2e1b5048>,\n",
       " 'alone': <gensim.models.keyedvectors.Vocab at 0x2e1b5470>,\n",
       " 'likely': <gensim.models.keyedvectors.Vocab at 0x2e1b5128>,\n",
       " '2001': <gensim.models.keyedvectors.Vocab at 0x2e1b5550>,\n",
       " 'board': <gensim.models.keyedvectors.Vocab at 0x2e1b5208>,\n",
       " 'structure': <gensim.models.keyedvectors.Vocab at 0x2e1b5630>,\n",
       " 'significant': <gensim.models.keyedvectors.Vocab at 0x2e1b52b0>,\n",
       " 'tax': <gensim.models.keyedvectors.Vocab at 0x2e1b56d8>,\n",
       " 'approach': <gensim.models.keyedvectors.Vocab at 0x2e1b5390>,\n",
       " 'hard': <gensim.models.keyedvectors.Vocab at 0x2e1b5710>,\n",
       " 'movement': <gensim.models.keyedvectors.Vocab at 0x2e1b54a8>,\n",
       " 'provides': <gensim.models.keyedvectors.Vocab at 0x2e1b57b8>,\n",
       " 'legal': <gensim.models.keyedvectors.Vocab at 0x2e1b54e0>,\n",
       " 'went': <gensim.models.keyedvectors.Vocab at 0x2e1b5898>,\n",
       " 'inside': <gensim.models.keyedvectors.Vocab at 0x2e1b55c0>,\n",
       " 'sentence': <gensim.models.keyedvectors.Vocab at 0x2e1b5940>,\n",
       " 'workers': <gensim.models.keyedvectors.Vocab at 0x2e1b5668>,\n",
       " 'related': <gensim.models.keyedvectors.Vocab at 0x2e1b5a20>,\n",
       " 'analysis': <gensim.models.keyedvectors.Vocab at 0x2e1b5748>,\n",
       " 'simple': <gensim.models.keyedvectors.Vocab at 0x2e1b5a58>,\n",
       " 'terms': <gensim.models.keyedvectors.Vocab at 0x2e1b5828>,\n",
       " 'ones': <gensim.models.keyedvectors.Vocab at 0x2e1b5b38>,\n",
       " 'especially': <gensim.models.keyedvectors.Vocab at 0x2e1b5908>,\n",
       " 'College': <gensim.models.keyedvectors.Vocab at 0x2e1b5ba8>,\n",
       " 'remains': <gensim.models.keyedvectors.Vocab at 0x2e1b59e8>,\n",
       " 'topic': <gensim.models.keyedvectors.Vocab at 0x2e1b5c88>,\n",
       " 'directly': <gensim.models.keyedvectors.Vocab at 0x2e1b5ac8>,\n",
       " 'rate': <gensim.models.keyedvectors.Vocab at 0x2e1b5cc0>,\n",
       " 'turn': <gensim.models.keyedvectors.Vocab at 0x2e1b5c18>,\n",
       " 'career': <gensim.models.keyedvectors.Vocab at 0x2e1b5e10>,\n",
       " 'sign': <gensim.models.keyedvectors.Vocab at 0x2e1b5cf8>,\n",
       " 'necessary': <gensim.models.keyedvectors.Vocab at 0x2e1b5eb8>,\n",
       " 'quite': <gensim.models.keyedvectors.Vocab at 0x2e1b5d30>,\n",
       " 'meaning': <gensim.models.keyedvectors.Vocab at 0x2e1b5f60>,\n",
       " 'application': <gensim.models.keyedvectors.Vocab at 0x2e1b5dd8>,\n",
       " 'recently': <gensim.models.keyedvectors.Vocab at 0x2e1b5fd0>,\n",
       " 'families': <gensim.models.keyedvectors.Vocab at 0x2e1b5e48>,\n",
       " 'status': <gensim.models.keyedvectors.Vocab at 0x2e1b6048>,\n",
       " 'strong': <gensim.models.keyedvectors.Vocab at 0x2e1b5f98>,\n",
       " '2002': <gensim.models.keyedvectors.Vocab at 0x2e1b6128>,\n",
       " 'percent': <gensim.models.keyedvectors.Vocab at 0x2e1b60b8>,\n",
       " 'Russian': <gensim.models.keyedvectors.Vocab at 0x2e1b6240>,\n",
       " 'Iraq': <gensim.models.keyedvectors.Vocab at 0x2e1b6198>,\n",
       " 'individuals': <gensim.models.keyedvectors.Vocab at 0x2e1b6320>,\n",
       " 'capital': <gensim.models.keyedvectors.Vocab at 0x2e1b6208>,\n",
       " 'studies': <gensim.models.keyedvectors.Vocab at 0x2e1b6400>,\n",
       " 'described': <gensim.models.keyedvectors.Vocab at 0x2e1b62e8>,\n",
       " 'reliable': <gensim.models.keyedvectors.Vocab at 0x2e1b6438>,\n",
       " 'due': <gensim.models.keyedvectors.Vocab at 0x2e1b6390>,\n",
       " 'killed': <gensim.models.keyedvectors.Vocab at 0x2e1b6518>,\n",
       " 'encyclopedia': <gensim.models.keyedvectors.Vocab at 0x2e1b6470>,\n",
       " 'Your': <gensim.models.keyedvectors.Vocab at 0x2e1b65c0>,\n",
       " 'blocked': <gensim.models.keyedvectors.Vocab at 0x2e1b6550>,\n",
       " 'room': <gensim.models.keyedvectors.Vocab at 0x2e1b66a0>,\n",
       " 'How': <gensim.models.keyedvectors.Vocab at 0x2e1b6630>,\n",
       " 'low': <gensim.models.keyedvectors.Vocab at 0x2e1b6780>,\n",
       " 'built': <gensim.models.keyedvectors.Vocab at 0x2e1b6710>,\n",
       " 'cover': <gensim.models.keyedvectors.Vocab at 0x2e1b6860>,\n",
       " 'giving': <gensim.models.keyedvectors.Vocab at 0x2e1b67f0>,\n",
       " 'worked': <gensim.models.keyedvectors.Vocab at 0x2e1b6940>,\n",
       " 'However': <gensim.models.keyedvectors.Vocab at 0x2e1b68d0>,\n",
       " 'brought': <gensim.models.keyedvectors.Vocab at 0x2e1b69e8>,\n",
       " 'https': <gensim.models.keyedvectors.Vocab at 0x2e1b69b0>,\n",
       " 'contact': <gensim.models.keyedvectors.Vocab at 0x2e1b6a90>,\n",
       " 'speedy': <gensim.models.keyedvectors.Vocab at 0x2e1b6ac8>,\n",
       " 'special': <gensim.models.keyedvectors.Vocab at 0x2e1b6b70>,\n",
       " 'features': <gensim.models.keyedvectors.Vocab at 0x2e1b6ba8>,\n",
       " 'size': <gensim.models.keyedvectors.Vocab at 0x2e1b6c18>,\n",
       " 'warning': <gensim.models.keyedvectors.Vocab at 0x2e1b6c88>,\n",
       " 'woman': <gensim.models.keyedvectors.Vocab at 0x2e1b6cf8>,\n",
       " 'appears': <gensim.models.keyedvectors.Vocab at 0x2e1b6d30>,\n",
       " 'create': <gensim.models.keyedvectors.Vocab at 0x2e1b6dd8>,\n",
       " 'lives': <gensim.models.keyedvectors.Vocab at 0x2e1b6e10>,\n",
       " 'standards': <gensim.models.keyedvectors.Vocab at 0x2e1b6ef0>,\n",
       " 'author': <gensim.models.keyedvectors.Vocab at 0x2e1b6e80>,\n",
       " 'relevant': <gensim.models.keyedvectors.Vocab at 0x2e1b6fd0>,\n",
       " 'James': <gensim.models.keyedvectors.Vocab at 0x2e1b6eb8>,\n",
       " ...}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_model.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = ['not', 'neither', 'nor', 'but', 'however', 'although', 'nonetheless', 'despite', 'except',\n",
    "                         'even though', 'yet']\n",
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)\n",
    "exclude.add('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(doc):\n",
    "    lemma=WordNetLemmatizer()\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop if i not in negative])\n",
    "    punc_free = \"\".join([ch for ch in stop_free if ch not in exclude])\n",
    "    normalized = \" \".join([lemma.lemmatize(word) for word in punc_free.split()])\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_word(li):\n",
    "    total_vecs=[]\n",
    "    for word in li:\n",
    "        if word in en_model.vocab:\n",
    "            vector = en_model[word]\n",
    "            total_vecs.append(vector)\n",
    "    return np.array(total_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vec_word('computer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "isear=pd.read_csv('isear_1.csv', header=-1)\n",
    "isear=isear.drop(2 , axis=1)\n",
    "isear[0][isear[0]=='guit']='guilt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=isear[1]\n",
    "X=X.apply(clean)\n",
    "y=isear[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_splits(series):\n",
    "    word_splits=series.str.split(' ')\n",
    "    return word_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits=word_splits(X)\n",
    "numbers_series=splits.apply(vec_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_input(text):\n",
    "    X=pd.Series(text).apply(clean)\n",
    "    splits=word_splits(X)\n",
    "    numbers_series=splits.apply(vec_word)\n",
    "    num_words=len(numbers_series)\n",
    "    X_1 = []\n",
    "    for index in range(0, num_words):\n",
    "        doc=numbers_series.iloc[index]\n",
    "        for i in range(3, len(doc)):\n",
    "            X_1.append(doc[i-3:i])\n",
    "    return np.array(X_1), len(X_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_textform(text):\n",
    "    X=pd.Series(text).apply(clean)\n",
    "    splits=word_splits(X)\n",
    "    numbers_series=splits\n",
    "    X_1 = []\n",
    "    for index in range(0, len(numbers_series)):\n",
    "        doc=numbers_series.iloc[index]\n",
    "        for i in range(3, len(doc)):\n",
    "            X_1.append(doc[i-3:i])\n",
    "    return X_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_textform(text):\n",
    "    X=pd.Series(text).apply(clean)\n",
    "    splits=word_splits(X)\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [like, pie, whole, bunch, lot]\n",
       "dtype: object"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_textform('I like pie a whole bunch a lot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [day, feel, close, partner, friend, feel, peac...\n",
       "1       [every, time, imagine, someone, love, could, c...\n",
       "2       [obviously, unjustly, treated, possibility, el...\n",
       "3       [think, short, time, live, relate, period, lif...\n",
       "4       [gathering, found, involuntarily, sitting, nex...\n",
       "5       [realized, directing, feeling, discontent, par...\n",
       "6       [feel, guilty, realize, consider, material, th...\n",
       "7          [girlfriend, taken, exam, went, parent, place]\n",
       "8           [when, first, time, realized, meaning, death]\n",
       "9         [car, overtaking, another, forced, drive, road]\n",
       "10      [recently, thought, hard, work, take, study, o...\n",
       "11                   [found, bristle, liver, paste, tube]\n",
       "12      [tired, unmotivated, shouted, girlfriend, brou...\n",
       "13      [think, study, enough, weekend, think, able, a...\n",
       "14                        [pas, examination, think, well]\n",
       "15      [one, arranged, meet, someone, person, arrives...\n",
       "16         [one, unjustly, accused, something, one, done]\n",
       "17      [one, study, seem, hopelessly, difficult, unin...\n",
       "18      [one, find, someone, know, like, one, thought,...\n",
       "19          [one, unjust, stupid, towards, someone, else]\n",
       "20                 [one, neglected, unjust, good, friend]\n",
       "21                           [passing, exam, expect, pas]\n",
       "22      [climbed, tree, pick, apple, angle, ladder, en...\n",
       "23                       [excuse, necessary, get, myself]\n",
       "24                                                [child]\n",
       "25      [2, year, old, son, climbed, sat, 7th, floor, ...\n",
       "26                [partner, attacked, lost, three, teeth]\n",
       "27       [see, child, tv, area, devastated, drought, war]\n",
       "28          [nearly, walked, blindworm, saw, crawl, away]\n",
       "29      [saw, 18, year, old, son, grab, oxygen, mask, ...\n",
       "                              ...                        \n",
       "7486              [forgot, zip, trouser, noticed, anyone]\n",
       "7487                                            [peeping]\n",
       "7488      [picnic, old, classmate, chatted, played, game]\n",
       "7489    [night, alone, home, all, family, member, usua...\n",
       "7490    [saw, bed, hostel, mess, guessed, someone, els...\n",
       "7491    [physic, experiment, session, understand, cont...\n",
       "7492    [man, sexually, aggressed, small, girl, bus, g...\n",
       "7493                       [unable, stop, urinating, bus]\n",
       "7494    [old, people, crowded, bus, courage, give, sea...\n",
       "7495    [first, time, gave, birthday, present, friend,...\n",
       "7496    [week, higher, level, result, announced, tried...\n",
       "7497    [surname, brother, different, ours, often, gri...\n",
       "7498    [primary, 6, father, died, young, know, happen...\n",
       "7499    [hostel, roommate, selfish, person, would, avo...\n",
       "7500    [friend, many, female, friend, thought, lover,...\n",
       "7501    [past, used, think, mother, nagging, person, s...\n",
       "7502    [august1983, long, awaited, big, envelope, a, ...\n",
       "7503    [christmas, eve1984, finished, exam, afraid, r...\n",
       "7504    [september, 1984, forced, live, someone, like,...\n",
       "7505    [issue, worried, rather, saddening, me, mid, s...\n",
       "7506    [roommate, liked, listen, meaningless, song, m...\n",
       "7507    [last, summer, went, camping, cu, student, wor...\n",
       "7508                            [lied, one, best, friend]\n",
       "7509                  [received, letter, distant, friend]\n",
       "7510    [parent, eldest, home, midnight, male, strange...\n",
       "7511    [two, year, back, someone, invited, tutor, gra...\n",
       "7512    [taken, responsibility, something, prepared, i...\n",
       "7513    [home, heard, loud, sound, spitting, outside, ...\n",
       "7514    [homework, teacher, asked, u, do, scolded, imm...\n",
       "7515    [shouted, younger, brother, always, afraid, ca...\n",
       "Name: 1, Length: 7516, dtype: object"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7516"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 300)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers_series.iloc[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Using non-normalized vector numbers? Check</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=isear[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = []\n",
    "y_1 = []\n",
    "for index in range(0, len(numbers_series)):\n",
    "    doc=numbers_series.iloc[index]\n",
    "    for i in range(3, len(doc)):\n",
    "        X_1.append(doc[i-3:i])\n",
    "        y_1.append(y.iloc[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 3.200e-02,  3.810e-02, -2.990e-02, -7.450e-02, -6.240e-02,\n",
       "         -1.060e-02,  1.214e-01,  6.520e-02, -2.870e-02, -9.300e-03,\n",
       "          4.320e-02,  1.459e-01, -2.000e-03, -5.200e-02, -5.320e-02,\n",
       "          2.760e-02,  5.220e-02,  2.200e-03,  1.427e-01,  3.780e-02,\n",
       "         -1.460e-02, -2.770e-02,  1.090e-02, -3.660e-02, -3.170e-02,\n",
       "         -3.650e-02, -4.070e-02,  1.970e-02,  5.730e-02, -1.530e-02,\n",
       "          1.760e-02,  2.430e-02,  7.420e-02, -1.240e-02, -2.500e-02,\n",
       "         -1.800e-03,  1.190e-02,  1.819e-01, -1.300e-03,  7.220e-02,\n",
       "         -4.430e-02,  3.330e-02,  2.290e-02, -1.340e-02,  2.340e-02,\n",
       "         -1.116e-01, -3.580e-02,  1.600e-03, -9.030e-02, -1.252e-01,\n",
       "         -4.470e-02, -3.710e-02, -6.549e-01,  2.000e-03, -3.950e-02,\n",
       "         -1.123e-01,  6.580e-02, -6.930e-02, -1.501e-01,  1.480e-02,\n",
       "         -1.100e-02, -9.800e-02, -6.130e-02,  1.700e-02, -2.390e-02,\n",
       "         -2.065e-01,  5.090e-02, -6.500e-03, -2.180e-02,  1.390e-02,\n",
       "         -1.250e-02,  4.410e-02,  4.790e-02, -1.867e-01, -3.230e-02,\n",
       "         -6.800e-03, -8.500e-02, -1.450e-02, -9.310e-02, -1.637e-01,\n",
       "          7.500e-03,  4.120e-02,  1.245e-01, -2.000e-01, -3.670e-02,\n",
       "          2.740e-02,  8.260e-02,  3.600e-02,  1.136e-01,  6.700e-02,\n",
       "          5.960e-02,  8.900e-03, -7.800e-03, -2.290e-02, -4.470e-02,\n",
       "         -3.100e-03,  4.140e-02,  2.040e-02, -3.990e-02, -1.714e-01,\n",
       "         -1.674e-01,  4.330e-02,  1.000e-01,  7.470e-02,  6.120e-02,\n",
       "          8.300e-02,  1.354e-01,  2.970e-02, -6.490e-02, -1.586e-01,\n",
       "         -7.510e-02,  1.097e-01,  1.800e-02,  5.380e-02,  5.620e-02,\n",
       "         -9.900e-02, -2.630e-02,  2.110e-02, -2.320e-02, -4.266e-01,\n",
       "          3.600e-03,  4.700e-02, -1.384e-01,  8.680e-02,  9.890e-02,\n",
       "          2.006e-01,  3.070e-02, -7.650e-02,  1.800e-02,  1.247e-01,\n",
       "         -1.310e-01,  5.380e-02,  2.730e-02,  2.590e-02, -6.400e-03,\n",
       "          2.500e-02, -6.000e-04,  2.650e-02,  1.347e-01, -1.770e-02,\n",
       "         -1.440e-02,  1.880e-02, -5.780e-02,  2.360e-01, -3.270e-02,\n",
       "         -4.060e-02,  6.090e-02, -5.380e-02, -2.230e-02, -1.710e-02,\n",
       "          1.744e-01, -6.700e-02, -2.550e-02,  1.930e-02,  9.390e-02,\n",
       "         -3.650e-02,  2.830e-02, -6.900e-03, -4.820e-02,  9.180e-02,\n",
       "          1.320e-02, -1.141e-01, -4.360e-02, -7.280e-02, -9.100e-03,\n",
       "          8.800e-03,  1.886e-01, -1.450e-02,  8.240e-02,  2.700e-02,\n",
       "         -2.947e-01, -2.790e-02,  9.500e-03,  9.000e-03,  1.655e-01,\n",
       "          8.160e-02,  1.838e-01, -7.310e-02,  6.430e-02, -5.360e-02,\n",
       "         -4.520e-02,  9.350e-02, -3.600e-02,  5.730e-02,  6.870e-02,\n",
       "         -2.477e-01, -8.710e-02, -1.210e-01,  9.100e-03,  1.141e-01,\n",
       "         -2.600e-03, -3.190e-02,  2.500e-02, -6.260e-02,  5.740e-02,\n",
       "          4.100e-02, -2.800e-03,  3.200e-03,  2.352e-01,  1.700e-02,\n",
       "         -2.820e-02, -1.094e-01,  1.283e-01,  2.460e-02,  1.732e-01,\n",
       "          8.470e-02,  7.700e-03, -2.120e-02,  1.663e-01,  5.410e-02,\n",
       "         -2.000e-04,  7.160e-02, -7.500e-03,  6.950e-02,  5.810e-02,\n",
       "         -1.371e-01, -4.870e-02, -1.312e-01,  3.800e-02,  1.567e-01,\n",
       "          7.410e-02,  5.100e-03,  9.870e-02,  4.090e-02,  2.390e-02,\n",
       "         -8.200e-03, -1.690e-02, -4.210e-02, -6.400e-03, -5.290e-02,\n",
       "         -8.200e-02,  8.390e-02,  3.865e-01, -1.897e-01,  5.260e-02,\n",
       "          1.094e-01, -1.560e-02,  8.210e-02, -2.498e-01,  8.600e-03,\n",
       "         -2.750e-02, -2.470e-02, -4.000e-03, -2.000e-04,  1.014e-01,\n",
       "         -6.340e-02,  2.040e-02, -8.590e-02, -1.220e-02,  3.081e-01,\n",
       "          2.380e-02,  2.240e-02,  6.300e-03, -8.210e-02,  1.800e-02,\n",
       "          1.220e-01, -1.168e-01,  1.170e-02, -1.670e-02, -1.115e-01,\n",
       "         -1.500e-02,  3.670e-02, -6.720e-02,  4.800e-02, -1.402e-01,\n",
       "         -1.926e-01, -2.378e-01, -7.780e-02, -1.381e-01,  6.000e-04,\n",
       "          1.300e-03,  1.280e-02, -8.500e-03, -2.820e-02,  1.087e-01,\n",
       "         -3.600e-03, -2.690e-02,  1.600e-03, -4.930e-02,  4.720e-02,\n",
       "          4.900e-03,  2.451e-01,  5.010e-02, -5.260e-02,  5.700e-02,\n",
       "         -5.700e-03, -5.700e-02, -6.700e-03,  1.320e-02,  6.800e-03,\n",
       "         -6.300e-02, -3.590e-02, -1.193e-01,  1.036e-01,  9.900e-02,\n",
       "         -1.067e-01,  7.470e-02,  1.316e-01,  1.363e-01,  4.400e-02],\n",
       "        [-3.720e-02,  6.150e-02,  1.670e-02, -3.820e-02,  2.070e-02,\n",
       "         -1.949e-01, -5.740e-02, -1.860e-02, -7.080e-02,  3.200e-02,\n",
       "         -8.050e-02,  6.830e-02,  9.450e-02, -4.390e-02,  1.260e-02,\n",
       "         -6.460e-02,  9.700e-03, -5.300e-03, -8.910e-02, -4.000e-03,\n",
       "         -6.980e-02, -7.330e-02,  4.830e-02,  1.170e-02,  1.000e-03,\n",
       "         -8.350e-02, -7.570e-02,  1.284e-01, -1.199e-01, -1.130e-02,\n",
       "         -7.560e-02, -1.086e-01,  4.320e-02, -5.050e-02,  4.290e-02,\n",
       "         -3.300e-03,  6.440e-02,  8.340e-02, -5.590e-02,  2.590e-02,\n",
       "         -1.146e-01, -1.870e-02,  1.726e-01, -5.940e-02, -4.630e-02,\n",
       "         -6.360e-02, -1.127e-01,  3.530e-02,  2.120e-02, -6.090e-02,\n",
       "         -1.483e-01, -3.080e-02, -7.681e-01,  4.510e-02,  6.200e-03,\n",
       "         -1.108e-01, -1.167e-01,  2.080e-01,  3.320e-02, -2.070e-02,\n",
       "         -1.250e-01, -1.418e-01,  1.279e-01, -3.970e-02, -1.530e-02,\n",
       "          5.080e-02,  4.710e-02, -6.600e-03,  1.740e-02, -5.250e-02,\n",
       "          2.140e-02,  2.500e-03,  3.580e-02,  1.115e-01, -8.900e-03,\n",
       "          1.160e-01, -1.130e-02,  5.200e-03,  1.180e-01,  4.206e-01,\n",
       "          1.220e-02,  5.700e-02, -9.100e-03, -2.539e-01, -3.300e-03,\n",
       "          1.401e-01, -8.000e-04,  6.430e-02, -2.602e-01,  2.130e-02,\n",
       "          1.616e-01, -1.225e-01, -1.296e-01,  5.240e-02, -2.500e-02,\n",
       "         -8.160e-02, -2.350e-02,  4.720e-02, -1.650e-02,  5.810e-02,\n",
       "         -2.563e-01, -7.400e-02, -1.620e-02, -6.420e-02,  2.326e-01,\n",
       "         -3.170e-02,  6.500e-03,  4.350e-02,  9.300e-03, -1.178e-01,\n",
       "          9.680e-02, -1.340e-02, -7.690e-02,  2.380e-02, -1.738e-01,\n",
       "         -1.450e-02, -6.170e-02, -5.410e-02, -5.550e-02, -3.698e-01,\n",
       "         -1.377e-01, -3.180e-02, -2.355e-01,  5.240e-02, -1.537e-01,\n",
       "          1.726e-01,  3.770e-02,  1.187e-01, -2.134e-01,  2.110e-02,\n",
       "          8.490e-02,  9.720e-02, -1.306e-01, -3.290e-02, -7.650e-02,\n",
       "          1.937e-01, -2.960e-02,  7.170e-02,  2.690e-02, -1.057e-01,\n",
       "          3.200e-02,  7.700e-02, -8.760e-02,  2.831e-01,  1.690e-02,\n",
       "         -4.290e-02,  1.161e-01, -9.800e-03, -8.130e-02, -3.070e-02,\n",
       "         -1.250e-02,  5.100e-02,  1.489e-01, -1.497e-01,  1.410e-01,\n",
       "          2.220e-02,  3.000e-04,  1.460e-02,  5.850e-02,  1.100e-03,\n",
       "         -4.360e-02,  7.400e-02,  4.340e-02,  5.880e-02, -2.657e-01,\n",
       "         -9.000e-03,  1.149e-01, -1.054e-01, -1.080e-02, -6.570e-02,\n",
       "         -2.301e-01, -2.220e-02,  2.280e-02,  2.110e-02,  2.018e-01,\n",
       "          2.087e-01,  2.543e-01, -1.050e-02,  3.320e-02,  8.310e-02,\n",
       "         -8.300e-03, -4.460e-02, -1.043e-01,  6.240e-02,  1.440e-01,\n",
       "         -7.810e-02, -3.770e-02, -1.402e-01,  2.362e-01, -9.820e-02,\n",
       "          4.010e-02,  5.420e-02, -7.730e-02, -4.880e-02,  2.670e-02,\n",
       "          1.035e-01,  9.500e-03,  7.310e-02,  2.603e-01,  4.200e-03,\n",
       "          1.124e-01,  1.970e-01, -1.377e-01, -1.770e-02,  1.377e-01,\n",
       "          7.220e-02,  1.613e-01,  1.321e-01, -2.120e-02, -1.130e-02,\n",
       "          4.510e-02, -7.260e-02, -2.900e-02, -1.279e-01, -1.159e-01,\n",
       "          1.030e-02, -1.519e-01,  2.510e-02, -3.930e-02, -6.200e-02,\n",
       "          4.310e-02, -1.120e-02,  8.650e-02, -3.510e-02, -8.900e-03,\n",
       "         -6.740e-02, -4.120e-02,  1.780e-02,  1.250e-01, -1.206e-01,\n",
       "         -1.380e-02, -7.200e-03,  2.376e-01,  1.030e-01, -5.390e-02,\n",
       "          2.830e-02,  8.700e-03, -4.330e-02, -2.478e-01,  6.260e-02,\n",
       "         -1.140e-02,  3.540e-02,  6.450e-02, -7.620e-02,  6.440e-02,\n",
       "          2.700e-02,  4.170e-02, -2.950e-02,  5.700e-03,  2.897e-01,\n",
       "         -4.570e-02,  1.536e-01,  5.970e-02, -1.020e-02,  1.500e-01,\n",
       "         -1.010e-02, -1.190e-02,  1.900e-03,  9.930e-02,  1.377e-01,\n",
       "          2.290e-02, -3.220e-02, -5.400e-02,  4.300e-03, -1.124e-01,\n",
       "          3.000e-02, -1.333e-01,  7.590e-02, -9.870e-02,  2.960e-02,\n",
       "          4.650e-02, -1.648e-01,  1.900e-02, -5.510e-02, -4.450e-02,\n",
       "         -1.550e-02,  1.090e-01, -7.970e-02,  8.700e-03, -7.630e-02,\n",
       "         -1.000e-02,  2.620e-02, -6.710e-02, -1.489e-01,  3.760e-02,\n",
       "         -1.027e-01, -6.520e-02, -8.100e-03,  6.130e-02, -4.130e-02,\n",
       "          1.132e-01, -1.560e-02, -1.584e-01,  2.490e-02,  1.890e-02,\n",
       "         -1.242e-01, -1.870e-01,  1.405e-01, -8.830e-02, -1.164e-01],\n",
       "        [ 6.220e-02,  6.280e-02,  2.393e-01,  1.030e-02,  3.810e-02,\n",
       "          1.586e-01,  5.310e-02, -4.900e-03, -3.270e-02, -2.283e-01,\n",
       "          4.800e-03,  2.000e-03, -1.032e-01,  8.110e-02, -1.228e-01,\n",
       "          2.010e-02, -2.330e-02,  1.321e-01,  3.720e-02,  7.090e-02,\n",
       "          4.800e-03,  5.590e-02,  5.600e-02,  3.120e-02,  2.030e-02,\n",
       "          9.290e-02,  5.100e-03, -1.637e-01, -1.068e-01, -2.248e-01,\n",
       "         -6.450e-02,  3.500e-02,  1.022e-01,  4.370e-02, -1.600e-03,\n",
       "          1.540e-02,  2.100e-03, -1.940e-01,  1.418e-01, -7.660e-02,\n",
       "         -3.180e-02,  1.209e-01, -2.086e-01, -4.030e-02, -1.605e-01,\n",
       "         -6.030e-02,  9.550e-02, -1.800e-01,  7.580e-02,  1.360e-01,\n",
       "         -2.710e-02,  2.020e-01, -6.912e-01,  6.750e-02, -1.057e-01,\n",
       "          3.340e-02, -1.053e-01,  1.560e-01,  3.610e-02, -4.110e-02,\n",
       "          3.700e-02, -5.760e-02,  2.320e-02, -5.360e-02, -1.189e-01,\n",
       "         -1.020e-02,  5.030e-02,  1.340e-02, -1.668e-01,  1.040e-02,\n",
       "          9.160e-02,  3.150e-02,  9.320e-02,  2.704e-01, -1.144e-01,\n",
       "         -4.750e-02,  6.480e-02,  5.780e-02, -3.400e-03, -4.800e-02,\n",
       "          2.610e-02, -6.490e-02,  9.560e-02, -2.246e-01,  2.750e-02,\n",
       "          4.160e-02,  1.630e-02, -2.600e-02, -9.030e-02,  9.210e-02,\n",
       "          3.180e-02,  8.000e-04,  4.600e-02, -1.040e-01,  2.930e-02,\n",
       "          8.060e-02, -4.660e-02, -2.990e-02, -5.180e-02, -8.540e-02,\n",
       "         -1.630e-01,  8.680e-02,  4.060e-02, -9.390e-02, -2.146e-01,\n",
       "         -8.160e-02,  1.847e-01, -6.970e-02,  1.462e-01, -1.044e-01,\n",
       "          9.980e-02, -1.972e-01, -8.770e-02, -5.190e-02,  3.850e-02,\n",
       "          6.550e-02, -4.420e-02, -4.800e-02,  1.144e-01, -3.020e-01,\n",
       "          3.150e-02,  1.520e-02, -4.960e-02,  1.340e-01, -7.200e-02,\n",
       "          1.974e-01, -1.870e-02,  1.990e-01, -2.750e-02,  4.160e-02,\n",
       "          3.160e-02,  1.762e-01,  1.070e-02,  2.796e-01,  8.430e-02,\n",
       "         -1.926e-01,  4.520e-02, -8.650e-02, -9.430e-02, -8.730e-02,\n",
       "         -2.610e-02,  8.300e-02,  1.460e-02,  2.599e-01,  1.602e-01,\n",
       "         -3.350e-02,  4.520e-02, -2.124e-01,  5.730e-02,  5.610e-02,\n",
       "          9.720e-02, -1.218e-01,  4.180e-02,  2.820e-02,  1.457e-01,\n",
       "         -9.600e-03, -3.280e-02,  4.140e-02,  1.230e-02,  1.438e-01,\n",
       "         -2.392e-01,  1.950e-02, -8.260e-02,  2.220e-02, -3.630e-02,\n",
       "         -2.060e-02,  1.029e-01,  7.790e-02, -1.540e-02,  5.300e-03,\n",
       "          2.676e-01, -2.140e-02, -1.084e-01, -5.190e-02,  5.520e-02,\n",
       "         -1.000e-03,  2.606e-01,  1.790e-02,  5.800e-03,  9.900e-03,\n",
       "         -1.066e-01,  2.458e-01, -1.551e-01, -2.940e-02,  5.040e-02,\n",
       "         -2.578e-01, -5.590e-02, -1.224e-01,  1.569e-01,  2.395e-01,\n",
       "         -7.780e-02,  2.030e-02, -7.650e-02, -6.510e-02, -3.510e-02,\n",
       "          5.130e-02, -9.800e-03,  2.830e-02,  1.340e-01,  5.560e-02,\n",
       "          1.021e-01, -5.670e-02,  1.682e-01, -3.360e-02,  1.151e-01,\n",
       "          1.223e-01, -1.974e-01, -3.760e-02, -1.560e-01,  7.870e-02,\n",
       "         -3.780e-02, -9.080e-02,  6.980e-02,  1.234e-01,  6.920e-02,\n",
       "          1.020e-02, -6.030e-02, -6.370e-02,  5.190e-02,  1.399e-01,\n",
       "          7.400e-03, -4.550e-02,  8.920e-02, -1.100e-02, -1.026e-01,\n",
       "         -3.300e-02, -4.830e-02, -4.950e-02, -5.810e-02, -9.190e-02,\n",
       "         -5.610e-02, -1.310e-02,  2.519e-01,  1.543e-01,  2.680e-02,\n",
       "         -2.500e-03, -5.890e-02,  1.284e-01, -2.187e-01,  8.900e-03,\n",
       "          1.070e-02, -1.597e-01, -1.143e-01,  2.280e-02, -1.590e-02,\n",
       "          8.460e-02,  3.750e-02, -1.131e-01,  5.370e-02,  3.220e-01,\n",
       "          8.510e-02,  1.031e-01,  1.587e-01,  1.400e-02,  4.840e-02,\n",
       "         -5.910e-02,  2.890e-02, -6.470e-02,  6.790e-02, -1.051e-01,\n",
       "         -2.098e-01, -9.090e-02,  8.330e-02, -4.690e-02,  2.224e-01,\n",
       "         -2.740e-02,  7.550e-02, -8.950e-02, -1.203e-01,  5.700e-03,\n",
       "          5.600e-03, -9.220e-02,  8.020e-02,  3.570e-02,  6.900e-03,\n",
       "          2.690e-02, -3.700e-03,  1.380e-02,  1.470e-02,  8.000e-02,\n",
       "         -1.681e-01, -5.350e-02,  2.224e-01, -2.410e-02,  4.340e-02,\n",
       "         -6.260e-02, -5.560e-02,  1.571e-01, -3.960e-02,  9.150e-02,\n",
       "          9.800e-03,  1.086e-01,  3.460e-02,  8.570e-02,  1.466e-01,\n",
       "         -2.067e-01,  7.700e-03,  1.802e-01, -3.940e-02, -2.430e-02]],\n",
       "       dtype=float32),\n",
       " array([[-3.720e-02,  6.150e-02,  1.670e-02, -3.820e-02,  2.070e-02,\n",
       "         -1.949e-01, -5.740e-02, -1.860e-02, -7.080e-02,  3.200e-02,\n",
       "         -8.050e-02,  6.830e-02,  9.450e-02, -4.390e-02,  1.260e-02,\n",
       "         -6.460e-02,  9.700e-03, -5.300e-03, -8.910e-02, -4.000e-03,\n",
       "         -6.980e-02, -7.330e-02,  4.830e-02,  1.170e-02,  1.000e-03,\n",
       "         -8.350e-02, -7.570e-02,  1.284e-01, -1.199e-01, -1.130e-02,\n",
       "         -7.560e-02, -1.086e-01,  4.320e-02, -5.050e-02,  4.290e-02,\n",
       "         -3.300e-03,  6.440e-02,  8.340e-02, -5.590e-02,  2.590e-02,\n",
       "         -1.146e-01, -1.870e-02,  1.726e-01, -5.940e-02, -4.630e-02,\n",
       "         -6.360e-02, -1.127e-01,  3.530e-02,  2.120e-02, -6.090e-02,\n",
       "         -1.483e-01, -3.080e-02, -7.681e-01,  4.510e-02,  6.200e-03,\n",
       "         -1.108e-01, -1.167e-01,  2.080e-01,  3.320e-02, -2.070e-02,\n",
       "         -1.250e-01, -1.418e-01,  1.279e-01, -3.970e-02, -1.530e-02,\n",
       "          5.080e-02,  4.710e-02, -6.600e-03,  1.740e-02, -5.250e-02,\n",
       "          2.140e-02,  2.500e-03,  3.580e-02,  1.115e-01, -8.900e-03,\n",
       "          1.160e-01, -1.130e-02,  5.200e-03,  1.180e-01,  4.206e-01,\n",
       "          1.220e-02,  5.700e-02, -9.100e-03, -2.539e-01, -3.300e-03,\n",
       "          1.401e-01, -8.000e-04,  6.430e-02, -2.602e-01,  2.130e-02,\n",
       "          1.616e-01, -1.225e-01, -1.296e-01,  5.240e-02, -2.500e-02,\n",
       "         -8.160e-02, -2.350e-02,  4.720e-02, -1.650e-02,  5.810e-02,\n",
       "         -2.563e-01, -7.400e-02, -1.620e-02, -6.420e-02,  2.326e-01,\n",
       "         -3.170e-02,  6.500e-03,  4.350e-02,  9.300e-03, -1.178e-01,\n",
       "          9.680e-02, -1.340e-02, -7.690e-02,  2.380e-02, -1.738e-01,\n",
       "         -1.450e-02, -6.170e-02, -5.410e-02, -5.550e-02, -3.698e-01,\n",
       "         -1.377e-01, -3.180e-02, -2.355e-01,  5.240e-02, -1.537e-01,\n",
       "          1.726e-01,  3.770e-02,  1.187e-01, -2.134e-01,  2.110e-02,\n",
       "          8.490e-02,  9.720e-02, -1.306e-01, -3.290e-02, -7.650e-02,\n",
       "          1.937e-01, -2.960e-02,  7.170e-02,  2.690e-02, -1.057e-01,\n",
       "          3.200e-02,  7.700e-02, -8.760e-02,  2.831e-01,  1.690e-02,\n",
       "         -4.290e-02,  1.161e-01, -9.800e-03, -8.130e-02, -3.070e-02,\n",
       "         -1.250e-02,  5.100e-02,  1.489e-01, -1.497e-01,  1.410e-01,\n",
       "          2.220e-02,  3.000e-04,  1.460e-02,  5.850e-02,  1.100e-03,\n",
       "         -4.360e-02,  7.400e-02,  4.340e-02,  5.880e-02, -2.657e-01,\n",
       "         -9.000e-03,  1.149e-01, -1.054e-01, -1.080e-02, -6.570e-02,\n",
       "         -2.301e-01, -2.220e-02,  2.280e-02,  2.110e-02,  2.018e-01,\n",
       "          2.087e-01,  2.543e-01, -1.050e-02,  3.320e-02,  8.310e-02,\n",
       "         -8.300e-03, -4.460e-02, -1.043e-01,  6.240e-02,  1.440e-01,\n",
       "         -7.810e-02, -3.770e-02, -1.402e-01,  2.362e-01, -9.820e-02,\n",
       "          4.010e-02,  5.420e-02, -7.730e-02, -4.880e-02,  2.670e-02,\n",
       "          1.035e-01,  9.500e-03,  7.310e-02,  2.603e-01,  4.200e-03,\n",
       "          1.124e-01,  1.970e-01, -1.377e-01, -1.770e-02,  1.377e-01,\n",
       "          7.220e-02,  1.613e-01,  1.321e-01, -2.120e-02, -1.130e-02,\n",
       "          4.510e-02, -7.260e-02, -2.900e-02, -1.279e-01, -1.159e-01,\n",
       "          1.030e-02, -1.519e-01,  2.510e-02, -3.930e-02, -6.200e-02,\n",
       "          4.310e-02, -1.120e-02,  8.650e-02, -3.510e-02, -8.900e-03,\n",
       "         -6.740e-02, -4.120e-02,  1.780e-02,  1.250e-01, -1.206e-01,\n",
       "         -1.380e-02, -7.200e-03,  2.376e-01,  1.030e-01, -5.390e-02,\n",
       "          2.830e-02,  8.700e-03, -4.330e-02, -2.478e-01,  6.260e-02,\n",
       "         -1.140e-02,  3.540e-02,  6.450e-02, -7.620e-02,  6.440e-02,\n",
       "          2.700e-02,  4.170e-02, -2.950e-02,  5.700e-03,  2.897e-01,\n",
       "         -4.570e-02,  1.536e-01,  5.970e-02, -1.020e-02,  1.500e-01,\n",
       "         -1.010e-02, -1.190e-02,  1.900e-03,  9.930e-02,  1.377e-01,\n",
       "          2.290e-02, -3.220e-02, -5.400e-02,  4.300e-03, -1.124e-01,\n",
       "          3.000e-02, -1.333e-01,  7.590e-02, -9.870e-02,  2.960e-02,\n",
       "          4.650e-02, -1.648e-01,  1.900e-02, -5.510e-02, -4.450e-02,\n",
       "         -1.550e-02,  1.090e-01, -7.970e-02,  8.700e-03, -7.630e-02,\n",
       "         -1.000e-02,  2.620e-02, -6.710e-02, -1.489e-01,  3.760e-02,\n",
       "         -1.027e-01, -6.520e-02, -8.100e-03,  6.130e-02, -4.130e-02,\n",
       "          1.132e-01, -1.560e-02, -1.584e-01,  2.490e-02,  1.890e-02,\n",
       "         -1.242e-01, -1.870e-01,  1.405e-01, -8.830e-02, -1.164e-01],\n",
       "        [ 6.220e-02,  6.280e-02,  2.393e-01,  1.030e-02,  3.810e-02,\n",
       "          1.586e-01,  5.310e-02, -4.900e-03, -3.270e-02, -2.283e-01,\n",
       "          4.800e-03,  2.000e-03, -1.032e-01,  8.110e-02, -1.228e-01,\n",
       "          2.010e-02, -2.330e-02,  1.321e-01,  3.720e-02,  7.090e-02,\n",
       "          4.800e-03,  5.590e-02,  5.600e-02,  3.120e-02,  2.030e-02,\n",
       "          9.290e-02,  5.100e-03, -1.637e-01, -1.068e-01, -2.248e-01,\n",
       "         -6.450e-02,  3.500e-02,  1.022e-01,  4.370e-02, -1.600e-03,\n",
       "          1.540e-02,  2.100e-03, -1.940e-01,  1.418e-01, -7.660e-02,\n",
       "         -3.180e-02,  1.209e-01, -2.086e-01, -4.030e-02, -1.605e-01,\n",
       "         -6.030e-02,  9.550e-02, -1.800e-01,  7.580e-02,  1.360e-01,\n",
       "         -2.710e-02,  2.020e-01, -6.912e-01,  6.750e-02, -1.057e-01,\n",
       "          3.340e-02, -1.053e-01,  1.560e-01,  3.610e-02, -4.110e-02,\n",
       "          3.700e-02, -5.760e-02,  2.320e-02, -5.360e-02, -1.189e-01,\n",
       "         -1.020e-02,  5.030e-02,  1.340e-02, -1.668e-01,  1.040e-02,\n",
       "          9.160e-02,  3.150e-02,  9.320e-02,  2.704e-01, -1.144e-01,\n",
       "         -4.750e-02,  6.480e-02,  5.780e-02, -3.400e-03, -4.800e-02,\n",
       "          2.610e-02, -6.490e-02,  9.560e-02, -2.246e-01,  2.750e-02,\n",
       "          4.160e-02,  1.630e-02, -2.600e-02, -9.030e-02,  9.210e-02,\n",
       "          3.180e-02,  8.000e-04,  4.600e-02, -1.040e-01,  2.930e-02,\n",
       "          8.060e-02, -4.660e-02, -2.990e-02, -5.180e-02, -8.540e-02,\n",
       "         -1.630e-01,  8.680e-02,  4.060e-02, -9.390e-02, -2.146e-01,\n",
       "         -8.160e-02,  1.847e-01, -6.970e-02,  1.462e-01, -1.044e-01,\n",
       "          9.980e-02, -1.972e-01, -8.770e-02, -5.190e-02,  3.850e-02,\n",
       "          6.550e-02, -4.420e-02, -4.800e-02,  1.144e-01, -3.020e-01,\n",
       "          3.150e-02,  1.520e-02, -4.960e-02,  1.340e-01, -7.200e-02,\n",
       "          1.974e-01, -1.870e-02,  1.990e-01, -2.750e-02,  4.160e-02,\n",
       "          3.160e-02,  1.762e-01,  1.070e-02,  2.796e-01,  8.430e-02,\n",
       "         -1.926e-01,  4.520e-02, -8.650e-02, -9.430e-02, -8.730e-02,\n",
       "         -2.610e-02,  8.300e-02,  1.460e-02,  2.599e-01,  1.602e-01,\n",
       "         -3.350e-02,  4.520e-02, -2.124e-01,  5.730e-02,  5.610e-02,\n",
       "          9.720e-02, -1.218e-01,  4.180e-02,  2.820e-02,  1.457e-01,\n",
       "         -9.600e-03, -3.280e-02,  4.140e-02,  1.230e-02,  1.438e-01,\n",
       "         -2.392e-01,  1.950e-02, -8.260e-02,  2.220e-02, -3.630e-02,\n",
       "         -2.060e-02,  1.029e-01,  7.790e-02, -1.540e-02,  5.300e-03,\n",
       "          2.676e-01, -2.140e-02, -1.084e-01, -5.190e-02,  5.520e-02,\n",
       "         -1.000e-03,  2.606e-01,  1.790e-02,  5.800e-03,  9.900e-03,\n",
       "         -1.066e-01,  2.458e-01, -1.551e-01, -2.940e-02,  5.040e-02,\n",
       "         -2.578e-01, -5.590e-02, -1.224e-01,  1.569e-01,  2.395e-01,\n",
       "         -7.780e-02,  2.030e-02, -7.650e-02, -6.510e-02, -3.510e-02,\n",
       "          5.130e-02, -9.800e-03,  2.830e-02,  1.340e-01,  5.560e-02,\n",
       "          1.021e-01, -5.670e-02,  1.682e-01, -3.360e-02,  1.151e-01,\n",
       "          1.223e-01, -1.974e-01, -3.760e-02, -1.560e-01,  7.870e-02,\n",
       "         -3.780e-02, -9.080e-02,  6.980e-02,  1.234e-01,  6.920e-02,\n",
       "          1.020e-02, -6.030e-02, -6.370e-02,  5.190e-02,  1.399e-01,\n",
       "          7.400e-03, -4.550e-02,  8.920e-02, -1.100e-02, -1.026e-01,\n",
       "         -3.300e-02, -4.830e-02, -4.950e-02, -5.810e-02, -9.190e-02,\n",
       "         -5.610e-02, -1.310e-02,  2.519e-01,  1.543e-01,  2.680e-02,\n",
       "         -2.500e-03, -5.890e-02,  1.284e-01, -2.187e-01,  8.900e-03,\n",
       "          1.070e-02, -1.597e-01, -1.143e-01,  2.280e-02, -1.590e-02,\n",
       "          8.460e-02,  3.750e-02, -1.131e-01,  5.370e-02,  3.220e-01,\n",
       "          8.510e-02,  1.031e-01,  1.587e-01,  1.400e-02,  4.840e-02,\n",
       "         -5.910e-02,  2.890e-02, -6.470e-02,  6.790e-02, -1.051e-01,\n",
       "         -2.098e-01, -9.090e-02,  8.330e-02, -4.690e-02,  2.224e-01,\n",
       "         -2.740e-02,  7.550e-02, -8.950e-02, -1.203e-01,  5.700e-03,\n",
       "          5.600e-03, -9.220e-02,  8.020e-02,  3.570e-02,  6.900e-03,\n",
       "          2.690e-02, -3.700e-03,  1.380e-02,  1.470e-02,  8.000e-02,\n",
       "         -1.681e-01, -5.350e-02,  2.224e-01, -2.410e-02,  4.340e-02,\n",
       "         -6.260e-02, -5.560e-02,  1.571e-01, -3.960e-02,  9.150e-02,\n",
       "          9.800e-03,  1.086e-01,  3.460e-02,  8.570e-02,  1.466e-01,\n",
       "         -2.067e-01,  7.700e-03,  1.802e-01, -3.940e-02, -2.430e-02],\n",
       "        [ 1.449e-01, -7.170e-02,  7.550e-02, -8.630e-02, -1.390e-02,\n",
       "          2.020e-02,  2.050e-02, -1.502e-01,  5.450e-02, -9.800e-03,\n",
       "         -2.382e-01,  5.940e-02,  3.990e-02, -2.740e-02, -9.420e-02,\n",
       "         -1.765e-01,  8.120e-02,  1.207e-01,  9.000e-03, -2.520e-02,\n",
       "         -6.760e-02, -2.560e-02,  8.000e-04,  1.239e-01,  4.690e-02,\n",
       "         -1.605e-01, -2.025e-01, -7.410e-02, -3.860e-02, -1.798e-01,\n",
       "          4.010e-02, -7.240e-02, -1.656e-01, -3.730e-02,  2.140e-02,\n",
       "         -6.290e-02, -1.930e-02, -1.128e-01,  6.600e-03, -1.639e-01,\n",
       "         -2.670e-02,  1.676e-01,  8.380e-02,  7.660e-02,  7.300e-02,\n",
       "         -9.390e-02,  7.700e-03,  3.180e-02,  7.720e-02,  3.560e-02,\n",
       "          1.136e-01,  1.133e-01, -5.993e-01,  6.180e-02, -7.260e-02,\n",
       "         -1.320e-02,  6.410e-02,  1.772e-01,  1.055e-01,  1.950e-01,\n",
       "         -3.760e-02, -4.270e-02,  1.910e-02, -2.450e-02,  2.270e-02,\n",
       "          6.540e-02,  4.090e-02, -8.490e-02, -2.150e-02, -5.660e-02,\n",
       "         -6.490e-02,  7.640e-02, -3.330e-02,  6.900e-02,  2.210e-02,\n",
       "          3.280e-02,  9.520e-02, -1.940e-02,  1.880e-02,  1.407e-01,\n",
       "          1.460e-02,  2.530e-02, -3.610e-02, -2.308e-01, -7.740e-02,\n",
       "         -3.780e-02, -1.319e-01, -1.520e-02,  1.663e-01, -1.077e-01,\n",
       "         -9.510e-02, -1.800e-03,  3.490e-02, -8.620e-02,  1.481e-01,\n",
       "          1.810e-02,  8.060e-02,  1.450e-02, -4.310e-02,  1.446e-01,\n",
       "         -2.313e-01, -5.900e-02,  4.050e-02, -1.631e-01, -4.260e-02,\n",
       "         -1.335e-01,  4.200e-02, -4.630e-02, -1.422e-01, -1.400e-03,\n",
       "          1.790e-01,  9.270e-02, -4.660e-02, -2.270e-02,  1.530e-02,\n",
       "         -6.800e-03, -6.470e-02, -6.660e-02, -2.219e-01, -3.828e-01,\n",
       "          1.819e-01, -4.960e-02,  1.670e-02, -5.200e-03,  1.094e-01,\n",
       "          2.482e-01,  4.770e-02, -4.980e-02,  1.705e-01, -2.800e-02,\n",
       "          1.740e-02,  1.377e-01,  1.558e-01, -8.750e-02,  1.521e-01,\n",
       "          9.930e-02, -5.440e-02,  1.200e-03, -2.196e-01, -1.068e-01,\n",
       "          1.163e-01, -1.110e-01,  6.280e-02,  1.295e-01,  6.260e-02,\n",
       "          2.400e-03, -1.726e-01,  8.880e-02,  5.010e-02,  3.600e-03,\n",
       "         -2.630e-02,  7.200e-02, -4.150e-02, -1.215e-01, -1.300e-02,\n",
       "          7.970e-02,  5.030e-02,  4.320e-02,  6.400e-02,  8.110e-02,\n",
       "         -1.887e-01,  5.620e-02,  1.880e-01,  1.917e-01,  1.320e-02,\n",
       "         -1.197e-01,  6.370e-02,  3.040e-02,  2.560e-02,  7.300e-02,\n",
       "          5.950e-02, -2.180e-02, -5.820e-02, -1.088e-01, -2.040e-02,\n",
       "          9.310e-02,  2.531e-01,  3.800e-03, -1.561e-01,  3.000e-02,\n",
       "         -8.500e-03, -2.880e-02, -1.152e-01,  5.570e-02,  1.062e-01,\n",
       "         -7.600e-02,  1.079e-01, -6.760e-02,  2.270e-02,  1.298e-01,\n",
       "         -1.221e-01,  2.118e-01, -1.680e-02,  2.446e-01, -5.130e-02,\n",
       "         -3.730e-02, -7.610e-02,  3.900e-02,  1.563e-01, -1.610e-02,\n",
       "         -2.056e-01, -3.870e-02, -1.260e-02, -2.350e-01, -1.160e-02,\n",
       "         -7.610e-02, -4.500e-02, -1.044e-01, -4.350e-02,  4.420e-02,\n",
       "         -6.350e-02,  5.110e-02,  1.963e-01,  1.766e-01,  4.360e-02,\n",
       "         -2.540e-02, -5.000e-02,  8.290e-02,  1.660e-02,  7.540e-02,\n",
       "         -1.232e-01,  2.600e-03,  1.225e-01,  5.780e-02,  7.000e-03,\n",
       "         -8.880e-02, -1.748e-01,  5.800e-03, -3.310e-02, -2.980e-02,\n",
       "         -3.329e-01,  1.343e-01,  4.041e-01, -1.436e-01,  8.800e-03,\n",
       "         -1.310e-01, -8.910e-02,  1.106e-01, -3.043e-01, -1.264e-01,\n",
       "          1.241e-01, -6.910e-02, -1.149e-01, -5.000e-02,  6.280e-02,\n",
       "         -1.145e-01,  8.880e-02, -8.270e-02, -4.560e-02,  3.709e-01,\n",
       "         -1.165e-01,  7.770e-02, -1.888e-01,  4.580e-02,  3.950e-02,\n",
       "          1.804e-01, -5.390e-02,  1.037e-01, -1.940e-02, -1.022e-01,\n",
       "         -1.692e-01, -9.570e-02,  6.240e-02, -1.314e-01, -2.734e-01,\n",
       "         -1.436e-01,  2.980e-02,  3.320e-02, -2.170e-01,  8.270e-02,\n",
       "         -1.092e-01,  3.290e-02, -2.565e-01, -3.660e-02,  6.940e-02,\n",
       "          1.027e-01, -7.370e-02, -1.480e-02, -1.175e-01, -2.840e-02,\n",
       "         -1.860e-02,  1.660e-02,  9.410e-02,  5.420e-02, -8.360e-02,\n",
       "         -6.120e-02, -2.114e-01, -1.129e-01,  1.242e-01,  1.463e-01,\n",
       "          7.690e-02, -2.770e-02, -3.500e-03,  1.253e-01,  1.017e-01,\n",
       "          6.310e-02,  2.180e-02,  5.700e-03, -7.600e-03, -5.020e-02]],\n",
       "       dtype=float32),\n",
       " array([[ 6.220e-02,  6.280e-02,  2.393e-01,  1.030e-02,  3.810e-02,\n",
       "          1.586e-01,  5.310e-02, -4.900e-03, -3.270e-02, -2.283e-01,\n",
       "          4.800e-03,  2.000e-03, -1.032e-01,  8.110e-02, -1.228e-01,\n",
       "          2.010e-02, -2.330e-02,  1.321e-01,  3.720e-02,  7.090e-02,\n",
       "          4.800e-03,  5.590e-02,  5.600e-02,  3.120e-02,  2.030e-02,\n",
       "          9.290e-02,  5.100e-03, -1.637e-01, -1.068e-01, -2.248e-01,\n",
       "         -6.450e-02,  3.500e-02,  1.022e-01,  4.370e-02, -1.600e-03,\n",
       "          1.540e-02,  2.100e-03, -1.940e-01,  1.418e-01, -7.660e-02,\n",
       "         -3.180e-02,  1.209e-01, -2.086e-01, -4.030e-02, -1.605e-01,\n",
       "         -6.030e-02,  9.550e-02, -1.800e-01,  7.580e-02,  1.360e-01,\n",
       "         -2.710e-02,  2.020e-01, -6.912e-01,  6.750e-02, -1.057e-01,\n",
       "          3.340e-02, -1.053e-01,  1.560e-01,  3.610e-02, -4.110e-02,\n",
       "          3.700e-02, -5.760e-02,  2.320e-02, -5.360e-02, -1.189e-01,\n",
       "         -1.020e-02,  5.030e-02,  1.340e-02, -1.668e-01,  1.040e-02,\n",
       "          9.160e-02,  3.150e-02,  9.320e-02,  2.704e-01, -1.144e-01,\n",
       "         -4.750e-02,  6.480e-02,  5.780e-02, -3.400e-03, -4.800e-02,\n",
       "          2.610e-02, -6.490e-02,  9.560e-02, -2.246e-01,  2.750e-02,\n",
       "          4.160e-02,  1.630e-02, -2.600e-02, -9.030e-02,  9.210e-02,\n",
       "          3.180e-02,  8.000e-04,  4.600e-02, -1.040e-01,  2.930e-02,\n",
       "          8.060e-02, -4.660e-02, -2.990e-02, -5.180e-02, -8.540e-02,\n",
       "         -1.630e-01,  8.680e-02,  4.060e-02, -9.390e-02, -2.146e-01,\n",
       "         -8.160e-02,  1.847e-01, -6.970e-02,  1.462e-01, -1.044e-01,\n",
       "          9.980e-02, -1.972e-01, -8.770e-02, -5.190e-02,  3.850e-02,\n",
       "          6.550e-02, -4.420e-02, -4.800e-02,  1.144e-01, -3.020e-01,\n",
       "          3.150e-02,  1.520e-02, -4.960e-02,  1.340e-01, -7.200e-02,\n",
       "          1.974e-01, -1.870e-02,  1.990e-01, -2.750e-02,  4.160e-02,\n",
       "          3.160e-02,  1.762e-01,  1.070e-02,  2.796e-01,  8.430e-02,\n",
       "         -1.926e-01,  4.520e-02, -8.650e-02, -9.430e-02, -8.730e-02,\n",
       "         -2.610e-02,  8.300e-02,  1.460e-02,  2.599e-01,  1.602e-01,\n",
       "         -3.350e-02,  4.520e-02, -2.124e-01,  5.730e-02,  5.610e-02,\n",
       "          9.720e-02, -1.218e-01,  4.180e-02,  2.820e-02,  1.457e-01,\n",
       "         -9.600e-03, -3.280e-02,  4.140e-02,  1.230e-02,  1.438e-01,\n",
       "         -2.392e-01,  1.950e-02, -8.260e-02,  2.220e-02, -3.630e-02,\n",
       "         -2.060e-02,  1.029e-01,  7.790e-02, -1.540e-02,  5.300e-03,\n",
       "          2.676e-01, -2.140e-02, -1.084e-01, -5.190e-02,  5.520e-02,\n",
       "         -1.000e-03,  2.606e-01,  1.790e-02,  5.800e-03,  9.900e-03,\n",
       "         -1.066e-01,  2.458e-01, -1.551e-01, -2.940e-02,  5.040e-02,\n",
       "         -2.578e-01, -5.590e-02, -1.224e-01,  1.569e-01,  2.395e-01,\n",
       "         -7.780e-02,  2.030e-02, -7.650e-02, -6.510e-02, -3.510e-02,\n",
       "          5.130e-02, -9.800e-03,  2.830e-02,  1.340e-01,  5.560e-02,\n",
       "          1.021e-01, -5.670e-02,  1.682e-01, -3.360e-02,  1.151e-01,\n",
       "          1.223e-01, -1.974e-01, -3.760e-02, -1.560e-01,  7.870e-02,\n",
       "         -3.780e-02, -9.080e-02,  6.980e-02,  1.234e-01,  6.920e-02,\n",
       "          1.020e-02, -6.030e-02, -6.370e-02,  5.190e-02,  1.399e-01,\n",
       "          7.400e-03, -4.550e-02,  8.920e-02, -1.100e-02, -1.026e-01,\n",
       "         -3.300e-02, -4.830e-02, -4.950e-02, -5.810e-02, -9.190e-02,\n",
       "         -5.610e-02, -1.310e-02,  2.519e-01,  1.543e-01,  2.680e-02,\n",
       "         -2.500e-03, -5.890e-02,  1.284e-01, -2.187e-01,  8.900e-03,\n",
       "          1.070e-02, -1.597e-01, -1.143e-01,  2.280e-02, -1.590e-02,\n",
       "          8.460e-02,  3.750e-02, -1.131e-01,  5.370e-02,  3.220e-01,\n",
       "          8.510e-02,  1.031e-01,  1.587e-01,  1.400e-02,  4.840e-02,\n",
       "         -5.910e-02,  2.890e-02, -6.470e-02,  6.790e-02, -1.051e-01,\n",
       "         -2.098e-01, -9.090e-02,  8.330e-02, -4.690e-02,  2.224e-01,\n",
       "         -2.740e-02,  7.550e-02, -8.950e-02, -1.203e-01,  5.700e-03,\n",
       "          5.600e-03, -9.220e-02,  8.020e-02,  3.570e-02,  6.900e-03,\n",
       "          2.690e-02, -3.700e-03,  1.380e-02,  1.470e-02,  8.000e-02,\n",
       "         -1.681e-01, -5.350e-02,  2.224e-01, -2.410e-02,  4.340e-02,\n",
       "         -6.260e-02, -5.560e-02,  1.571e-01, -3.960e-02,  9.150e-02,\n",
       "          9.800e-03,  1.086e-01,  3.460e-02,  8.570e-02,  1.466e-01,\n",
       "         -2.067e-01,  7.700e-03,  1.802e-01, -3.940e-02, -2.430e-02],\n",
       "        [ 1.449e-01, -7.170e-02,  7.550e-02, -8.630e-02, -1.390e-02,\n",
       "          2.020e-02,  2.050e-02, -1.502e-01,  5.450e-02, -9.800e-03,\n",
       "         -2.382e-01,  5.940e-02,  3.990e-02, -2.740e-02, -9.420e-02,\n",
       "         -1.765e-01,  8.120e-02,  1.207e-01,  9.000e-03, -2.520e-02,\n",
       "         -6.760e-02, -2.560e-02,  8.000e-04,  1.239e-01,  4.690e-02,\n",
       "         -1.605e-01, -2.025e-01, -7.410e-02, -3.860e-02, -1.798e-01,\n",
       "          4.010e-02, -7.240e-02, -1.656e-01, -3.730e-02,  2.140e-02,\n",
       "         -6.290e-02, -1.930e-02, -1.128e-01,  6.600e-03, -1.639e-01,\n",
       "         -2.670e-02,  1.676e-01,  8.380e-02,  7.660e-02,  7.300e-02,\n",
       "         -9.390e-02,  7.700e-03,  3.180e-02,  7.720e-02,  3.560e-02,\n",
       "          1.136e-01,  1.133e-01, -5.993e-01,  6.180e-02, -7.260e-02,\n",
       "         -1.320e-02,  6.410e-02,  1.772e-01,  1.055e-01,  1.950e-01,\n",
       "         -3.760e-02, -4.270e-02,  1.910e-02, -2.450e-02,  2.270e-02,\n",
       "          6.540e-02,  4.090e-02, -8.490e-02, -2.150e-02, -5.660e-02,\n",
       "         -6.490e-02,  7.640e-02, -3.330e-02,  6.900e-02,  2.210e-02,\n",
       "          3.280e-02,  9.520e-02, -1.940e-02,  1.880e-02,  1.407e-01,\n",
       "          1.460e-02,  2.530e-02, -3.610e-02, -2.308e-01, -7.740e-02,\n",
       "         -3.780e-02, -1.319e-01, -1.520e-02,  1.663e-01, -1.077e-01,\n",
       "         -9.510e-02, -1.800e-03,  3.490e-02, -8.620e-02,  1.481e-01,\n",
       "          1.810e-02,  8.060e-02,  1.450e-02, -4.310e-02,  1.446e-01,\n",
       "         -2.313e-01, -5.900e-02,  4.050e-02, -1.631e-01, -4.260e-02,\n",
       "         -1.335e-01,  4.200e-02, -4.630e-02, -1.422e-01, -1.400e-03,\n",
       "          1.790e-01,  9.270e-02, -4.660e-02, -2.270e-02,  1.530e-02,\n",
       "         -6.800e-03, -6.470e-02, -6.660e-02, -2.219e-01, -3.828e-01,\n",
       "          1.819e-01, -4.960e-02,  1.670e-02, -5.200e-03,  1.094e-01,\n",
       "          2.482e-01,  4.770e-02, -4.980e-02,  1.705e-01, -2.800e-02,\n",
       "          1.740e-02,  1.377e-01,  1.558e-01, -8.750e-02,  1.521e-01,\n",
       "          9.930e-02, -5.440e-02,  1.200e-03, -2.196e-01, -1.068e-01,\n",
       "          1.163e-01, -1.110e-01,  6.280e-02,  1.295e-01,  6.260e-02,\n",
       "          2.400e-03, -1.726e-01,  8.880e-02,  5.010e-02,  3.600e-03,\n",
       "         -2.630e-02,  7.200e-02, -4.150e-02, -1.215e-01, -1.300e-02,\n",
       "          7.970e-02,  5.030e-02,  4.320e-02,  6.400e-02,  8.110e-02,\n",
       "         -1.887e-01,  5.620e-02,  1.880e-01,  1.917e-01,  1.320e-02,\n",
       "         -1.197e-01,  6.370e-02,  3.040e-02,  2.560e-02,  7.300e-02,\n",
       "          5.950e-02, -2.180e-02, -5.820e-02, -1.088e-01, -2.040e-02,\n",
       "          9.310e-02,  2.531e-01,  3.800e-03, -1.561e-01,  3.000e-02,\n",
       "         -8.500e-03, -2.880e-02, -1.152e-01,  5.570e-02,  1.062e-01,\n",
       "         -7.600e-02,  1.079e-01, -6.760e-02,  2.270e-02,  1.298e-01,\n",
       "         -1.221e-01,  2.118e-01, -1.680e-02,  2.446e-01, -5.130e-02,\n",
       "         -3.730e-02, -7.610e-02,  3.900e-02,  1.563e-01, -1.610e-02,\n",
       "         -2.056e-01, -3.870e-02, -1.260e-02, -2.350e-01, -1.160e-02,\n",
       "         -7.610e-02, -4.500e-02, -1.044e-01, -4.350e-02,  4.420e-02,\n",
       "         -6.350e-02,  5.110e-02,  1.963e-01,  1.766e-01,  4.360e-02,\n",
       "         -2.540e-02, -5.000e-02,  8.290e-02,  1.660e-02,  7.540e-02,\n",
       "         -1.232e-01,  2.600e-03,  1.225e-01,  5.780e-02,  7.000e-03,\n",
       "         -8.880e-02, -1.748e-01,  5.800e-03, -3.310e-02, -2.980e-02,\n",
       "         -3.329e-01,  1.343e-01,  4.041e-01, -1.436e-01,  8.800e-03,\n",
       "         -1.310e-01, -8.910e-02,  1.106e-01, -3.043e-01, -1.264e-01,\n",
       "          1.241e-01, -6.910e-02, -1.149e-01, -5.000e-02,  6.280e-02,\n",
       "         -1.145e-01,  8.880e-02, -8.270e-02, -4.560e-02,  3.709e-01,\n",
       "         -1.165e-01,  7.770e-02, -1.888e-01,  4.580e-02,  3.950e-02,\n",
       "          1.804e-01, -5.390e-02,  1.037e-01, -1.940e-02, -1.022e-01,\n",
       "         -1.692e-01, -9.570e-02,  6.240e-02, -1.314e-01, -2.734e-01,\n",
       "         -1.436e-01,  2.980e-02,  3.320e-02, -2.170e-01,  8.270e-02,\n",
       "         -1.092e-01,  3.290e-02, -2.565e-01, -3.660e-02,  6.940e-02,\n",
       "          1.027e-01, -7.370e-02, -1.480e-02, -1.175e-01, -2.840e-02,\n",
       "         -1.860e-02,  1.660e-02,  9.410e-02,  5.420e-02, -8.360e-02,\n",
       "         -6.120e-02, -2.114e-01, -1.129e-01,  1.242e-01,  1.463e-01,\n",
       "          7.690e-02, -2.770e-02, -3.500e-03,  1.253e-01,  1.017e-01,\n",
       "          6.310e-02,  2.180e-02,  5.700e-03, -7.600e-03, -5.020e-02],\n",
       "        [ 7.890e-02, -3.130e-02,  1.218e-01, -1.990e-02, -1.300e-03,\n",
       "          9.540e-02,  2.630e-02, -6.500e-02, -5.340e-02, -2.390e-02,\n",
       "         -1.320e-02,  1.489e-01, -5.200e-03, -3.660e-02, -1.333e-01,\n",
       "         -5.580e-02,  1.494e-01,  4.430e-02,  1.756e-01, -1.610e-02,\n",
       "         -2.290e-02,  1.308e-01, -9.020e-02,  2.010e-02,  3.900e-03,\n",
       "          9.080e-02, -2.005e-01, -4.420e-02,  1.900e-03, -2.419e-01,\n",
       "          8.230e-02, -5.280e-02,  5.300e-02,  1.000e-03,  5.660e-02,\n",
       "          4.590e-02, -5.060e-02, -2.840e-02,  9.670e-02,  1.600e-03,\n",
       "          2.010e-02,  1.579e-01, -2.139e-01, -1.360e-02, -4.140e-02,\n",
       "         -4.800e-02,  1.031e-01, -2.014e-01,  7.270e-02, -2.520e-02,\n",
       "          4.880e-02,  1.396e-01, -6.528e-01,  6.020e-02, -1.086e-01,\n",
       "          9.800e-03,  3.830e-02,  1.621e-01,  1.611e-01, -2.870e-02,\n",
       "          7.360e-02, -1.547e-01, -7.870e-02,  1.750e-02, -6.510e-02,\n",
       "         -1.969e-01,  1.052e-01,  1.200e-03,  2.200e-03, -3.840e-02,\n",
       "          1.760e-02, -6.850e-02,  1.294e-01,  8.590e-02, -2.400e-03,\n",
       "          4.460e-02,  1.436e-01,  8.250e-02, -1.244e-01,  1.198e-01,\n",
       "          1.930e-02, -5.650e-02, -1.221e-01, -2.329e-01, -8.400e-03,\n",
       "         -9.490e-02, -2.190e-02, -1.307e-01,  1.991e-01,  5.820e-02,\n",
       "         -1.060e-02,  1.526e-01, -3.070e-02, -9.780e-02,  8.910e-02,\n",
       "          9.040e-02,  6.000e-02,  9.070e-02,  6.680e-02,  3.090e-02,\n",
       "         -2.008e-01,  1.307e-01,  1.450e-02, -1.256e-01, -5.850e-02,\n",
       "          7.550e-02,  1.685e-01, -2.000e-03, -1.518e-01,  5.900e-02,\n",
       "          1.163e-01,  1.540e-02,  9.630e-02, -7.350e-02, -8.720e-02,\n",
       "         -1.350e-02, -2.380e-02,  1.860e-02, -2.080e-02, -4.789e-01,\n",
       "          1.039e-01,  9.420e-02, -2.600e-02, -1.324e-01,  1.907e-01,\n",
       "          2.562e-01,  3.760e-02, -7.000e-02,  2.327e-01,  3.700e-02,\n",
       "          1.085e-01,  2.276e-01, -2.960e-02, -5.190e-02,  9.770e-02,\n",
       "          6.390e-02, -5.150e-02,  1.930e-02, -6.480e-02,  6.570e-02,\n",
       "          5.100e-02, -5.230e-02,  2.760e-02,  2.979e-01,  6.810e-02,\n",
       "          1.250e-02,  8.390e-02, -1.107e-01, -5.560e-02,  3.410e-02,\n",
       "         -1.160e-02, -8.400e-03,  7.960e-02, -3.770e-02,  1.055e-01,\n",
       "          9.940e-02, -1.940e-02,  4.410e-02, -4.610e-02,  1.001e-01,\n",
       "         -1.496e-01, -1.239e-01,  3.990e-02,  1.870e-01,  1.030e-02,\n",
       "         -6.560e-02,  1.710e-01,  8.930e-02,  1.970e-02,  4.860e-02,\n",
       "          3.950e-02, -4.720e-02, -1.597e-01, -2.255e-01,  7.490e-02,\n",
       "          4.870e-02,  2.583e-01, -1.315e-01,  1.515e-01,  3.920e-02,\n",
       "         -7.420e-02,  1.033e-01, -1.218e-01,  2.450e-02,  2.880e-02,\n",
       "         -4.910e-02,  5.940e-02, -6.650e-02, -1.300e-02,  5.990e-02,\n",
       "         -7.660e-02,  1.352e-01,  5.160e-02,  3.610e-02,  1.410e-02,\n",
       "          4.000e-02, -6.260e-02,  1.940e-02,  1.258e-01, -1.809e-01,\n",
       "         -6.090e-02, -1.673e-01, -1.570e-02, -1.790e-01,  1.385e-01,\n",
       "          9.580e-02, -2.376e-01, -2.150e-02, -2.530e-02,  5.240e-02,\n",
       "          1.563e-01,  1.417e-01, -1.120e-02,  7.640e-02, -8.140e-02,\n",
       "         -3.200e-03, -2.340e-02, -3.600e-02, -2.460e-02,  4.570e-02,\n",
       "         -7.400e-03, -4.240e-02,  2.000e-04,  1.460e-02,  3.840e-02,\n",
       "          4.960e-02, -5.690e-02, -6.210e-02, -1.340e-02, -1.932e-01,\n",
       "         -3.233e-01,  1.990e-02,  4.230e-01,  9.000e-04, -2.440e-02,\n",
       "         -1.892e-01, -7.920e-02,  1.529e-01, -2.925e-01, -1.540e-01,\n",
       "         -1.190e-02, -7.700e-02, -1.785e-01, -3.380e-02,  6.800e-03,\n",
       "          1.930e-01,  0.000e+00, -1.067e-01, -9.800e-03,  4.261e-01,\n",
       "          5.050e-02, -5.900e-03, -6.430e-02,  9.160e-02,  1.354e-01,\n",
       "         -1.264e-01, -1.438e-01,  1.459e-01, -1.092e-01, -4.500e-02,\n",
       "         -5.780e-02, -4.730e-02,  1.462e-01, -1.800e-03, -4.404e-01,\n",
       "          3.610e-02,  1.041e-01, -5.380e-02, -2.494e-01,  1.400e-02,\n",
       "         -1.334e-01,  1.009e-01,  2.850e-02,  7.600e-03, -1.258e-01,\n",
       "          2.930e-02,  1.470e-01,  4.260e-02,  3.680e-02,  1.015e-01,\n",
       "         -1.153e-01, -5.230e-02,  1.901e-01,  5.000e-04,  8.750e-02,\n",
       "         -1.134e-01, -9.520e-02, -3.142e-01,  4.160e-02,  1.015e-01,\n",
       "         -5.200e-02, -2.300e-02, -6.490e-02,  6.460e-02,  6.380e-02,\n",
       "         -9.550e-02, -1.086e-01,  6.540e-02,  3.000e-03, -1.005e-01]],\n",
       "       dtype=float32),\n",
       " array([[ 1.449e-01, -7.170e-02,  7.550e-02, -8.630e-02, -1.390e-02,\n",
       "          2.020e-02,  2.050e-02, -1.502e-01,  5.450e-02, -9.800e-03,\n",
       "         -2.382e-01,  5.940e-02,  3.990e-02, -2.740e-02, -9.420e-02,\n",
       "         -1.765e-01,  8.120e-02,  1.207e-01,  9.000e-03, -2.520e-02,\n",
       "         -6.760e-02, -2.560e-02,  8.000e-04,  1.239e-01,  4.690e-02,\n",
       "         -1.605e-01, -2.025e-01, -7.410e-02, -3.860e-02, -1.798e-01,\n",
       "          4.010e-02, -7.240e-02, -1.656e-01, -3.730e-02,  2.140e-02,\n",
       "         -6.290e-02, -1.930e-02, -1.128e-01,  6.600e-03, -1.639e-01,\n",
       "         -2.670e-02,  1.676e-01,  8.380e-02,  7.660e-02,  7.300e-02,\n",
       "         -9.390e-02,  7.700e-03,  3.180e-02,  7.720e-02,  3.560e-02,\n",
       "          1.136e-01,  1.133e-01, -5.993e-01,  6.180e-02, -7.260e-02,\n",
       "         -1.320e-02,  6.410e-02,  1.772e-01,  1.055e-01,  1.950e-01,\n",
       "         -3.760e-02, -4.270e-02,  1.910e-02, -2.450e-02,  2.270e-02,\n",
       "          6.540e-02,  4.090e-02, -8.490e-02, -2.150e-02, -5.660e-02,\n",
       "         -6.490e-02,  7.640e-02, -3.330e-02,  6.900e-02,  2.210e-02,\n",
       "          3.280e-02,  9.520e-02, -1.940e-02,  1.880e-02,  1.407e-01,\n",
       "          1.460e-02,  2.530e-02, -3.610e-02, -2.308e-01, -7.740e-02,\n",
       "         -3.780e-02, -1.319e-01, -1.520e-02,  1.663e-01, -1.077e-01,\n",
       "         -9.510e-02, -1.800e-03,  3.490e-02, -8.620e-02,  1.481e-01,\n",
       "          1.810e-02,  8.060e-02,  1.450e-02, -4.310e-02,  1.446e-01,\n",
       "         -2.313e-01, -5.900e-02,  4.050e-02, -1.631e-01, -4.260e-02,\n",
       "         -1.335e-01,  4.200e-02, -4.630e-02, -1.422e-01, -1.400e-03,\n",
       "          1.790e-01,  9.270e-02, -4.660e-02, -2.270e-02,  1.530e-02,\n",
       "         -6.800e-03, -6.470e-02, -6.660e-02, -2.219e-01, -3.828e-01,\n",
       "          1.819e-01, -4.960e-02,  1.670e-02, -5.200e-03,  1.094e-01,\n",
       "          2.482e-01,  4.770e-02, -4.980e-02,  1.705e-01, -2.800e-02,\n",
       "          1.740e-02,  1.377e-01,  1.558e-01, -8.750e-02,  1.521e-01,\n",
       "          9.930e-02, -5.440e-02,  1.200e-03, -2.196e-01, -1.068e-01,\n",
       "          1.163e-01, -1.110e-01,  6.280e-02,  1.295e-01,  6.260e-02,\n",
       "          2.400e-03, -1.726e-01,  8.880e-02,  5.010e-02,  3.600e-03,\n",
       "         -2.630e-02,  7.200e-02, -4.150e-02, -1.215e-01, -1.300e-02,\n",
       "          7.970e-02,  5.030e-02,  4.320e-02,  6.400e-02,  8.110e-02,\n",
       "         -1.887e-01,  5.620e-02,  1.880e-01,  1.917e-01,  1.320e-02,\n",
       "         -1.197e-01,  6.370e-02,  3.040e-02,  2.560e-02,  7.300e-02,\n",
       "          5.950e-02, -2.180e-02, -5.820e-02, -1.088e-01, -2.040e-02,\n",
       "          9.310e-02,  2.531e-01,  3.800e-03, -1.561e-01,  3.000e-02,\n",
       "         -8.500e-03, -2.880e-02, -1.152e-01,  5.570e-02,  1.062e-01,\n",
       "         -7.600e-02,  1.079e-01, -6.760e-02,  2.270e-02,  1.298e-01,\n",
       "         -1.221e-01,  2.118e-01, -1.680e-02,  2.446e-01, -5.130e-02,\n",
       "         -3.730e-02, -7.610e-02,  3.900e-02,  1.563e-01, -1.610e-02,\n",
       "         -2.056e-01, -3.870e-02, -1.260e-02, -2.350e-01, -1.160e-02,\n",
       "         -7.610e-02, -4.500e-02, -1.044e-01, -4.350e-02,  4.420e-02,\n",
       "         -6.350e-02,  5.110e-02,  1.963e-01,  1.766e-01,  4.360e-02,\n",
       "         -2.540e-02, -5.000e-02,  8.290e-02,  1.660e-02,  7.540e-02,\n",
       "         -1.232e-01,  2.600e-03,  1.225e-01,  5.780e-02,  7.000e-03,\n",
       "         -8.880e-02, -1.748e-01,  5.800e-03, -3.310e-02, -2.980e-02,\n",
       "         -3.329e-01,  1.343e-01,  4.041e-01, -1.436e-01,  8.800e-03,\n",
       "         -1.310e-01, -8.910e-02,  1.106e-01, -3.043e-01, -1.264e-01,\n",
       "          1.241e-01, -6.910e-02, -1.149e-01, -5.000e-02,  6.280e-02,\n",
       "         -1.145e-01,  8.880e-02, -8.270e-02, -4.560e-02,  3.709e-01,\n",
       "         -1.165e-01,  7.770e-02, -1.888e-01,  4.580e-02,  3.950e-02,\n",
       "          1.804e-01, -5.390e-02,  1.037e-01, -1.940e-02, -1.022e-01,\n",
       "         -1.692e-01, -9.570e-02,  6.240e-02, -1.314e-01, -2.734e-01,\n",
       "         -1.436e-01,  2.980e-02,  3.320e-02, -2.170e-01,  8.270e-02,\n",
       "         -1.092e-01,  3.290e-02, -2.565e-01, -3.660e-02,  6.940e-02,\n",
       "          1.027e-01, -7.370e-02, -1.480e-02, -1.175e-01, -2.840e-02,\n",
       "         -1.860e-02,  1.660e-02,  9.410e-02,  5.420e-02, -8.360e-02,\n",
       "         -6.120e-02, -2.114e-01, -1.129e-01,  1.242e-01,  1.463e-01,\n",
       "          7.690e-02, -2.770e-02, -3.500e-03,  1.253e-01,  1.017e-01,\n",
       "          6.310e-02,  2.180e-02,  5.700e-03, -7.600e-03, -5.020e-02],\n",
       "        [ 7.890e-02, -3.130e-02,  1.218e-01, -1.990e-02, -1.300e-03,\n",
       "          9.540e-02,  2.630e-02, -6.500e-02, -5.340e-02, -2.390e-02,\n",
       "         -1.320e-02,  1.489e-01, -5.200e-03, -3.660e-02, -1.333e-01,\n",
       "         -5.580e-02,  1.494e-01,  4.430e-02,  1.756e-01, -1.610e-02,\n",
       "         -2.290e-02,  1.308e-01, -9.020e-02,  2.010e-02,  3.900e-03,\n",
       "          9.080e-02, -2.005e-01, -4.420e-02,  1.900e-03, -2.419e-01,\n",
       "          8.230e-02, -5.280e-02,  5.300e-02,  1.000e-03,  5.660e-02,\n",
       "          4.590e-02, -5.060e-02, -2.840e-02,  9.670e-02,  1.600e-03,\n",
       "          2.010e-02,  1.579e-01, -2.139e-01, -1.360e-02, -4.140e-02,\n",
       "         -4.800e-02,  1.031e-01, -2.014e-01,  7.270e-02, -2.520e-02,\n",
       "          4.880e-02,  1.396e-01, -6.528e-01,  6.020e-02, -1.086e-01,\n",
       "          9.800e-03,  3.830e-02,  1.621e-01,  1.611e-01, -2.870e-02,\n",
       "          7.360e-02, -1.547e-01, -7.870e-02,  1.750e-02, -6.510e-02,\n",
       "         -1.969e-01,  1.052e-01,  1.200e-03,  2.200e-03, -3.840e-02,\n",
       "          1.760e-02, -6.850e-02,  1.294e-01,  8.590e-02, -2.400e-03,\n",
       "          4.460e-02,  1.436e-01,  8.250e-02, -1.244e-01,  1.198e-01,\n",
       "          1.930e-02, -5.650e-02, -1.221e-01, -2.329e-01, -8.400e-03,\n",
       "         -9.490e-02, -2.190e-02, -1.307e-01,  1.991e-01,  5.820e-02,\n",
       "         -1.060e-02,  1.526e-01, -3.070e-02, -9.780e-02,  8.910e-02,\n",
       "          9.040e-02,  6.000e-02,  9.070e-02,  6.680e-02,  3.090e-02,\n",
       "         -2.008e-01,  1.307e-01,  1.450e-02, -1.256e-01, -5.850e-02,\n",
       "          7.550e-02,  1.685e-01, -2.000e-03, -1.518e-01,  5.900e-02,\n",
       "          1.163e-01,  1.540e-02,  9.630e-02, -7.350e-02, -8.720e-02,\n",
       "         -1.350e-02, -2.380e-02,  1.860e-02, -2.080e-02, -4.789e-01,\n",
       "          1.039e-01,  9.420e-02, -2.600e-02, -1.324e-01,  1.907e-01,\n",
       "          2.562e-01,  3.760e-02, -7.000e-02,  2.327e-01,  3.700e-02,\n",
       "          1.085e-01,  2.276e-01, -2.960e-02, -5.190e-02,  9.770e-02,\n",
       "          6.390e-02, -5.150e-02,  1.930e-02, -6.480e-02,  6.570e-02,\n",
       "          5.100e-02, -5.230e-02,  2.760e-02,  2.979e-01,  6.810e-02,\n",
       "          1.250e-02,  8.390e-02, -1.107e-01, -5.560e-02,  3.410e-02,\n",
       "         -1.160e-02, -8.400e-03,  7.960e-02, -3.770e-02,  1.055e-01,\n",
       "          9.940e-02, -1.940e-02,  4.410e-02, -4.610e-02,  1.001e-01,\n",
       "         -1.496e-01, -1.239e-01,  3.990e-02,  1.870e-01,  1.030e-02,\n",
       "         -6.560e-02,  1.710e-01,  8.930e-02,  1.970e-02,  4.860e-02,\n",
       "          3.950e-02, -4.720e-02, -1.597e-01, -2.255e-01,  7.490e-02,\n",
       "          4.870e-02,  2.583e-01, -1.315e-01,  1.515e-01,  3.920e-02,\n",
       "         -7.420e-02,  1.033e-01, -1.218e-01,  2.450e-02,  2.880e-02,\n",
       "         -4.910e-02,  5.940e-02, -6.650e-02, -1.300e-02,  5.990e-02,\n",
       "         -7.660e-02,  1.352e-01,  5.160e-02,  3.610e-02,  1.410e-02,\n",
       "          4.000e-02, -6.260e-02,  1.940e-02,  1.258e-01, -1.809e-01,\n",
       "         -6.090e-02, -1.673e-01, -1.570e-02, -1.790e-01,  1.385e-01,\n",
       "          9.580e-02, -2.376e-01, -2.150e-02, -2.530e-02,  5.240e-02,\n",
       "          1.563e-01,  1.417e-01, -1.120e-02,  7.640e-02, -8.140e-02,\n",
       "         -3.200e-03, -2.340e-02, -3.600e-02, -2.460e-02,  4.570e-02,\n",
       "         -7.400e-03, -4.240e-02,  2.000e-04,  1.460e-02,  3.840e-02,\n",
       "          4.960e-02, -5.690e-02, -6.210e-02, -1.340e-02, -1.932e-01,\n",
       "         -3.233e-01,  1.990e-02,  4.230e-01,  9.000e-04, -2.440e-02,\n",
       "         -1.892e-01, -7.920e-02,  1.529e-01, -2.925e-01, -1.540e-01,\n",
       "         -1.190e-02, -7.700e-02, -1.785e-01, -3.380e-02,  6.800e-03,\n",
       "          1.930e-01,  0.000e+00, -1.067e-01, -9.800e-03,  4.261e-01,\n",
       "          5.050e-02, -5.900e-03, -6.430e-02,  9.160e-02,  1.354e-01,\n",
       "         -1.264e-01, -1.438e-01,  1.459e-01, -1.092e-01, -4.500e-02,\n",
       "         -5.780e-02, -4.730e-02,  1.462e-01, -1.800e-03, -4.404e-01,\n",
       "          3.610e-02,  1.041e-01, -5.380e-02, -2.494e-01,  1.400e-02,\n",
       "         -1.334e-01,  1.009e-01,  2.850e-02,  7.600e-03, -1.258e-01,\n",
       "          2.930e-02,  1.470e-01,  4.260e-02,  3.680e-02,  1.015e-01,\n",
       "         -1.153e-01, -5.230e-02,  1.901e-01,  5.000e-04,  8.750e-02,\n",
       "         -1.134e-01, -9.520e-02, -3.142e-01,  4.160e-02,  1.015e-01,\n",
       "         -5.200e-02, -2.300e-02, -6.490e-02,  6.460e-02,  6.380e-02,\n",
       "         -9.550e-02, -1.086e-01,  6.540e-02,  3.000e-03, -1.005e-01],\n",
       "        [-3.720e-02,  6.150e-02,  1.670e-02, -3.820e-02,  2.070e-02,\n",
       "         -1.949e-01, -5.740e-02, -1.860e-02, -7.080e-02,  3.200e-02,\n",
       "         -8.050e-02,  6.830e-02,  9.450e-02, -4.390e-02,  1.260e-02,\n",
       "         -6.460e-02,  9.700e-03, -5.300e-03, -8.910e-02, -4.000e-03,\n",
       "         -6.980e-02, -7.330e-02,  4.830e-02,  1.170e-02,  1.000e-03,\n",
       "         -8.350e-02, -7.570e-02,  1.284e-01, -1.199e-01, -1.130e-02,\n",
       "         -7.560e-02, -1.086e-01,  4.320e-02, -5.050e-02,  4.290e-02,\n",
       "         -3.300e-03,  6.440e-02,  8.340e-02, -5.590e-02,  2.590e-02,\n",
       "         -1.146e-01, -1.870e-02,  1.726e-01, -5.940e-02, -4.630e-02,\n",
       "         -6.360e-02, -1.127e-01,  3.530e-02,  2.120e-02, -6.090e-02,\n",
       "         -1.483e-01, -3.080e-02, -7.681e-01,  4.510e-02,  6.200e-03,\n",
       "         -1.108e-01, -1.167e-01,  2.080e-01,  3.320e-02, -2.070e-02,\n",
       "         -1.250e-01, -1.418e-01,  1.279e-01, -3.970e-02, -1.530e-02,\n",
       "          5.080e-02,  4.710e-02, -6.600e-03,  1.740e-02, -5.250e-02,\n",
       "          2.140e-02,  2.500e-03,  3.580e-02,  1.115e-01, -8.900e-03,\n",
       "          1.160e-01, -1.130e-02,  5.200e-03,  1.180e-01,  4.206e-01,\n",
       "          1.220e-02,  5.700e-02, -9.100e-03, -2.539e-01, -3.300e-03,\n",
       "          1.401e-01, -8.000e-04,  6.430e-02, -2.602e-01,  2.130e-02,\n",
       "          1.616e-01, -1.225e-01, -1.296e-01,  5.240e-02, -2.500e-02,\n",
       "         -8.160e-02, -2.350e-02,  4.720e-02, -1.650e-02,  5.810e-02,\n",
       "         -2.563e-01, -7.400e-02, -1.620e-02, -6.420e-02,  2.326e-01,\n",
       "         -3.170e-02,  6.500e-03,  4.350e-02,  9.300e-03, -1.178e-01,\n",
       "          9.680e-02, -1.340e-02, -7.690e-02,  2.380e-02, -1.738e-01,\n",
       "         -1.450e-02, -6.170e-02, -5.410e-02, -5.550e-02, -3.698e-01,\n",
       "         -1.377e-01, -3.180e-02, -2.355e-01,  5.240e-02, -1.537e-01,\n",
       "          1.726e-01,  3.770e-02,  1.187e-01, -2.134e-01,  2.110e-02,\n",
       "          8.490e-02,  9.720e-02, -1.306e-01, -3.290e-02, -7.650e-02,\n",
       "          1.937e-01, -2.960e-02,  7.170e-02,  2.690e-02, -1.057e-01,\n",
       "          3.200e-02,  7.700e-02, -8.760e-02,  2.831e-01,  1.690e-02,\n",
       "         -4.290e-02,  1.161e-01, -9.800e-03, -8.130e-02, -3.070e-02,\n",
       "         -1.250e-02,  5.100e-02,  1.489e-01, -1.497e-01,  1.410e-01,\n",
       "          2.220e-02,  3.000e-04,  1.460e-02,  5.850e-02,  1.100e-03,\n",
       "         -4.360e-02,  7.400e-02,  4.340e-02,  5.880e-02, -2.657e-01,\n",
       "         -9.000e-03,  1.149e-01, -1.054e-01, -1.080e-02, -6.570e-02,\n",
       "         -2.301e-01, -2.220e-02,  2.280e-02,  2.110e-02,  2.018e-01,\n",
       "          2.087e-01,  2.543e-01, -1.050e-02,  3.320e-02,  8.310e-02,\n",
       "         -8.300e-03, -4.460e-02, -1.043e-01,  6.240e-02,  1.440e-01,\n",
       "         -7.810e-02, -3.770e-02, -1.402e-01,  2.362e-01, -9.820e-02,\n",
       "          4.010e-02,  5.420e-02, -7.730e-02, -4.880e-02,  2.670e-02,\n",
       "          1.035e-01,  9.500e-03,  7.310e-02,  2.603e-01,  4.200e-03,\n",
       "          1.124e-01,  1.970e-01, -1.377e-01, -1.770e-02,  1.377e-01,\n",
       "          7.220e-02,  1.613e-01,  1.321e-01, -2.120e-02, -1.130e-02,\n",
       "          4.510e-02, -7.260e-02, -2.900e-02, -1.279e-01, -1.159e-01,\n",
       "          1.030e-02, -1.519e-01,  2.510e-02, -3.930e-02, -6.200e-02,\n",
       "          4.310e-02, -1.120e-02,  8.650e-02, -3.510e-02, -8.900e-03,\n",
       "         -6.740e-02, -4.120e-02,  1.780e-02,  1.250e-01, -1.206e-01,\n",
       "         -1.380e-02, -7.200e-03,  2.376e-01,  1.030e-01, -5.390e-02,\n",
       "          2.830e-02,  8.700e-03, -4.330e-02, -2.478e-01,  6.260e-02,\n",
       "         -1.140e-02,  3.540e-02,  6.450e-02, -7.620e-02,  6.440e-02,\n",
       "          2.700e-02,  4.170e-02, -2.950e-02,  5.700e-03,  2.897e-01,\n",
       "         -4.570e-02,  1.536e-01,  5.970e-02, -1.020e-02,  1.500e-01,\n",
       "         -1.010e-02, -1.190e-02,  1.900e-03,  9.930e-02,  1.377e-01,\n",
       "          2.290e-02, -3.220e-02, -5.400e-02,  4.300e-03, -1.124e-01,\n",
       "          3.000e-02, -1.333e-01,  7.590e-02, -9.870e-02,  2.960e-02,\n",
       "          4.650e-02, -1.648e-01,  1.900e-02, -5.510e-02, -4.450e-02,\n",
       "         -1.550e-02,  1.090e-01, -7.970e-02,  8.700e-03, -7.630e-02,\n",
       "         -1.000e-02,  2.620e-02, -6.710e-02, -1.489e-01,  3.760e-02,\n",
       "         -1.027e-01, -6.520e-02, -8.100e-03,  6.130e-02, -4.130e-02,\n",
       "          1.132e-01, -1.560e-02, -1.584e-01,  2.490e-02,  1.890e-02,\n",
       "         -1.242e-01, -1.870e-01,  1.405e-01, -8.830e-02, -1.164e-01]],\n",
       "       dtype=float32),\n",
       " array([[ 7.890e-02, -3.130e-02,  1.218e-01, -1.990e-02, -1.300e-03,\n",
       "          9.540e-02,  2.630e-02, -6.500e-02, -5.340e-02, -2.390e-02,\n",
       "         -1.320e-02,  1.489e-01, -5.200e-03, -3.660e-02, -1.333e-01,\n",
       "         -5.580e-02,  1.494e-01,  4.430e-02,  1.756e-01, -1.610e-02,\n",
       "         -2.290e-02,  1.308e-01, -9.020e-02,  2.010e-02,  3.900e-03,\n",
       "          9.080e-02, -2.005e-01, -4.420e-02,  1.900e-03, -2.419e-01,\n",
       "          8.230e-02, -5.280e-02,  5.300e-02,  1.000e-03,  5.660e-02,\n",
       "          4.590e-02, -5.060e-02, -2.840e-02,  9.670e-02,  1.600e-03,\n",
       "          2.010e-02,  1.579e-01, -2.139e-01, -1.360e-02, -4.140e-02,\n",
       "         -4.800e-02,  1.031e-01, -2.014e-01,  7.270e-02, -2.520e-02,\n",
       "          4.880e-02,  1.396e-01, -6.528e-01,  6.020e-02, -1.086e-01,\n",
       "          9.800e-03,  3.830e-02,  1.621e-01,  1.611e-01, -2.870e-02,\n",
       "          7.360e-02, -1.547e-01, -7.870e-02,  1.750e-02, -6.510e-02,\n",
       "         -1.969e-01,  1.052e-01,  1.200e-03,  2.200e-03, -3.840e-02,\n",
       "          1.760e-02, -6.850e-02,  1.294e-01,  8.590e-02, -2.400e-03,\n",
       "          4.460e-02,  1.436e-01,  8.250e-02, -1.244e-01,  1.198e-01,\n",
       "          1.930e-02, -5.650e-02, -1.221e-01, -2.329e-01, -8.400e-03,\n",
       "         -9.490e-02, -2.190e-02, -1.307e-01,  1.991e-01,  5.820e-02,\n",
       "         -1.060e-02,  1.526e-01, -3.070e-02, -9.780e-02,  8.910e-02,\n",
       "          9.040e-02,  6.000e-02,  9.070e-02,  6.680e-02,  3.090e-02,\n",
       "         -2.008e-01,  1.307e-01,  1.450e-02, -1.256e-01, -5.850e-02,\n",
       "          7.550e-02,  1.685e-01, -2.000e-03, -1.518e-01,  5.900e-02,\n",
       "          1.163e-01,  1.540e-02,  9.630e-02, -7.350e-02, -8.720e-02,\n",
       "         -1.350e-02, -2.380e-02,  1.860e-02, -2.080e-02, -4.789e-01,\n",
       "          1.039e-01,  9.420e-02, -2.600e-02, -1.324e-01,  1.907e-01,\n",
       "          2.562e-01,  3.760e-02, -7.000e-02,  2.327e-01,  3.700e-02,\n",
       "          1.085e-01,  2.276e-01, -2.960e-02, -5.190e-02,  9.770e-02,\n",
       "          6.390e-02, -5.150e-02,  1.930e-02, -6.480e-02,  6.570e-02,\n",
       "          5.100e-02, -5.230e-02,  2.760e-02,  2.979e-01,  6.810e-02,\n",
       "          1.250e-02,  8.390e-02, -1.107e-01, -5.560e-02,  3.410e-02,\n",
       "         -1.160e-02, -8.400e-03,  7.960e-02, -3.770e-02,  1.055e-01,\n",
       "          9.940e-02, -1.940e-02,  4.410e-02, -4.610e-02,  1.001e-01,\n",
       "         -1.496e-01, -1.239e-01,  3.990e-02,  1.870e-01,  1.030e-02,\n",
       "         -6.560e-02,  1.710e-01,  8.930e-02,  1.970e-02,  4.860e-02,\n",
       "          3.950e-02, -4.720e-02, -1.597e-01, -2.255e-01,  7.490e-02,\n",
       "          4.870e-02,  2.583e-01, -1.315e-01,  1.515e-01,  3.920e-02,\n",
       "         -7.420e-02,  1.033e-01, -1.218e-01,  2.450e-02,  2.880e-02,\n",
       "         -4.910e-02,  5.940e-02, -6.650e-02, -1.300e-02,  5.990e-02,\n",
       "         -7.660e-02,  1.352e-01,  5.160e-02,  3.610e-02,  1.410e-02,\n",
       "          4.000e-02, -6.260e-02,  1.940e-02,  1.258e-01, -1.809e-01,\n",
       "         -6.090e-02, -1.673e-01, -1.570e-02, -1.790e-01,  1.385e-01,\n",
       "          9.580e-02, -2.376e-01, -2.150e-02, -2.530e-02,  5.240e-02,\n",
       "          1.563e-01,  1.417e-01, -1.120e-02,  7.640e-02, -8.140e-02,\n",
       "         -3.200e-03, -2.340e-02, -3.600e-02, -2.460e-02,  4.570e-02,\n",
       "         -7.400e-03, -4.240e-02,  2.000e-04,  1.460e-02,  3.840e-02,\n",
       "          4.960e-02, -5.690e-02, -6.210e-02, -1.340e-02, -1.932e-01,\n",
       "         -3.233e-01,  1.990e-02,  4.230e-01,  9.000e-04, -2.440e-02,\n",
       "         -1.892e-01, -7.920e-02,  1.529e-01, -2.925e-01, -1.540e-01,\n",
       "         -1.190e-02, -7.700e-02, -1.785e-01, -3.380e-02,  6.800e-03,\n",
       "          1.930e-01,  0.000e+00, -1.067e-01, -9.800e-03,  4.261e-01,\n",
       "          5.050e-02, -5.900e-03, -6.430e-02,  9.160e-02,  1.354e-01,\n",
       "         -1.264e-01, -1.438e-01,  1.459e-01, -1.092e-01, -4.500e-02,\n",
       "         -5.780e-02, -4.730e-02,  1.462e-01, -1.800e-03, -4.404e-01,\n",
       "          3.610e-02,  1.041e-01, -5.380e-02, -2.494e-01,  1.400e-02,\n",
       "         -1.334e-01,  1.009e-01,  2.850e-02,  7.600e-03, -1.258e-01,\n",
       "          2.930e-02,  1.470e-01,  4.260e-02,  3.680e-02,  1.015e-01,\n",
       "         -1.153e-01, -5.230e-02,  1.901e-01,  5.000e-04,  8.750e-02,\n",
       "         -1.134e-01, -9.520e-02, -3.142e-01,  4.160e-02,  1.015e-01,\n",
       "         -5.200e-02, -2.300e-02, -6.490e-02,  6.460e-02,  6.380e-02,\n",
       "         -9.550e-02, -1.086e-01,  6.540e-02,  3.000e-03, -1.005e-01],\n",
       "        [-3.720e-02,  6.150e-02,  1.670e-02, -3.820e-02,  2.070e-02,\n",
       "         -1.949e-01, -5.740e-02, -1.860e-02, -7.080e-02,  3.200e-02,\n",
       "         -8.050e-02,  6.830e-02,  9.450e-02, -4.390e-02,  1.260e-02,\n",
       "         -6.460e-02,  9.700e-03, -5.300e-03, -8.910e-02, -4.000e-03,\n",
       "         -6.980e-02, -7.330e-02,  4.830e-02,  1.170e-02,  1.000e-03,\n",
       "         -8.350e-02, -7.570e-02,  1.284e-01, -1.199e-01, -1.130e-02,\n",
       "         -7.560e-02, -1.086e-01,  4.320e-02, -5.050e-02,  4.290e-02,\n",
       "         -3.300e-03,  6.440e-02,  8.340e-02, -5.590e-02,  2.590e-02,\n",
       "         -1.146e-01, -1.870e-02,  1.726e-01, -5.940e-02, -4.630e-02,\n",
       "         -6.360e-02, -1.127e-01,  3.530e-02,  2.120e-02, -6.090e-02,\n",
       "         -1.483e-01, -3.080e-02, -7.681e-01,  4.510e-02,  6.200e-03,\n",
       "         -1.108e-01, -1.167e-01,  2.080e-01,  3.320e-02, -2.070e-02,\n",
       "         -1.250e-01, -1.418e-01,  1.279e-01, -3.970e-02, -1.530e-02,\n",
       "          5.080e-02,  4.710e-02, -6.600e-03,  1.740e-02, -5.250e-02,\n",
       "          2.140e-02,  2.500e-03,  3.580e-02,  1.115e-01, -8.900e-03,\n",
       "          1.160e-01, -1.130e-02,  5.200e-03,  1.180e-01,  4.206e-01,\n",
       "          1.220e-02,  5.700e-02, -9.100e-03, -2.539e-01, -3.300e-03,\n",
       "          1.401e-01, -8.000e-04,  6.430e-02, -2.602e-01,  2.130e-02,\n",
       "          1.616e-01, -1.225e-01, -1.296e-01,  5.240e-02, -2.500e-02,\n",
       "         -8.160e-02, -2.350e-02,  4.720e-02, -1.650e-02,  5.810e-02,\n",
       "         -2.563e-01, -7.400e-02, -1.620e-02, -6.420e-02,  2.326e-01,\n",
       "         -3.170e-02,  6.500e-03,  4.350e-02,  9.300e-03, -1.178e-01,\n",
       "          9.680e-02, -1.340e-02, -7.690e-02,  2.380e-02, -1.738e-01,\n",
       "         -1.450e-02, -6.170e-02, -5.410e-02, -5.550e-02, -3.698e-01,\n",
       "         -1.377e-01, -3.180e-02, -2.355e-01,  5.240e-02, -1.537e-01,\n",
       "          1.726e-01,  3.770e-02,  1.187e-01, -2.134e-01,  2.110e-02,\n",
       "          8.490e-02,  9.720e-02, -1.306e-01, -3.290e-02, -7.650e-02,\n",
       "          1.937e-01, -2.960e-02,  7.170e-02,  2.690e-02, -1.057e-01,\n",
       "          3.200e-02,  7.700e-02, -8.760e-02,  2.831e-01,  1.690e-02,\n",
       "         -4.290e-02,  1.161e-01, -9.800e-03, -8.130e-02, -3.070e-02,\n",
       "         -1.250e-02,  5.100e-02,  1.489e-01, -1.497e-01,  1.410e-01,\n",
       "          2.220e-02,  3.000e-04,  1.460e-02,  5.850e-02,  1.100e-03,\n",
       "         -4.360e-02,  7.400e-02,  4.340e-02,  5.880e-02, -2.657e-01,\n",
       "         -9.000e-03,  1.149e-01, -1.054e-01, -1.080e-02, -6.570e-02,\n",
       "         -2.301e-01, -2.220e-02,  2.280e-02,  2.110e-02,  2.018e-01,\n",
       "          2.087e-01,  2.543e-01, -1.050e-02,  3.320e-02,  8.310e-02,\n",
       "         -8.300e-03, -4.460e-02, -1.043e-01,  6.240e-02,  1.440e-01,\n",
       "         -7.810e-02, -3.770e-02, -1.402e-01,  2.362e-01, -9.820e-02,\n",
       "          4.010e-02,  5.420e-02, -7.730e-02, -4.880e-02,  2.670e-02,\n",
       "          1.035e-01,  9.500e-03,  7.310e-02,  2.603e-01,  4.200e-03,\n",
       "          1.124e-01,  1.970e-01, -1.377e-01, -1.770e-02,  1.377e-01,\n",
       "          7.220e-02,  1.613e-01,  1.321e-01, -2.120e-02, -1.130e-02,\n",
       "          4.510e-02, -7.260e-02, -2.900e-02, -1.279e-01, -1.159e-01,\n",
       "          1.030e-02, -1.519e-01,  2.510e-02, -3.930e-02, -6.200e-02,\n",
       "          4.310e-02, -1.120e-02,  8.650e-02, -3.510e-02, -8.900e-03,\n",
       "         -6.740e-02, -4.120e-02,  1.780e-02,  1.250e-01, -1.206e-01,\n",
       "         -1.380e-02, -7.200e-03,  2.376e-01,  1.030e-01, -5.390e-02,\n",
       "          2.830e-02,  8.700e-03, -4.330e-02, -2.478e-01,  6.260e-02,\n",
       "         -1.140e-02,  3.540e-02,  6.450e-02, -7.620e-02,  6.440e-02,\n",
       "          2.700e-02,  4.170e-02, -2.950e-02,  5.700e-03,  2.897e-01,\n",
       "         -4.570e-02,  1.536e-01,  5.970e-02, -1.020e-02,  1.500e-01,\n",
       "         -1.010e-02, -1.190e-02,  1.900e-03,  9.930e-02,  1.377e-01,\n",
       "          2.290e-02, -3.220e-02, -5.400e-02,  4.300e-03, -1.124e-01,\n",
       "          3.000e-02, -1.333e-01,  7.590e-02, -9.870e-02,  2.960e-02,\n",
       "          4.650e-02, -1.648e-01,  1.900e-02, -5.510e-02, -4.450e-02,\n",
       "         -1.550e-02,  1.090e-01, -7.970e-02,  8.700e-03, -7.630e-02,\n",
       "         -1.000e-02,  2.620e-02, -6.710e-02, -1.489e-01,  3.760e-02,\n",
       "         -1.027e-01, -6.520e-02, -8.100e-03,  6.130e-02, -4.130e-02,\n",
       "          1.132e-01, -1.560e-02, -1.584e-01,  2.490e-02,  1.890e-02,\n",
       "         -1.242e-01, -1.870e-01,  1.405e-01, -8.830e-02, -1.164e-01],\n",
       "        [ 6.650e-02,  1.064e-01, -7.990e-02, -6.000e-02,  6.650e-02,\n",
       "          6.230e-02,  8.490e-02,  8.340e-02, -8.790e-02,  4.360e-02,\n",
       "         -3.290e-02,  2.470e-02,  9.970e-02, -6.940e-02,  1.777e-01,\n",
       "         -8.690e-02,  6.130e-02, -1.947e-01, -4.400e-03, -3.270e-02,\n",
       "         -1.520e-01, -2.190e-02, -1.621e-01,  1.271e-01, -7.420e-02,\n",
       "         -1.570e-02, -2.490e-02, -5.260e-02,  2.007e-01, -4.560e-02,\n",
       "          6.820e-02,  1.510e-02, -4.390e-02,  5.480e-02, -3.750e-02,\n",
       "          9.260e-02, -1.193e-01,  1.728e-01,  8.780e-02,  8.130e-02,\n",
       "          7.350e-02,  6.950e-02, -1.136e-01,  4.800e-02, -7.980e-02,\n",
       "          1.130e-02,  4.980e-02, -1.300e-02, -5.280e-02, -1.099e-01,\n",
       "         -7.440e-02,  8.780e-02, -7.191e-01, -1.230e-02,  1.053e-01,\n",
       "         -1.034e-01, -1.089e-01,  3.890e-02,  1.740e-02, -6.990e-02,\n",
       "         -1.223e-01, -6.070e-02,  6.700e-02,  1.830e-02, -6.280e-02,\n",
       "         -3.750e-02,  1.335e-01,  1.702e-01,  2.120e-02,  3.120e-02,\n",
       "         -6.300e-03, -1.307e-01,  2.420e-02,  2.620e-02,  1.351e-01,\n",
       "         -7.700e-02, -1.082e-01,  2.740e-02,  1.325e-01,  2.672e-01,\n",
       "          1.000e-03, -1.130e-02, -2.920e-02, -1.065e-01,  3.460e-02,\n",
       "          5.870e-02, -5.700e-02, -4.160e-02,  2.995e-01,  5.360e-02,\n",
       "          2.834e-01,  8.740e-02, -1.110e-01,  5.260e-02, -2.740e-02,\n",
       "          8.020e-02, -6.580e-02,  1.900e-02, -1.044e-01, -1.173e-01,\n",
       "         -1.941e-01, -2.187e-01,  7.530e-02, -1.339e-01, -3.250e-02,\n",
       "          6.910e-02, -9.600e-03,  1.285e-01,  1.710e-02, -2.292e-01,\n",
       "          2.444e-01,  7.100e-02,  1.002e-01,  8.290e-02, -7.860e-02,\n",
       "         -9.100e-03, -5.500e-03,  1.895e-01,  1.594e-01, -2.081e-01,\n",
       "          1.289e-01,  1.427e-01, -2.180e-02,  6.370e-02,  7.690e-02,\n",
       "          2.382e-01,  5.500e-03,  1.710e-02, -6.000e-04, -1.398e-01,\n",
       "          2.470e-02, -5.000e-04,  1.605e-01, -1.170e-02,  8.280e-02,\n",
       "         -1.093e-01, -1.079e-01,  1.415e-01,  3.020e-02, -3.430e-02,\n",
       "          9.940e-02,  3.080e-01,  1.003e-01,  1.525e-01,  2.247e-01,\n",
       "          3.690e-02,  3.800e-03, -3.500e-02,  7.010e-02,  4.700e-03,\n",
       "          2.320e-02, -8.500e-03, -7.640e-02,  8.870e-02,  7.330e-02,\n",
       "          2.271e-01, -7.080e-02,  1.870e-02,  1.270e-02,  1.207e-01,\n",
       "         -2.940e-02, -2.550e-02,  1.100e-01,  2.044e-01,  1.448e-01,\n",
       "         -1.214e-01,  1.385e-01,  3.747e-01, -1.499e-01, -7.100e-02,\n",
       "          1.337e-01, -7.160e-02, -7.940e-02,  9.170e-02, -9.440e-02,\n",
       "         -5.790e-02,  2.827e-01, -1.561e-01,  1.126e-01, -8.520e-02,\n",
       "          9.800e-03, -3.430e-02,  3.000e-03,  4.300e-02, -1.204e-01,\n",
       "         -1.387e-01, -9.210e-02, -1.950e-02, -2.057e-01,  1.185e-01,\n",
       "          1.640e-02, -1.582e-01,  1.245e-01, -2.430e-01,  9.100e-02,\n",
       "         -5.880e-02, -1.416e-01,  1.447e-01,  8.220e-02,  8.320e-02,\n",
       "         -9.040e-02, -2.004e-01,  8.900e-02,  5.050e-02, -2.690e-02,\n",
       "          3.890e-02,  7.150e-02,  2.060e-02, -1.439e-01, -3.090e-02,\n",
       "         -5.910e-02, -1.257e-01,  3.720e-02,  8.900e-03, -2.083e-01,\n",
       "         -1.277e-01,  6.380e-02, -6.400e-02, -1.788e-01, -2.420e-02,\n",
       "         -8.550e-02, -9.320e-02, -8.230e-02, -1.600e-02,  7.100e-03,\n",
       "         -4.450e-02, -4.480e-02, -2.158e-01,  1.318e-01,  1.064e-01,\n",
       "          5.600e-03,  2.700e-02,  3.291e-01, -1.467e-01,  1.058e-01,\n",
       "         -1.795e-01, -9.070e-02,  5.690e-02, -2.181e-01,  2.370e-02,\n",
       "         -1.306e-01,  1.240e-02, -2.139e-01, -6.160e-02,  5.490e-02,\n",
       "         -2.736e-01,  6.900e-02, -1.150e-02,  1.476e-01,  3.688e-01,\n",
       "         -1.550e-02,  4.211e-01, -2.310e-02,  4.010e-02, -2.199e-01,\n",
       "          6.500e-02, -2.640e-02,  2.023e-01,  7.180e-02, -9.220e-02,\n",
       "         -1.592e-01, -7.200e-02,  7.680e-02,  7.710e-02, -3.072e-01,\n",
       "          8.750e-02,  3.280e-02,  1.508e-01, -1.216e-01,  1.969e-01,\n",
       "         -1.467e-01,  1.176e-01, -6.930e-02,  1.370e-01, -3.140e-02,\n",
       "          1.525e-01, -2.330e-02,  2.000e-03,  3.850e-02, -8.750e-02,\n",
       "         -1.340e-02, -2.120e-02,  2.257e-01,  1.138e-01,  8.300e-02,\n",
       "          1.124e-01,  1.420e-02, -1.266e-01, -3.470e-02, -1.512e-01,\n",
       "          8.440e-02, -1.503e-01,  2.096e-01,  1.055e-01,  1.180e-02,\n",
       "          8.120e-02, -5.990e-02,  1.672e-01,  1.297e-01,  1.036e-01]],\n",
       "       dtype=float32),\n",
       " array([[-3.720e-02,  6.150e-02,  1.670e-02, -3.820e-02,  2.070e-02,\n",
       "         -1.949e-01, -5.740e-02, -1.860e-02, -7.080e-02,  3.200e-02,\n",
       "         -8.050e-02,  6.830e-02,  9.450e-02, -4.390e-02,  1.260e-02,\n",
       "         -6.460e-02,  9.700e-03, -5.300e-03, -8.910e-02, -4.000e-03,\n",
       "         -6.980e-02, -7.330e-02,  4.830e-02,  1.170e-02,  1.000e-03,\n",
       "         -8.350e-02, -7.570e-02,  1.284e-01, -1.199e-01, -1.130e-02,\n",
       "         -7.560e-02, -1.086e-01,  4.320e-02, -5.050e-02,  4.290e-02,\n",
       "         -3.300e-03,  6.440e-02,  8.340e-02, -5.590e-02,  2.590e-02,\n",
       "         -1.146e-01, -1.870e-02,  1.726e-01, -5.940e-02, -4.630e-02,\n",
       "         -6.360e-02, -1.127e-01,  3.530e-02,  2.120e-02, -6.090e-02,\n",
       "         -1.483e-01, -3.080e-02, -7.681e-01,  4.510e-02,  6.200e-03,\n",
       "         -1.108e-01, -1.167e-01,  2.080e-01,  3.320e-02, -2.070e-02,\n",
       "         -1.250e-01, -1.418e-01,  1.279e-01, -3.970e-02, -1.530e-02,\n",
       "          5.080e-02,  4.710e-02, -6.600e-03,  1.740e-02, -5.250e-02,\n",
       "          2.140e-02,  2.500e-03,  3.580e-02,  1.115e-01, -8.900e-03,\n",
       "          1.160e-01, -1.130e-02,  5.200e-03,  1.180e-01,  4.206e-01,\n",
       "          1.220e-02,  5.700e-02, -9.100e-03, -2.539e-01, -3.300e-03,\n",
       "          1.401e-01, -8.000e-04,  6.430e-02, -2.602e-01,  2.130e-02,\n",
       "          1.616e-01, -1.225e-01, -1.296e-01,  5.240e-02, -2.500e-02,\n",
       "         -8.160e-02, -2.350e-02,  4.720e-02, -1.650e-02,  5.810e-02,\n",
       "         -2.563e-01, -7.400e-02, -1.620e-02, -6.420e-02,  2.326e-01,\n",
       "         -3.170e-02,  6.500e-03,  4.350e-02,  9.300e-03, -1.178e-01,\n",
       "          9.680e-02, -1.340e-02, -7.690e-02,  2.380e-02, -1.738e-01,\n",
       "         -1.450e-02, -6.170e-02, -5.410e-02, -5.550e-02, -3.698e-01,\n",
       "         -1.377e-01, -3.180e-02, -2.355e-01,  5.240e-02, -1.537e-01,\n",
       "          1.726e-01,  3.770e-02,  1.187e-01, -2.134e-01,  2.110e-02,\n",
       "          8.490e-02,  9.720e-02, -1.306e-01, -3.290e-02, -7.650e-02,\n",
       "          1.937e-01, -2.960e-02,  7.170e-02,  2.690e-02, -1.057e-01,\n",
       "          3.200e-02,  7.700e-02, -8.760e-02,  2.831e-01,  1.690e-02,\n",
       "         -4.290e-02,  1.161e-01, -9.800e-03, -8.130e-02, -3.070e-02,\n",
       "         -1.250e-02,  5.100e-02,  1.489e-01, -1.497e-01,  1.410e-01,\n",
       "          2.220e-02,  3.000e-04,  1.460e-02,  5.850e-02,  1.100e-03,\n",
       "         -4.360e-02,  7.400e-02,  4.340e-02,  5.880e-02, -2.657e-01,\n",
       "         -9.000e-03,  1.149e-01, -1.054e-01, -1.080e-02, -6.570e-02,\n",
       "         -2.301e-01, -2.220e-02,  2.280e-02,  2.110e-02,  2.018e-01,\n",
       "          2.087e-01,  2.543e-01, -1.050e-02,  3.320e-02,  8.310e-02,\n",
       "         -8.300e-03, -4.460e-02, -1.043e-01,  6.240e-02,  1.440e-01,\n",
       "         -7.810e-02, -3.770e-02, -1.402e-01,  2.362e-01, -9.820e-02,\n",
       "          4.010e-02,  5.420e-02, -7.730e-02, -4.880e-02,  2.670e-02,\n",
       "          1.035e-01,  9.500e-03,  7.310e-02,  2.603e-01,  4.200e-03,\n",
       "          1.124e-01,  1.970e-01, -1.377e-01, -1.770e-02,  1.377e-01,\n",
       "          7.220e-02,  1.613e-01,  1.321e-01, -2.120e-02, -1.130e-02,\n",
       "          4.510e-02, -7.260e-02, -2.900e-02, -1.279e-01, -1.159e-01,\n",
       "          1.030e-02, -1.519e-01,  2.510e-02, -3.930e-02, -6.200e-02,\n",
       "          4.310e-02, -1.120e-02,  8.650e-02, -3.510e-02, -8.900e-03,\n",
       "         -6.740e-02, -4.120e-02,  1.780e-02,  1.250e-01, -1.206e-01,\n",
       "         -1.380e-02, -7.200e-03,  2.376e-01,  1.030e-01, -5.390e-02,\n",
       "          2.830e-02,  8.700e-03, -4.330e-02, -2.478e-01,  6.260e-02,\n",
       "         -1.140e-02,  3.540e-02,  6.450e-02, -7.620e-02,  6.440e-02,\n",
       "          2.700e-02,  4.170e-02, -2.950e-02,  5.700e-03,  2.897e-01,\n",
       "         -4.570e-02,  1.536e-01,  5.970e-02, -1.020e-02,  1.500e-01,\n",
       "         -1.010e-02, -1.190e-02,  1.900e-03,  9.930e-02,  1.377e-01,\n",
       "          2.290e-02, -3.220e-02, -5.400e-02,  4.300e-03, -1.124e-01,\n",
       "          3.000e-02, -1.333e-01,  7.590e-02, -9.870e-02,  2.960e-02,\n",
       "          4.650e-02, -1.648e-01,  1.900e-02, -5.510e-02, -4.450e-02,\n",
       "         -1.550e-02,  1.090e-01, -7.970e-02,  8.700e-03, -7.630e-02,\n",
       "         -1.000e-02,  2.620e-02, -6.710e-02, -1.489e-01,  3.760e-02,\n",
       "         -1.027e-01, -6.520e-02, -8.100e-03,  6.130e-02, -4.130e-02,\n",
       "          1.132e-01, -1.560e-02, -1.584e-01,  2.490e-02,  1.890e-02,\n",
       "         -1.242e-01, -1.870e-01,  1.405e-01, -8.830e-02, -1.164e-01],\n",
       "        [ 6.650e-02,  1.064e-01, -7.990e-02, -6.000e-02,  6.650e-02,\n",
       "          6.230e-02,  8.490e-02,  8.340e-02, -8.790e-02,  4.360e-02,\n",
       "         -3.290e-02,  2.470e-02,  9.970e-02, -6.940e-02,  1.777e-01,\n",
       "         -8.690e-02,  6.130e-02, -1.947e-01, -4.400e-03, -3.270e-02,\n",
       "         -1.520e-01, -2.190e-02, -1.621e-01,  1.271e-01, -7.420e-02,\n",
       "         -1.570e-02, -2.490e-02, -5.260e-02,  2.007e-01, -4.560e-02,\n",
       "          6.820e-02,  1.510e-02, -4.390e-02,  5.480e-02, -3.750e-02,\n",
       "          9.260e-02, -1.193e-01,  1.728e-01,  8.780e-02,  8.130e-02,\n",
       "          7.350e-02,  6.950e-02, -1.136e-01,  4.800e-02, -7.980e-02,\n",
       "          1.130e-02,  4.980e-02, -1.300e-02, -5.280e-02, -1.099e-01,\n",
       "         -7.440e-02,  8.780e-02, -7.191e-01, -1.230e-02,  1.053e-01,\n",
       "         -1.034e-01, -1.089e-01,  3.890e-02,  1.740e-02, -6.990e-02,\n",
       "         -1.223e-01, -6.070e-02,  6.700e-02,  1.830e-02, -6.280e-02,\n",
       "         -3.750e-02,  1.335e-01,  1.702e-01,  2.120e-02,  3.120e-02,\n",
       "         -6.300e-03, -1.307e-01,  2.420e-02,  2.620e-02,  1.351e-01,\n",
       "         -7.700e-02, -1.082e-01,  2.740e-02,  1.325e-01,  2.672e-01,\n",
       "          1.000e-03, -1.130e-02, -2.920e-02, -1.065e-01,  3.460e-02,\n",
       "          5.870e-02, -5.700e-02, -4.160e-02,  2.995e-01,  5.360e-02,\n",
       "          2.834e-01,  8.740e-02, -1.110e-01,  5.260e-02, -2.740e-02,\n",
       "          8.020e-02, -6.580e-02,  1.900e-02, -1.044e-01, -1.173e-01,\n",
       "         -1.941e-01, -2.187e-01,  7.530e-02, -1.339e-01, -3.250e-02,\n",
       "          6.910e-02, -9.600e-03,  1.285e-01,  1.710e-02, -2.292e-01,\n",
       "          2.444e-01,  7.100e-02,  1.002e-01,  8.290e-02, -7.860e-02,\n",
       "         -9.100e-03, -5.500e-03,  1.895e-01,  1.594e-01, -2.081e-01,\n",
       "          1.289e-01,  1.427e-01, -2.180e-02,  6.370e-02,  7.690e-02,\n",
       "          2.382e-01,  5.500e-03,  1.710e-02, -6.000e-04, -1.398e-01,\n",
       "          2.470e-02, -5.000e-04,  1.605e-01, -1.170e-02,  8.280e-02,\n",
       "         -1.093e-01, -1.079e-01,  1.415e-01,  3.020e-02, -3.430e-02,\n",
       "          9.940e-02,  3.080e-01,  1.003e-01,  1.525e-01,  2.247e-01,\n",
       "          3.690e-02,  3.800e-03, -3.500e-02,  7.010e-02,  4.700e-03,\n",
       "          2.320e-02, -8.500e-03, -7.640e-02,  8.870e-02,  7.330e-02,\n",
       "          2.271e-01, -7.080e-02,  1.870e-02,  1.270e-02,  1.207e-01,\n",
       "         -2.940e-02, -2.550e-02,  1.100e-01,  2.044e-01,  1.448e-01,\n",
       "         -1.214e-01,  1.385e-01,  3.747e-01, -1.499e-01, -7.100e-02,\n",
       "          1.337e-01, -7.160e-02, -7.940e-02,  9.170e-02, -9.440e-02,\n",
       "         -5.790e-02,  2.827e-01, -1.561e-01,  1.126e-01, -8.520e-02,\n",
       "          9.800e-03, -3.430e-02,  3.000e-03,  4.300e-02, -1.204e-01,\n",
       "         -1.387e-01, -9.210e-02, -1.950e-02, -2.057e-01,  1.185e-01,\n",
       "          1.640e-02, -1.582e-01,  1.245e-01, -2.430e-01,  9.100e-02,\n",
       "         -5.880e-02, -1.416e-01,  1.447e-01,  8.220e-02,  8.320e-02,\n",
       "         -9.040e-02, -2.004e-01,  8.900e-02,  5.050e-02, -2.690e-02,\n",
       "          3.890e-02,  7.150e-02,  2.060e-02, -1.439e-01, -3.090e-02,\n",
       "         -5.910e-02, -1.257e-01,  3.720e-02,  8.900e-03, -2.083e-01,\n",
       "         -1.277e-01,  6.380e-02, -6.400e-02, -1.788e-01, -2.420e-02,\n",
       "         -8.550e-02, -9.320e-02, -8.230e-02, -1.600e-02,  7.100e-03,\n",
       "         -4.450e-02, -4.480e-02, -2.158e-01,  1.318e-01,  1.064e-01,\n",
       "          5.600e-03,  2.700e-02,  3.291e-01, -1.467e-01,  1.058e-01,\n",
       "         -1.795e-01, -9.070e-02,  5.690e-02, -2.181e-01,  2.370e-02,\n",
       "         -1.306e-01,  1.240e-02, -2.139e-01, -6.160e-02,  5.490e-02,\n",
       "         -2.736e-01,  6.900e-02, -1.150e-02,  1.476e-01,  3.688e-01,\n",
       "         -1.550e-02,  4.211e-01, -2.310e-02,  4.010e-02, -2.199e-01,\n",
       "          6.500e-02, -2.640e-02,  2.023e-01,  7.180e-02, -9.220e-02,\n",
       "         -1.592e-01, -7.200e-02,  7.680e-02,  7.710e-02, -3.072e-01,\n",
       "          8.750e-02,  3.280e-02,  1.508e-01, -1.216e-01,  1.969e-01,\n",
       "         -1.467e-01,  1.176e-01, -6.930e-02,  1.370e-01, -3.140e-02,\n",
       "          1.525e-01, -2.330e-02,  2.000e-03,  3.850e-02, -8.750e-02,\n",
       "         -1.340e-02, -2.120e-02,  2.257e-01,  1.138e-01,  8.300e-02,\n",
       "          1.124e-01,  1.420e-02, -1.266e-01, -3.470e-02, -1.512e-01,\n",
       "          8.440e-02, -1.503e-01,  2.096e-01,  1.055e-01,  1.180e-02,\n",
       "          8.120e-02, -5.990e-02,  1.672e-01,  1.297e-01,  1.036e-01],\n",
       "        [-7.640e-02,  4.510e-02, -8.830e-02,  2.230e-02, -2.671e-01,\n",
       "          4.040e-02,  1.210e-02, -3.490e-02,  5.150e-02, -1.087e-01,\n",
       "          3.910e-02,  6.170e-02, -2.400e-02,  1.430e-02, -7.080e-02,\n",
       "         -2.070e-02, -3.650e-02,  4.890e-02, -1.316e-01, -3.600e-02,\n",
       "          7.410e-02,  4.990e-02,  3.890e-02,  2.090e-02,  3.800e-02,\n",
       "          8.420e-02,  2.130e-02,  8.520e-02,  1.540e-02,  1.890e-02,\n",
       "          6.080e-02, -3.500e-02, -1.372e-01, -5.270e-02,  1.770e-02,\n",
       "          1.280e-02,  1.870e-02,  6.530e-02, -7.280e-02,  6.800e-02,\n",
       "         -2.000e-02,  3.300e-02, -1.300e-03, -1.002e-01, -1.118e-01,\n",
       "          2.040e-02,  6.000e-04, -1.430e-02,  5.000e-03,  3.700e-03,\n",
       "         -5.920e-02,  5.700e-02, -5.512e-01, -3.990e-02, -2.390e-02,\n",
       "         -3.630e-02, -3.840e-02,  3.650e-02, -4.260e-02, -2.700e-02,\n",
       "         -4.260e-02, -2.380e-02, -5.070e-02, -2.450e-02,  5.600e-03,\n",
       "          1.088e-01, -5.940e-02,  1.710e-02,  3.140e-02,  3.350e-02,\n",
       "          4.680e-02,  2.050e-02, -8.800e-03, -6.690e-02, -1.210e-02,\n",
       "         -6.830e-02,  1.580e-02, -3.100e-02,  1.330e-02,  1.679e-01,\n",
       "          2.850e-02, -1.956e-01, -4.350e-02, -9.050e-02,  1.210e-02,\n",
       "          4.380e-02, -2.570e-02,  1.460e-02, -7.351e-01,  2.280e-02,\n",
       "         -1.610e-02, -2.200e-03, -3.160e-02, -2.510e-02,  4.200e-03,\n",
       "          3.770e-02, -6.620e-02, -1.580e-02, -3.100e-03,  9.940e-02,\n",
       "         -1.238e-01, -2.570e-02, -2.560e-02,  5.000e-03,  2.160e-02,\n",
       "          6.820e-02, -1.335e-01,  2.680e-02, -8.120e-02, -2.820e-02,\n",
       "         -4.880e-02,  5.900e-03, -3.630e-02, -7.990e-02,  1.410e-02,\n",
       "         -4.700e-03,  5.400e-03, -4.670e-02,  3.600e-03, -2.524e-01,\n",
       "         -6.980e-02, -1.790e-02, -3.180e-02, -9.790e-02, -1.305e-01,\n",
       "          1.492e-01,  9.610e-02,  9.260e-02,  8.300e-03,  1.490e-02,\n",
       "          4.600e-02,  8.680e-02,  3.730e-02,  4.060e-02, -2.700e-02,\n",
       "         -2.346e-01, -8.040e-02, -5.290e-02, -9.900e-03,  2.430e-02,\n",
       "          0.000e+00,  7.780e-02,  6.670e-02,  2.532e-01,  1.450e-02,\n",
       "          1.000e-02,  3.000e-04, -7.810e-02,  1.220e-02, -8.160e-02,\n",
       "         -1.570e-02,  5.220e-02,  1.310e-02, -7.340e-02,  2.400e-03,\n",
       "         -5.000e-03, -4.160e-02,  1.070e-02, -6.480e-02, -6.170e-02,\n",
       "          5.480e-02,  1.000e-02,  2.440e-02,  1.800e-03, -3.293e-01,\n",
       "          8.300e-03,  6.160e-02,  3.980e-02,  9.000e-04,  1.090e-02,\n",
       "         -3.260e-02, -4.050e-02,  4.460e-02,  5.450e-02,  3.650e-02,\n",
       "         -1.185e-01,  1.119e-01, -2.742e-01,  7.000e-03, -8.000e-03,\n",
       "         -4.660e-02, -1.235e-01,  5.010e-02, -2.500e-02,  5.940e-02,\n",
       "          1.180e-02,  4.330e-02, -6.320e-02,  2.194e-01,  3.300e-02,\n",
       "         -9.100e-03, -4.060e-02, -4.400e-03,  6.220e-02,  3.590e-02,\n",
       "         -5.990e-02,  1.460e-02,  2.130e-02,  3.371e-01,  2.550e-02,\n",
       "         -1.650e-02,  3.640e-02, -1.830e-02,  1.370e-02, -4.960e-02,\n",
       "         -4.700e-03,  8.900e-03,  5.060e-02, -3.470e-02,  1.250e-02,\n",
       "          6.810e-02,  9.760e-02, -1.590e-02,  3.620e-02, -7.500e-03,\n",
       "         -6.600e-03, -5.170e-02, -3.690e-02,  3.380e-02,  1.376e-01,\n",
       "         -6.870e-02,  9.520e-02,  2.170e-02,  4.100e-03,  2.500e-03,\n",
       "         -8.980e-02,  3.450e-02,  3.260e-02,  3.320e-02, -1.976e-01,\n",
       "          1.040e-02, -1.660e-02,  3.335e-01, -5.040e-02, -6.000e-03,\n",
       "         -1.911e-01,  4.360e-02,  3.620e-02, -1.601e-01, -3.730e-02,\n",
       "          1.100e-02, -7.590e-02,  1.230e-02, -4.870e-02, -1.140e-02,\n",
       "         -3.040e-02, -3.210e-02, -8.730e-02, -2.360e-02,  1.024e-01,\n",
       "         -9.900e-03,  3.310e-02, -5.570e-02,  5.360e-02,  4.660e-02,\n",
       "         -1.100e-03, -1.130e-01,  8.430e-02,  2.510e-02,  3.000e-03,\n",
       "         -1.450e-02, -8.240e-02, -4.850e-02,  2.100e-03, -2.108e-01,\n",
       "          1.200e-03,  3.170e-02,  7.190e-02, -8.510e-02, -9.020e-02,\n",
       "         -3.300e-03, -9.000e-03,  4.100e-02,  1.210e-02,  1.760e-02,\n",
       "          4.590e-02, -4.240e-02, -1.690e-02,  3.320e-02, -1.070e-02,\n",
       "          2.262e-01,  1.014e-01,  3.230e-02,  1.810e-02,  2.900e-03,\n",
       "         -4.020e-02, -5.090e-02,  1.120e-02, -7.020e-02,  6.710e-02,\n",
       "          2.700e-02, -4.800e-03,  1.600e-02, -4.760e-02, -8.470e-02,\n",
       "         -1.418e-01, -1.198e-01,  1.588e-01,  5.200e-03, -1.040e-02]],\n",
       "       dtype=float32),\n",
       " array([[ 6.650e-02,  1.064e-01, -7.990e-02, -6.000e-02,  6.650e-02,\n",
       "          6.230e-02,  8.490e-02,  8.340e-02, -8.790e-02,  4.360e-02,\n",
       "         -3.290e-02,  2.470e-02,  9.970e-02, -6.940e-02,  1.777e-01,\n",
       "         -8.690e-02,  6.130e-02, -1.947e-01, -4.400e-03, -3.270e-02,\n",
       "         -1.520e-01, -2.190e-02, -1.621e-01,  1.271e-01, -7.420e-02,\n",
       "         -1.570e-02, -2.490e-02, -5.260e-02,  2.007e-01, -4.560e-02,\n",
       "          6.820e-02,  1.510e-02, -4.390e-02,  5.480e-02, -3.750e-02,\n",
       "          9.260e-02, -1.193e-01,  1.728e-01,  8.780e-02,  8.130e-02,\n",
       "          7.350e-02,  6.950e-02, -1.136e-01,  4.800e-02, -7.980e-02,\n",
       "          1.130e-02,  4.980e-02, -1.300e-02, -5.280e-02, -1.099e-01,\n",
       "         -7.440e-02,  8.780e-02, -7.191e-01, -1.230e-02,  1.053e-01,\n",
       "         -1.034e-01, -1.089e-01,  3.890e-02,  1.740e-02, -6.990e-02,\n",
       "         -1.223e-01, -6.070e-02,  6.700e-02,  1.830e-02, -6.280e-02,\n",
       "         -3.750e-02,  1.335e-01,  1.702e-01,  2.120e-02,  3.120e-02,\n",
       "         -6.300e-03, -1.307e-01,  2.420e-02,  2.620e-02,  1.351e-01,\n",
       "         -7.700e-02, -1.082e-01,  2.740e-02,  1.325e-01,  2.672e-01,\n",
       "          1.000e-03, -1.130e-02, -2.920e-02, -1.065e-01,  3.460e-02,\n",
       "          5.870e-02, -5.700e-02, -4.160e-02,  2.995e-01,  5.360e-02,\n",
       "          2.834e-01,  8.740e-02, -1.110e-01,  5.260e-02, -2.740e-02,\n",
       "          8.020e-02, -6.580e-02,  1.900e-02, -1.044e-01, -1.173e-01,\n",
       "         -1.941e-01, -2.187e-01,  7.530e-02, -1.339e-01, -3.250e-02,\n",
       "          6.910e-02, -9.600e-03,  1.285e-01,  1.710e-02, -2.292e-01,\n",
       "          2.444e-01,  7.100e-02,  1.002e-01,  8.290e-02, -7.860e-02,\n",
       "         -9.100e-03, -5.500e-03,  1.895e-01,  1.594e-01, -2.081e-01,\n",
       "          1.289e-01,  1.427e-01, -2.180e-02,  6.370e-02,  7.690e-02,\n",
       "          2.382e-01,  5.500e-03,  1.710e-02, -6.000e-04, -1.398e-01,\n",
       "          2.470e-02, -5.000e-04,  1.605e-01, -1.170e-02,  8.280e-02,\n",
       "         -1.093e-01, -1.079e-01,  1.415e-01,  3.020e-02, -3.430e-02,\n",
       "          9.940e-02,  3.080e-01,  1.003e-01,  1.525e-01,  2.247e-01,\n",
       "          3.690e-02,  3.800e-03, -3.500e-02,  7.010e-02,  4.700e-03,\n",
       "          2.320e-02, -8.500e-03, -7.640e-02,  8.870e-02,  7.330e-02,\n",
       "          2.271e-01, -7.080e-02,  1.870e-02,  1.270e-02,  1.207e-01,\n",
       "         -2.940e-02, -2.550e-02,  1.100e-01,  2.044e-01,  1.448e-01,\n",
       "         -1.214e-01,  1.385e-01,  3.747e-01, -1.499e-01, -7.100e-02,\n",
       "          1.337e-01, -7.160e-02, -7.940e-02,  9.170e-02, -9.440e-02,\n",
       "         -5.790e-02,  2.827e-01, -1.561e-01,  1.126e-01, -8.520e-02,\n",
       "          9.800e-03, -3.430e-02,  3.000e-03,  4.300e-02, -1.204e-01,\n",
       "         -1.387e-01, -9.210e-02, -1.950e-02, -2.057e-01,  1.185e-01,\n",
       "          1.640e-02, -1.582e-01,  1.245e-01, -2.430e-01,  9.100e-02,\n",
       "         -5.880e-02, -1.416e-01,  1.447e-01,  8.220e-02,  8.320e-02,\n",
       "         -9.040e-02, -2.004e-01,  8.900e-02,  5.050e-02, -2.690e-02,\n",
       "          3.890e-02,  7.150e-02,  2.060e-02, -1.439e-01, -3.090e-02,\n",
       "         -5.910e-02, -1.257e-01,  3.720e-02,  8.900e-03, -2.083e-01,\n",
       "         -1.277e-01,  6.380e-02, -6.400e-02, -1.788e-01, -2.420e-02,\n",
       "         -8.550e-02, -9.320e-02, -8.230e-02, -1.600e-02,  7.100e-03,\n",
       "         -4.450e-02, -4.480e-02, -2.158e-01,  1.318e-01,  1.064e-01,\n",
       "          5.600e-03,  2.700e-02,  3.291e-01, -1.467e-01,  1.058e-01,\n",
       "         -1.795e-01, -9.070e-02,  5.690e-02, -2.181e-01,  2.370e-02,\n",
       "         -1.306e-01,  1.240e-02, -2.139e-01, -6.160e-02,  5.490e-02,\n",
       "         -2.736e-01,  6.900e-02, -1.150e-02,  1.476e-01,  3.688e-01,\n",
       "         -1.550e-02,  4.211e-01, -2.310e-02,  4.010e-02, -2.199e-01,\n",
       "          6.500e-02, -2.640e-02,  2.023e-01,  7.180e-02, -9.220e-02,\n",
       "         -1.592e-01, -7.200e-02,  7.680e-02,  7.710e-02, -3.072e-01,\n",
       "          8.750e-02,  3.280e-02,  1.508e-01, -1.216e-01,  1.969e-01,\n",
       "         -1.467e-01,  1.176e-01, -6.930e-02,  1.370e-01, -3.140e-02,\n",
       "          1.525e-01, -2.330e-02,  2.000e-03,  3.850e-02, -8.750e-02,\n",
       "         -1.340e-02, -2.120e-02,  2.257e-01,  1.138e-01,  8.300e-02,\n",
       "          1.124e-01,  1.420e-02, -1.266e-01, -3.470e-02, -1.512e-01,\n",
       "          8.440e-02, -1.503e-01,  2.096e-01,  1.055e-01,  1.180e-02,\n",
       "          8.120e-02, -5.990e-02,  1.672e-01,  1.297e-01,  1.036e-01],\n",
       "        [-7.640e-02,  4.510e-02, -8.830e-02,  2.230e-02, -2.671e-01,\n",
       "          4.040e-02,  1.210e-02, -3.490e-02,  5.150e-02, -1.087e-01,\n",
       "          3.910e-02,  6.170e-02, -2.400e-02,  1.430e-02, -7.080e-02,\n",
       "         -2.070e-02, -3.650e-02,  4.890e-02, -1.316e-01, -3.600e-02,\n",
       "          7.410e-02,  4.990e-02,  3.890e-02,  2.090e-02,  3.800e-02,\n",
       "          8.420e-02,  2.130e-02,  8.520e-02,  1.540e-02,  1.890e-02,\n",
       "          6.080e-02, -3.500e-02, -1.372e-01, -5.270e-02,  1.770e-02,\n",
       "          1.280e-02,  1.870e-02,  6.530e-02, -7.280e-02,  6.800e-02,\n",
       "         -2.000e-02,  3.300e-02, -1.300e-03, -1.002e-01, -1.118e-01,\n",
       "          2.040e-02,  6.000e-04, -1.430e-02,  5.000e-03,  3.700e-03,\n",
       "         -5.920e-02,  5.700e-02, -5.512e-01, -3.990e-02, -2.390e-02,\n",
       "         -3.630e-02, -3.840e-02,  3.650e-02, -4.260e-02, -2.700e-02,\n",
       "         -4.260e-02, -2.380e-02, -5.070e-02, -2.450e-02,  5.600e-03,\n",
       "          1.088e-01, -5.940e-02,  1.710e-02,  3.140e-02,  3.350e-02,\n",
       "          4.680e-02,  2.050e-02, -8.800e-03, -6.690e-02, -1.210e-02,\n",
       "         -6.830e-02,  1.580e-02, -3.100e-02,  1.330e-02,  1.679e-01,\n",
       "          2.850e-02, -1.956e-01, -4.350e-02, -9.050e-02,  1.210e-02,\n",
       "          4.380e-02, -2.570e-02,  1.460e-02, -7.351e-01,  2.280e-02,\n",
       "         -1.610e-02, -2.200e-03, -3.160e-02, -2.510e-02,  4.200e-03,\n",
       "          3.770e-02, -6.620e-02, -1.580e-02, -3.100e-03,  9.940e-02,\n",
       "         -1.238e-01, -2.570e-02, -2.560e-02,  5.000e-03,  2.160e-02,\n",
       "          6.820e-02, -1.335e-01,  2.680e-02, -8.120e-02, -2.820e-02,\n",
       "         -4.880e-02,  5.900e-03, -3.630e-02, -7.990e-02,  1.410e-02,\n",
       "         -4.700e-03,  5.400e-03, -4.670e-02,  3.600e-03, -2.524e-01,\n",
       "         -6.980e-02, -1.790e-02, -3.180e-02, -9.790e-02, -1.305e-01,\n",
       "          1.492e-01,  9.610e-02,  9.260e-02,  8.300e-03,  1.490e-02,\n",
       "          4.600e-02,  8.680e-02,  3.730e-02,  4.060e-02, -2.700e-02,\n",
       "         -2.346e-01, -8.040e-02, -5.290e-02, -9.900e-03,  2.430e-02,\n",
       "          0.000e+00,  7.780e-02,  6.670e-02,  2.532e-01,  1.450e-02,\n",
       "          1.000e-02,  3.000e-04, -7.810e-02,  1.220e-02, -8.160e-02,\n",
       "         -1.570e-02,  5.220e-02,  1.310e-02, -7.340e-02,  2.400e-03,\n",
       "         -5.000e-03, -4.160e-02,  1.070e-02, -6.480e-02, -6.170e-02,\n",
       "          5.480e-02,  1.000e-02,  2.440e-02,  1.800e-03, -3.293e-01,\n",
       "          8.300e-03,  6.160e-02,  3.980e-02,  9.000e-04,  1.090e-02,\n",
       "         -3.260e-02, -4.050e-02,  4.460e-02,  5.450e-02,  3.650e-02,\n",
       "         -1.185e-01,  1.119e-01, -2.742e-01,  7.000e-03, -8.000e-03,\n",
       "         -4.660e-02, -1.235e-01,  5.010e-02, -2.500e-02,  5.940e-02,\n",
       "          1.180e-02,  4.330e-02, -6.320e-02,  2.194e-01,  3.300e-02,\n",
       "         -9.100e-03, -4.060e-02, -4.400e-03,  6.220e-02,  3.590e-02,\n",
       "         -5.990e-02,  1.460e-02,  2.130e-02,  3.371e-01,  2.550e-02,\n",
       "         -1.650e-02,  3.640e-02, -1.830e-02,  1.370e-02, -4.960e-02,\n",
       "         -4.700e-03,  8.900e-03,  5.060e-02, -3.470e-02,  1.250e-02,\n",
       "          6.810e-02,  9.760e-02, -1.590e-02,  3.620e-02, -7.500e-03,\n",
       "         -6.600e-03, -5.170e-02, -3.690e-02,  3.380e-02,  1.376e-01,\n",
       "         -6.870e-02,  9.520e-02,  2.170e-02,  4.100e-03,  2.500e-03,\n",
       "         -8.980e-02,  3.450e-02,  3.260e-02,  3.320e-02, -1.976e-01,\n",
       "          1.040e-02, -1.660e-02,  3.335e-01, -5.040e-02, -6.000e-03,\n",
       "         -1.911e-01,  4.360e-02,  3.620e-02, -1.601e-01, -3.730e-02,\n",
       "          1.100e-02, -7.590e-02,  1.230e-02, -4.870e-02, -1.140e-02,\n",
       "         -3.040e-02, -3.210e-02, -8.730e-02, -2.360e-02,  1.024e-01,\n",
       "         -9.900e-03,  3.310e-02, -5.570e-02,  5.360e-02,  4.660e-02,\n",
       "         -1.100e-03, -1.130e-01,  8.430e-02,  2.510e-02,  3.000e-03,\n",
       "         -1.450e-02, -8.240e-02, -4.850e-02,  2.100e-03, -2.108e-01,\n",
       "          1.200e-03,  3.170e-02,  7.190e-02, -8.510e-02, -9.020e-02,\n",
       "         -3.300e-03, -9.000e-03,  4.100e-02,  1.210e-02,  1.760e-02,\n",
       "          4.590e-02, -4.240e-02, -1.690e-02,  3.320e-02, -1.070e-02,\n",
       "          2.262e-01,  1.014e-01,  3.230e-02,  1.810e-02,  2.900e-03,\n",
       "         -4.020e-02, -5.090e-02,  1.120e-02, -7.020e-02,  6.710e-02,\n",
       "          2.700e-02, -4.800e-03,  1.600e-02, -4.760e-02, -8.470e-02,\n",
       "         -1.418e-01, -1.198e-01,  1.588e-01,  5.200e-03, -1.040e-02],\n",
       "        [ 1.350e-02,  3.530e-02, -8.150e-02, -5.900e-03, -2.810e-02,\n",
       "          1.270e-01,  4.450e-02, -2.880e-02, -1.833e-01,  4.370e-02,\n",
       "         -8.840e-02,  1.550e-02,  3.610e-02,  1.181e-01, -1.024e-01,\n",
       "         -1.064e-01, -7.790e-02,  1.792e-01, -1.111e-01,  3.310e-02,\n",
       "         -2.550e-02,  3.230e-02,  7.010e-02,  1.954e-01,  8.800e-03,\n",
       "          3.780e-02,  6.800e-03,  9.600e-03, -8.120e-02,  1.280e-02,\n",
       "         -2.770e-02, -1.091e-01,  8.180e-02, -1.004e-01, -2.910e-02,\n",
       "          1.050e-02,  3.070e-02, -1.223e-01, -1.161e-01,  2.060e-02,\n",
       "          7.940e-02,  2.430e-02, -1.187e-01,  1.410e-02,  5.840e-02,\n",
       "         -1.121e-01, -1.650e-02, -9.200e-02, -1.110e-02,  2.720e-02,\n",
       "          1.670e-02, -5.200e-03, -6.131e-01, -4.270e-02,  4.970e-02,\n",
       "         -8.370e-02, -5.520e-02,  1.630e-01, -1.027e-01,  2.500e-03,\n",
       "         -1.100e-02,  2.480e-02, -1.160e-02,  1.137e-01, -3.390e-02,\n",
       "         -2.091e-01,  1.184e-01,  3.260e-02,  3.020e-02, -3.470e-02,\n",
       "         -3.440e-02, -3.890e-02,  3.020e-02, -1.657e-01,  1.047e-01,\n",
       "          1.000e-01, -1.990e-02, -3.100e-02, -6.330e-02,  2.126e-01,\n",
       "         -4.730e-02,  9.700e-02,  6.100e-03, -1.707e-01, -5.420e-02,\n",
       "         -8.560e-02,  1.371e-01, -6.260e-02,  7.120e-02,  5.870e-02,\n",
       "          6.100e-02, -1.240e-02, -8.620e-02,  2.220e-02,  3.830e-02,\n",
       "         -1.133e-01,  1.714e-01,  7.220e-02, -1.580e-02,  5.530e-02,\n",
       "         -1.816e-01, -1.039e-01,  2.130e-02, -6.650e-02,  9.690e-02,\n",
       "         -5.150e-02, -4.730e-02, -6.600e-03, -1.490e-02, -9.160e-02,\n",
       "          6.200e-03,  8.240e-02, -6.120e-02,  8.730e-02,  1.000e-02,\n",
       "         -2.390e-02, -3.350e-02, -7.000e-02, -7.780e-02, -3.506e-01,\n",
       "         -7.800e-03, -3.710e-02, -1.424e-01,  1.394e-01, -1.067e-01,\n",
       "          2.317e-01,  7.290e-02,  9.380e-02,  1.780e-02, -5.660e-02,\n",
       "         -3.420e-02,  5.800e-02,  5.980e-02, -5.030e-02, -7.100e-03,\n",
       "          6.780e-02, -1.028e-01,  6.810e-02,  2.410e-02,  1.090e-02,\n",
       "          1.116e-01, -1.930e-02, -9.980e-02,  1.935e-01, -5.050e-02,\n",
       "          7.600e-03,  7.040e-02, -1.545e-01,  6.620e-02, -5.800e-03,\n",
       "          7.910e-02,  1.560e-02, -6.570e-02, -1.049e-01,  1.233e-01,\n",
       "          1.760e-02, -1.133e-01,  3.750e-02,  1.420e-02,  1.109e-01,\n",
       "         -1.800e-02,  1.960e-01, -6.000e-04,  6.940e-02, -8.590e-02,\n",
       "          6.120e-02,  1.114e-01, -6.050e-02,  4.600e-02,  3.210e-02,\n",
       "          7.660e-02, -7.190e-02, -5.800e-03, -5.000e-02, -1.330e-02,\n",
       "         -5.300e-02,  2.022e-01, -2.388e-01, -9.350e-02,  1.267e-01,\n",
       "         -7.590e-02,  4.600e-03, -2.274e-01, -1.810e-02,  1.560e-02,\n",
       "         -4.920e-02,  3.060e-02, -1.603e-01,  4.640e-02, -1.433e-01,\n",
       "          3.820e-02,  9.700e-03, -5.300e-02,  2.740e-02,  7.380e-02,\n",
       "          1.334e-01, -3.860e-02,  7.110e-02,  1.793e-01, -5.900e-02,\n",
       "         -5.820e-02,  7.290e-02, -2.850e-02, -5.660e-02,  2.580e-02,\n",
       "         -1.425e-01, -6.140e-02, -1.882e-01, -1.990e-02,  1.174e-01,\n",
       "          1.198e-01,  3.660e-02, -6.530e-02, -1.460e-02, -3.720e-02,\n",
       "         -1.046e-01, -2.800e-02,  1.029e-01,  5.940e-02,  4.830e-02,\n",
       "         -7.490e-02,  6.830e-02,  1.150e-02,  1.002e-01,  1.036e-01,\n",
       "          1.547e-01, -4.790e-02, -1.180e-01, -5.440e-02, -8.810e-02,\n",
       "         -2.573e-01,  5.100e-03,  3.627e-01,  1.050e-01,  2.200e-02,\n",
       "         -1.715e-01, -2.070e-02, -5.580e-02, -2.275e-01, -9.900e-02,\n",
       "         -7.020e-02,  6.530e-02, -2.900e-03,  7.840e-02, -4.430e-02,\n",
       "         -6.140e-02,  1.690e-02,  8.330e-02,  3.280e-02,  3.342e-01,\n",
       "          7.880e-02,  6.410e-02, -1.184e-01,  9.100e-03, -1.146e-01,\n",
       "         -1.042e-01, -1.222e-01, -1.770e-02, -5.060e-02,  4.160e-02,\n",
       "         -2.149e-01,  2.160e-02, -5.900e-03, -2.670e-02, -2.921e-01,\n",
       "         -3.900e-02, -2.344e-01,  1.360e-02, -9.610e-02, -3.630e-02,\n",
       "         -9.370e-02,  3.940e-02, -6.010e-02, -1.511e-01,  1.104e-01,\n",
       "         -4.150e-02,  1.040e-01, -1.856e-01,  4.900e-03, -1.334e-01,\n",
       "         -9.080e-02,  4.630e-02, -2.310e-02, -2.850e-02, -3.780e-02,\n",
       "         -2.590e-02, -2.210e-02,  1.015e-01, -3.000e-02,  3.860e-02,\n",
       "         -8.250e-02,  3.920e-02, -7.220e-02, -1.980e-02, -1.600e-02,\n",
       "         -9.680e-02, -2.680e-02,  2.662e-01, -5.570e-02, -5.940e-02]],\n",
       "       dtype=float32),\n",
       " array([[-7.640e-02,  4.510e-02, -8.830e-02,  2.230e-02, -2.671e-01,\n",
       "          4.040e-02,  1.210e-02, -3.490e-02,  5.150e-02, -1.087e-01,\n",
       "          3.910e-02,  6.170e-02, -2.400e-02,  1.430e-02, -7.080e-02,\n",
       "         -2.070e-02, -3.650e-02,  4.890e-02, -1.316e-01, -3.600e-02,\n",
       "          7.410e-02,  4.990e-02,  3.890e-02,  2.090e-02,  3.800e-02,\n",
       "          8.420e-02,  2.130e-02,  8.520e-02,  1.540e-02,  1.890e-02,\n",
       "          6.080e-02, -3.500e-02, -1.372e-01, -5.270e-02,  1.770e-02,\n",
       "          1.280e-02,  1.870e-02,  6.530e-02, -7.280e-02,  6.800e-02,\n",
       "         -2.000e-02,  3.300e-02, -1.300e-03, -1.002e-01, -1.118e-01,\n",
       "          2.040e-02,  6.000e-04, -1.430e-02,  5.000e-03,  3.700e-03,\n",
       "         -5.920e-02,  5.700e-02, -5.512e-01, -3.990e-02, -2.390e-02,\n",
       "         -3.630e-02, -3.840e-02,  3.650e-02, -4.260e-02, -2.700e-02,\n",
       "         -4.260e-02, -2.380e-02, -5.070e-02, -2.450e-02,  5.600e-03,\n",
       "          1.088e-01, -5.940e-02,  1.710e-02,  3.140e-02,  3.350e-02,\n",
       "          4.680e-02,  2.050e-02, -8.800e-03, -6.690e-02, -1.210e-02,\n",
       "         -6.830e-02,  1.580e-02, -3.100e-02,  1.330e-02,  1.679e-01,\n",
       "          2.850e-02, -1.956e-01, -4.350e-02, -9.050e-02,  1.210e-02,\n",
       "          4.380e-02, -2.570e-02,  1.460e-02, -7.351e-01,  2.280e-02,\n",
       "         -1.610e-02, -2.200e-03, -3.160e-02, -2.510e-02,  4.200e-03,\n",
       "          3.770e-02, -6.620e-02, -1.580e-02, -3.100e-03,  9.940e-02,\n",
       "         -1.238e-01, -2.570e-02, -2.560e-02,  5.000e-03,  2.160e-02,\n",
       "          6.820e-02, -1.335e-01,  2.680e-02, -8.120e-02, -2.820e-02,\n",
       "         -4.880e-02,  5.900e-03, -3.630e-02, -7.990e-02,  1.410e-02,\n",
       "         -4.700e-03,  5.400e-03, -4.670e-02,  3.600e-03, -2.524e-01,\n",
       "         -6.980e-02, -1.790e-02, -3.180e-02, -9.790e-02, -1.305e-01,\n",
       "          1.492e-01,  9.610e-02,  9.260e-02,  8.300e-03,  1.490e-02,\n",
       "          4.600e-02,  8.680e-02,  3.730e-02,  4.060e-02, -2.700e-02,\n",
       "         -2.346e-01, -8.040e-02, -5.290e-02, -9.900e-03,  2.430e-02,\n",
       "          0.000e+00,  7.780e-02,  6.670e-02,  2.532e-01,  1.450e-02,\n",
       "          1.000e-02,  3.000e-04, -7.810e-02,  1.220e-02, -8.160e-02,\n",
       "         -1.570e-02,  5.220e-02,  1.310e-02, -7.340e-02,  2.400e-03,\n",
       "         -5.000e-03, -4.160e-02,  1.070e-02, -6.480e-02, -6.170e-02,\n",
       "          5.480e-02,  1.000e-02,  2.440e-02,  1.800e-03, -3.293e-01,\n",
       "          8.300e-03,  6.160e-02,  3.980e-02,  9.000e-04,  1.090e-02,\n",
       "         -3.260e-02, -4.050e-02,  4.460e-02,  5.450e-02,  3.650e-02,\n",
       "         -1.185e-01,  1.119e-01, -2.742e-01,  7.000e-03, -8.000e-03,\n",
       "         -4.660e-02, -1.235e-01,  5.010e-02, -2.500e-02,  5.940e-02,\n",
       "          1.180e-02,  4.330e-02, -6.320e-02,  2.194e-01,  3.300e-02,\n",
       "         -9.100e-03, -4.060e-02, -4.400e-03,  6.220e-02,  3.590e-02,\n",
       "         -5.990e-02,  1.460e-02,  2.130e-02,  3.371e-01,  2.550e-02,\n",
       "         -1.650e-02,  3.640e-02, -1.830e-02,  1.370e-02, -4.960e-02,\n",
       "         -4.700e-03,  8.900e-03,  5.060e-02, -3.470e-02,  1.250e-02,\n",
       "          6.810e-02,  9.760e-02, -1.590e-02,  3.620e-02, -7.500e-03,\n",
       "         -6.600e-03, -5.170e-02, -3.690e-02,  3.380e-02,  1.376e-01,\n",
       "         -6.870e-02,  9.520e-02,  2.170e-02,  4.100e-03,  2.500e-03,\n",
       "         -8.980e-02,  3.450e-02,  3.260e-02,  3.320e-02, -1.976e-01,\n",
       "          1.040e-02, -1.660e-02,  3.335e-01, -5.040e-02, -6.000e-03,\n",
       "         -1.911e-01,  4.360e-02,  3.620e-02, -1.601e-01, -3.730e-02,\n",
       "          1.100e-02, -7.590e-02,  1.230e-02, -4.870e-02, -1.140e-02,\n",
       "         -3.040e-02, -3.210e-02, -8.730e-02, -2.360e-02,  1.024e-01,\n",
       "         -9.900e-03,  3.310e-02, -5.570e-02,  5.360e-02,  4.660e-02,\n",
       "         -1.100e-03, -1.130e-01,  8.430e-02,  2.510e-02,  3.000e-03,\n",
       "         -1.450e-02, -8.240e-02, -4.850e-02,  2.100e-03, -2.108e-01,\n",
       "          1.200e-03,  3.170e-02,  7.190e-02, -8.510e-02, -9.020e-02,\n",
       "         -3.300e-03, -9.000e-03,  4.100e-02,  1.210e-02,  1.760e-02,\n",
       "          4.590e-02, -4.240e-02, -1.690e-02,  3.320e-02, -1.070e-02,\n",
       "          2.262e-01,  1.014e-01,  3.230e-02,  1.810e-02,  2.900e-03,\n",
       "         -4.020e-02, -5.090e-02,  1.120e-02, -7.020e-02,  6.710e-02,\n",
       "          2.700e-02, -4.800e-03,  1.600e-02, -4.760e-02, -8.470e-02,\n",
       "         -1.418e-01, -1.198e-01,  1.588e-01,  5.200e-03, -1.040e-02],\n",
       "        [ 1.350e-02,  3.530e-02, -8.150e-02, -5.900e-03, -2.810e-02,\n",
       "          1.270e-01,  4.450e-02, -2.880e-02, -1.833e-01,  4.370e-02,\n",
       "         -8.840e-02,  1.550e-02,  3.610e-02,  1.181e-01, -1.024e-01,\n",
       "         -1.064e-01, -7.790e-02,  1.792e-01, -1.111e-01,  3.310e-02,\n",
       "         -2.550e-02,  3.230e-02,  7.010e-02,  1.954e-01,  8.800e-03,\n",
       "          3.780e-02,  6.800e-03,  9.600e-03, -8.120e-02,  1.280e-02,\n",
       "         -2.770e-02, -1.091e-01,  8.180e-02, -1.004e-01, -2.910e-02,\n",
       "          1.050e-02,  3.070e-02, -1.223e-01, -1.161e-01,  2.060e-02,\n",
       "          7.940e-02,  2.430e-02, -1.187e-01,  1.410e-02,  5.840e-02,\n",
       "         -1.121e-01, -1.650e-02, -9.200e-02, -1.110e-02,  2.720e-02,\n",
       "          1.670e-02, -5.200e-03, -6.131e-01, -4.270e-02,  4.970e-02,\n",
       "         -8.370e-02, -5.520e-02,  1.630e-01, -1.027e-01,  2.500e-03,\n",
       "         -1.100e-02,  2.480e-02, -1.160e-02,  1.137e-01, -3.390e-02,\n",
       "         -2.091e-01,  1.184e-01,  3.260e-02,  3.020e-02, -3.470e-02,\n",
       "         -3.440e-02, -3.890e-02,  3.020e-02, -1.657e-01,  1.047e-01,\n",
       "          1.000e-01, -1.990e-02, -3.100e-02, -6.330e-02,  2.126e-01,\n",
       "         -4.730e-02,  9.700e-02,  6.100e-03, -1.707e-01, -5.420e-02,\n",
       "         -8.560e-02,  1.371e-01, -6.260e-02,  7.120e-02,  5.870e-02,\n",
       "          6.100e-02, -1.240e-02, -8.620e-02,  2.220e-02,  3.830e-02,\n",
       "         -1.133e-01,  1.714e-01,  7.220e-02, -1.580e-02,  5.530e-02,\n",
       "         -1.816e-01, -1.039e-01,  2.130e-02, -6.650e-02,  9.690e-02,\n",
       "         -5.150e-02, -4.730e-02, -6.600e-03, -1.490e-02, -9.160e-02,\n",
       "          6.200e-03,  8.240e-02, -6.120e-02,  8.730e-02,  1.000e-02,\n",
       "         -2.390e-02, -3.350e-02, -7.000e-02, -7.780e-02, -3.506e-01,\n",
       "         -7.800e-03, -3.710e-02, -1.424e-01,  1.394e-01, -1.067e-01,\n",
       "          2.317e-01,  7.290e-02,  9.380e-02,  1.780e-02, -5.660e-02,\n",
       "         -3.420e-02,  5.800e-02,  5.980e-02, -5.030e-02, -7.100e-03,\n",
       "          6.780e-02, -1.028e-01,  6.810e-02,  2.410e-02,  1.090e-02,\n",
       "          1.116e-01, -1.930e-02, -9.980e-02,  1.935e-01, -5.050e-02,\n",
       "          7.600e-03,  7.040e-02, -1.545e-01,  6.620e-02, -5.800e-03,\n",
       "          7.910e-02,  1.560e-02, -6.570e-02, -1.049e-01,  1.233e-01,\n",
       "          1.760e-02, -1.133e-01,  3.750e-02,  1.420e-02,  1.109e-01,\n",
       "         -1.800e-02,  1.960e-01, -6.000e-04,  6.940e-02, -8.590e-02,\n",
       "          6.120e-02,  1.114e-01, -6.050e-02,  4.600e-02,  3.210e-02,\n",
       "          7.660e-02, -7.190e-02, -5.800e-03, -5.000e-02, -1.330e-02,\n",
       "         -5.300e-02,  2.022e-01, -2.388e-01, -9.350e-02,  1.267e-01,\n",
       "         -7.590e-02,  4.600e-03, -2.274e-01, -1.810e-02,  1.560e-02,\n",
       "         -4.920e-02,  3.060e-02, -1.603e-01,  4.640e-02, -1.433e-01,\n",
       "          3.820e-02,  9.700e-03, -5.300e-02,  2.740e-02,  7.380e-02,\n",
       "          1.334e-01, -3.860e-02,  7.110e-02,  1.793e-01, -5.900e-02,\n",
       "         -5.820e-02,  7.290e-02, -2.850e-02, -5.660e-02,  2.580e-02,\n",
       "         -1.425e-01, -6.140e-02, -1.882e-01, -1.990e-02,  1.174e-01,\n",
       "          1.198e-01,  3.660e-02, -6.530e-02, -1.460e-02, -3.720e-02,\n",
       "         -1.046e-01, -2.800e-02,  1.029e-01,  5.940e-02,  4.830e-02,\n",
       "         -7.490e-02,  6.830e-02,  1.150e-02,  1.002e-01,  1.036e-01,\n",
       "          1.547e-01, -4.790e-02, -1.180e-01, -5.440e-02, -8.810e-02,\n",
       "         -2.573e-01,  5.100e-03,  3.627e-01,  1.050e-01,  2.200e-02,\n",
       "         -1.715e-01, -2.070e-02, -5.580e-02, -2.275e-01, -9.900e-02,\n",
       "         -7.020e-02,  6.530e-02, -2.900e-03,  7.840e-02, -4.430e-02,\n",
       "         -6.140e-02,  1.690e-02,  8.330e-02,  3.280e-02,  3.342e-01,\n",
       "          7.880e-02,  6.410e-02, -1.184e-01,  9.100e-03, -1.146e-01,\n",
       "         -1.042e-01, -1.222e-01, -1.770e-02, -5.060e-02,  4.160e-02,\n",
       "         -2.149e-01,  2.160e-02, -5.900e-03, -2.670e-02, -2.921e-01,\n",
       "         -3.900e-02, -2.344e-01,  1.360e-02, -9.610e-02, -3.630e-02,\n",
       "         -9.370e-02,  3.940e-02, -6.010e-02, -1.511e-01,  1.104e-01,\n",
       "         -4.150e-02,  1.040e-01, -1.856e-01,  4.900e-03, -1.334e-01,\n",
       "         -9.080e-02,  4.630e-02, -2.310e-02, -2.850e-02, -3.780e-02,\n",
       "         -2.590e-02, -2.210e-02,  1.015e-01, -3.000e-02,  3.860e-02,\n",
       "         -8.250e-02,  3.920e-02, -7.220e-02, -1.980e-02, -1.600e-02,\n",
       "         -9.680e-02, -2.680e-02,  2.662e-01, -5.570e-02, -5.940e-02],\n",
       "        [ 6.220e-02,  6.280e-02,  2.393e-01,  1.030e-02,  3.810e-02,\n",
       "          1.586e-01,  5.310e-02, -4.900e-03, -3.270e-02, -2.283e-01,\n",
       "          4.800e-03,  2.000e-03, -1.032e-01,  8.110e-02, -1.228e-01,\n",
       "          2.010e-02, -2.330e-02,  1.321e-01,  3.720e-02,  7.090e-02,\n",
       "          4.800e-03,  5.590e-02,  5.600e-02,  3.120e-02,  2.030e-02,\n",
       "          9.290e-02,  5.100e-03, -1.637e-01, -1.068e-01, -2.248e-01,\n",
       "         -6.450e-02,  3.500e-02,  1.022e-01,  4.370e-02, -1.600e-03,\n",
       "          1.540e-02,  2.100e-03, -1.940e-01,  1.418e-01, -7.660e-02,\n",
       "         -3.180e-02,  1.209e-01, -2.086e-01, -4.030e-02, -1.605e-01,\n",
       "         -6.030e-02,  9.550e-02, -1.800e-01,  7.580e-02,  1.360e-01,\n",
       "         -2.710e-02,  2.020e-01, -6.912e-01,  6.750e-02, -1.057e-01,\n",
       "          3.340e-02, -1.053e-01,  1.560e-01,  3.610e-02, -4.110e-02,\n",
       "          3.700e-02, -5.760e-02,  2.320e-02, -5.360e-02, -1.189e-01,\n",
       "         -1.020e-02,  5.030e-02,  1.340e-02, -1.668e-01,  1.040e-02,\n",
       "          9.160e-02,  3.150e-02,  9.320e-02,  2.704e-01, -1.144e-01,\n",
       "         -4.750e-02,  6.480e-02,  5.780e-02, -3.400e-03, -4.800e-02,\n",
       "          2.610e-02, -6.490e-02,  9.560e-02, -2.246e-01,  2.750e-02,\n",
       "          4.160e-02,  1.630e-02, -2.600e-02, -9.030e-02,  9.210e-02,\n",
       "          3.180e-02,  8.000e-04,  4.600e-02, -1.040e-01,  2.930e-02,\n",
       "          8.060e-02, -4.660e-02, -2.990e-02, -5.180e-02, -8.540e-02,\n",
       "         -1.630e-01,  8.680e-02,  4.060e-02, -9.390e-02, -2.146e-01,\n",
       "         -8.160e-02,  1.847e-01, -6.970e-02,  1.462e-01, -1.044e-01,\n",
       "          9.980e-02, -1.972e-01, -8.770e-02, -5.190e-02,  3.850e-02,\n",
       "          6.550e-02, -4.420e-02, -4.800e-02,  1.144e-01, -3.020e-01,\n",
       "          3.150e-02,  1.520e-02, -4.960e-02,  1.340e-01, -7.200e-02,\n",
       "          1.974e-01, -1.870e-02,  1.990e-01, -2.750e-02,  4.160e-02,\n",
       "          3.160e-02,  1.762e-01,  1.070e-02,  2.796e-01,  8.430e-02,\n",
       "         -1.926e-01,  4.520e-02, -8.650e-02, -9.430e-02, -8.730e-02,\n",
       "         -2.610e-02,  8.300e-02,  1.460e-02,  2.599e-01,  1.602e-01,\n",
       "         -3.350e-02,  4.520e-02, -2.124e-01,  5.730e-02,  5.610e-02,\n",
       "          9.720e-02, -1.218e-01,  4.180e-02,  2.820e-02,  1.457e-01,\n",
       "         -9.600e-03, -3.280e-02,  4.140e-02,  1.230e-02,  1.438e-01,\n",
       "         -2.392e-01,  1.950e-02, -8.260e-02,  2.220e-02, -3.630e-02,\n",
       "         -2.060e-02,  1.029e-01,  7.790e-02, -1.540e-02,  5.300e-03,\n",
       "          2.676e-01, -2.140e-02, -1.084e-01, -5.190e-02,  5.520e-02,\n",
       "         -1.000e-03,  2.606e-01,  1.790e-02,  5.800e-03,  9.900e-03,\n",
       "         -1.066e-01,  2.458e-01, -1.551e-01, -2.940e-02,  5.040e-02,\n",
       "         -2.578e-01, -5.590e-02, -1.224e-01,  1.569e-01,  2.395e-01,\n",
       "         -7.780e-02,  2.030e-02, -7.650e-02, -6.510e-02, -3.510e-02,\n",
       "          5.130e-02, -9.800e-03,  2.830e-02,  1.340e-01,  5.560e-02,\n",
       "          1.021e-01, -5.670e-02,  1.682e-01, -3.360e-02,  1.151e-01,\n",
       "          1.223e-01, -1.974e-01, -3.760e-02, -1.560e-01,  7.870e-02,\n",
       "         -3.780e-02, -9.080e-02,  6.980e-02,  1.234e-01,  6.920e-02,\n",
       "          1.020e-02, -6.030e-02, -6.370e-02,  5.190e-02,  1.399e-01,\n",
       "          7.400e-03, -4.550e-02,  8.920e-02, -1.100e-02, -1.026e-01,\n",
       "         -3.300e-02, -4.830e-02, -4.950e-02, -5.810e-02, -9.190e-02,\n",
       "         -5.610e-02, -1.310e-02,  2.519e-01,  1.543e-01,  2.680e-02,\n",
       "         -2.500e-03, -5.890e-02,  1.284e-01, -2.187e-01,  8.900e-03,\n",
       "          1.070e-02, -1.597e-01, -1.143e-01,  2.280e-02, -1.590e-02,\n",
       "          8.460e-02,  3.750e-02, -1.131e-01,  5.370e-02,  3.220e-01,\n",
       "          8.510e-02,  1.031e-01,  1.587e-01,  1.400e-02,  4.840e-02,\n",
       "         -5.910e-02,  2.890e-02, -6.470e-02,  6.790e-02, -1.051e-01,\n",
       "         -2.098e-01, -9.090e-02,  8.330e-02, -4.690e-02,  2.224e-01,\n",
       "         -2.740e-02,  7.550e-02, -8.950e-02, -1.203e-01,  5.700e-03,\n",
       "          5.600e-03, -9.220e-02,  8.020e-02,  3.570e-02,  6.900e-03,\n",
       "          2.690e-02, -3.700e-03,  1.380e-02,  1.470e-02,  8.000e-02,\n",
       "         -1.681e-01, -5.350e-02,  2.224e-01, -2.410e-02,  4.340e-02,\n",
       "         -6.260e-02, -5.560e-02,  1.571e-01, -3.960e-02,  9.150e-02,\n",
       "          9.800e-03,  1.086e-01,  3.460e-02,  8.570e-02,  1.466e-01,\n",
       "         -2.067e-01,  7.700e-03,  1.802e-01, -3.940e-02, -2.430e-02]],\n",
       "       dtype=float32),\n",
       " array([[ 1.350e-02,  3.530e-02, -8.150e-02, -5.900e-03, -2.810e-02,\n",
       "          1.270e-01,  4.450e-02, -2.880e-02, -1.833e-01,  4.370e-02,\n",
       "         -8.840e-02,  1.550e-02,  3.610e-02,  1.181e-01, -1.024e-01,\n",
       "         -1.064e-01, -7.790e-02,  1.792e-01, -1.111e-01,  3.310e-02,\n",
       "         -2.550e-02,  3.230e-02,  7.010e-02,  1.954e-01,  8.800e-03,\n",
       "          3.780e-02,  6.800e-03,  9.600e-03, -8.120e-02,  1.280e-02,\n",
       "         -2.770e-02, -1.091e-01,  8.180e-02, -1.004e-01, -2.910e-02,\n",
       "          1.050e-02,  3.070e-02, -1.223e-01, -1.161e-01,  2.060e-02,\n",
       "          7.940e-02,  2.430e-02, -1.187e-01,  1.410e-02,  5.840e-02,\n",
       "         -1.121e-01, -1.650e-02, -9.200e-02, -1.110e-02,  2.720e-02,\n",
       "          1.670e-02, -5.200e-03, -6.131e-01, -4.270e-02,  4.970e-02,\n",
       "         -8.370e-02, -5.520e-02,  1.630e-01, -1.027e-01,  2.500e-03,\n",
       "         -1.100e-02,  2.480e-02, -1.160e-02,  1.137e-01, -3.390e-02,\n",
       "         -2.091e-01,  1.184e-01,  3.260e-02,  3.020e-02, -3.470e-02,\n",
       "         -3.440e-02, -3.890e-02,  3.020e-02, -1.657e-01,  1.047e-01,\n",
       "          1.000e-01, -1.990e-02, -3.100e-02, -6.330e-02,  2.126e-01,\n",
       "         -4.730e-02,  9.700e-02,  6.100e-03, -1.707e-01, -5.420e-02,\n",
       "         -8.560e-02,  1.371e-01, -6.260e-02,  7.120e-02,  5.870e-02,\n",
       "          6.100e-02, -1.240e-02, -8.620e-02,  2.220e-02,  3.830e-02,\n",
       "         -1.133e-01,  1.714e-01,  7.220e-02, -1.580e-02,  5.530e-02,\n",
       "         -1.816e-01, -1.039e-01,  2.130e-02, -6.650e-02,  9.690e-02,\n",
       "         -5.150e-02, -4.730e-02, -6.600e-03, -1.490e-02, -9.160e-02,\n",
       "          6.200e-03,  8.240e-02, -6.120e-02,  8.730e-02,  1.000e-02,\n",
       "         -2.390e-02, -3.350e-02, -7.000e-02, -7.780e-02, -3.506e-01,\n",
       "         -7.800e-03, -3.710e-02, -1.424e-01,  1.394e-01, -1.067e-01,\n",
       "          2.317e-01,  7.290e-02,  9.380e-02,  1.780e-02, -5.660e-02,\n",
       "         -3.420e-02,  5.800e-02,  5.980e-02, -5.030e-02, -7.100e-03,\n",
       "          6.780e-02, -1.028e-01,  6.810e-02,  2.410e-02,  1.090e-02,\n",
       "          1.116e-01, -1.930e-02, -9.980e-02,  1.935e-01, -5.050e-02,\n",
       "          7.600e-03,  7.040e-02, -1.545e-01,  6.620e-02, -5.800e-03,\n",
       "          7.910e-02,  1.560e-02, -6.570e-02, -1.049e-01,  1.233e-01,\n",
       "          1.760e-02, -1.133e-01,  3.750e-02,  1.420e-02,  1.109e-01,\n",
       "         -1.800e-02,  1.960e-01, -6.000e-04,  6.940e-02, -8.590e-02,\n",
       "          6.120e-02,  1.114e-01, -6.050e-02,  4.600e-02,  3.210e-02,\n",
       "          7.660e-02, -7.190e-02, -5.800e-03, -5.000e-02, -1.330e-02,\n",
       "         -5.300e-02,  2.022e-01, -2.388e-01, -9.350e-02,  1.267e-01,\n",
       "         -7.590e-02,  4.600e-03, -2.274e-01, -1.810e-02,  1.560e-02,\n",
       "         -4.920e-02,  3.060e-02, -1.603e-01,  4.640e-02, -1.433e-01,\n",
       "          3.820e-02,  9.700e-03, -5.300e-02,  2.740e-02,  7.380e-02,\n",
       "          1.334e-01, -3.860e-02,  7.110e-02,  1.793e-01, -5.900e-02,\n",
       "         -5.820e-02,  7.290e-02, -2.850e-02, -5.660e-02,  2.580e-02,\n",
       "         -1.425e-01, -6.140e-02, -1.882e-01, -1.990e-02,  1.174e-01,\n",
       "          1.198e-01,  3.660e-02, -6.530e-02, -1.460e-02, -3.720e-02,\n",
       "         -1.046e-01, -2.800e-02,  1.029e-01,  5.940e-02,  4.830e-02,\n",
       "         -7.490e-02,  6.830e-02,  1.150e-02,  1.002e-01,  1.036e-01,\n",
       "          1.547e-01, -4.790e-02, -1.180e-01, -5.440e-02, -8.810e-02,\n",
       "         -2.573e-01,  5.100e-03,  3.627e-01,  1.050e-01,  2.200e-02,\n",
       "         -1.715e-01, -2.070e-02, -5.580e-02, -2.275e-01, -9.900e-02,\n",
       "         -7.020e-02,  6.530e-02, -2.900e-03,  7.840e-02, -4.430e-02,\n",
       "         -6.140e-02,  1.690e-02,  8.330e-02,  3.280e-02,  3.342e-01,\n",
       "          7.880e-02,  6.410e-02, -1.184e-01,  9.100e-03, -1.146e-01,\n",
       "         -1.042e-01, -1.222e-01, -1.770e-02, -5.060e-02,  4.160e-02,\n",
       "         -2.149e-01,  2.160e-02, -5.900e-03, -2.670e-02, -2.921e-01,\n",
       "         -3.900e-02, -2.344e-01,  1.360e-02, -9.610e-02, -3.630e-02,\n",
       "         -9.370e-02,  3.940e-02, -6.010e-02, -1.511e-01,  1.104e-01,\n",
       "         -4.150e-02,  1.040e-01, -1.856e-01,  4.900e-03, -1.334e-01,\n",
       "         -9.080e-02,  4.630e-02, -2.310e-02, -2.850e-02, -3.780e-02,\n",
       "         -2.590e-02, -2.210e-02,  1.015e-01, -3.000e-02,  3.860e-02,\n",
       "         -8.250e-02,  3.920e-02, -7.220e-02, -1.980e-02, -1.600e-02,\n",
       "         -9.680e-02, -2.680e-02,  2.662e-01, -5.570e-02, -5.940e-02],\n",
       "        [ 6.220e-02,  6.280e-02,  2.393e-01,  1.030e-02,  3.810e-02,\n",
       "          1.586e-01,  5.310e-02, -4.900e-03, -3.270e-02, -2.283e-01,\n",
       "          4.800e-03,  2.000e-03, -1.032e-01,  8.110e-02, -1.228e-01,\n",
       "          2.010e-02, -2.330e-02,  1.321e-01,  3.720e-02,  7.090e-02,\n",
       "          4.800e-03,  5.590e-02,  5.600e-02,  3.120e-02,  2.030e-02,\n",
       "          9.290e-02,  5.100e-03, -1.637e-01, -1.068e-01, -2.248e-01,\n",
       "         -6.450e-02,  3.500e-02,  1.022e-01,  4.370e-02, -1.600e-03,\n",
       "          1.540e-02,  2.100e-03, -1.940e-01,  1.418e-01, -7.660e-02,\n",
       "         -3.180e-02,  1.209e-01, -2.086e-01, -4.030e-02, -1.605e-01,\n",
       "         -6.030e-02,  9.550e-02, -1.800e-01,  7.580e-02,  1.360e-01,\n",
       "         -2.710e-02,  2.020e-01, -6.912e-01,  6.750e-02, -1.057e-01,\n",
       "          3.340e-02, -1.053e-01,  1.560e-01,  3.610e-02, -4.110e-02,\n",
       "          3.700e-02, -5.760e-02,  2.320e-02, -5.360e-02, -1.189e-01,\n",
       "         -1.020e-02,  5.030e-02,  1.340e-02, -1.668e-01,  1.040e-02,\n",
       "          9.160e-02,  3.150e-02,  9.320e-02,  2.704e-01, -1.144e-01,\n",
       "         -4.750e-02,  6.480e-02,  5.780e-02, -3.400e-03, -4.800e-02,\n",
       "          2.610e-02, -6.490e-02,  9.560e-02, -2.246e-01,  2.750e-02,\n",
       "          4.160e-02,  1.630e-02, -2.600e-02, -9.030e-02,  9.210e-02,\n",
       "          3.180e-02,  8.000e-04,  4.600e-02, -1.040e-01,  2.930e-02,\n",
       "          8.060e-02, -4.660e-02, -2.990e-02, -5.180e-02, -8.540e-02,\n",
       "         -1.630e-01,  8.680e-02,  4.060e-02, -9.390e-02, -2.146e-01,\n",
       "         -8.160e-02,  1.847e-01, -6.970e-02,  1.462e-01, -1.044e-01,\n",
       "          9.980e-02, -1.972e-01, -8.770e-02, -5.190e-02,  3.850e-02,\n",
       "          6.550e-02, -4.420e-02, -4.800e-02,  1.144e-01, -3.020e-01,\n",
       "          3.150e-02,  1.520e-02, -4.960e-02,  1.340e-01, -7.200e-02,\n",
       "          1.974e-01, -1.870e-02,  1.990e-01, -2.750e-02,  4.160e-02,\n",
       "          3.160e-02,  1.762e-01,  1.070e-02,  2.796e-01,  8.430e-02,\n",
       "         -1.926e-01,  4.520e-02, -8.650e-02, -9.430e-02, -8.730e-02,\n",
       "         -2.610e-02,  8.300e-02,  1.460e-02,  2.599e-01,  1.602e-01,\n",
       "         -3.350e-02,  4.520e-02, -2.124e-01,  5.730e-02,  5.610e-02,\n",
       "          9.720e-02, -1.218e-01,  4.180e-02,  2.820e-02,  1.457e-01,\n",
       "         -9.600e-03, -3.280e-02,  4.140e-02,  1.230e-02,  1.438e-01,\n",
       "         -2.392e-01,  1.950e-02, -8.260e-02,  2.220e-02, -3.630e-02,\n",
       "         -2.060e-02,  1.029e-01,  7.790e-02, -1.540e-02,  5.300e-03,\n",
       "          2.676e-01, -2.140e-02, -1.084e-01, -5.190e-02,  5.520e-02,\n",
       "         -1.000e-03,  2.606e-01,  1.790e-02,  5.800e-03,  9.900e-03,\n",
       "         -1.066e-01,  2.458e-01, -1.551e-01, -2.940e-02,  5.040e-02,\n",
       "         -2.578e-01, -5.590e-02, -1.224e-01,  1.569e-01,  2.395e-01,\n",
       "         -7.780e-02,  2.030e-02, -7.650e-02, -6.510e-02, -3.510e-02,\n",
       "          5.130e-02, -9.800e-03,  2.830e-02,  1.340e-01,  5.560e-02,\n",
       "          1.021e-01, -5.670e-02,  1.682e-01, -3.360e-02,  1.151e-01,\n",
       "          1.223e-01, -1.974e-01, -3.760e-02, -1.560e-01,  7.870e-02,\n",
       "         -3.780e-02, -9.080e-02,  6.980e-02,  1.234e-01,  6.920e-02,\n",
       "          1.020e-02, -6.030e-02, -6.370e-02,  5.190e-02,  1.399e-01,\n",
       "          7.400e-03, -4.550e-02,  8.920e-02, -1.100e-02, -1.026e-01,\n",
       "         -3.300e-02, -4.830e-02, -4.950e-02, -5.810e-02, -9.190e-02,\n",
       "         -5.610e-02, -1.310e-02,  2.519e-01,  1.543e-01,  2.680e-02,\n",
       "         -2.500e-03, -5.890e-02,  1.284e-01, -2.187e-01,  8.900e-03,\n",
       "          1.070e-02, -1.597e-01, -1.143e-01,  2.280e-02, -1.590e-02,\n",
       "          8.460e-02,  3.750e-02, -1.131e-01,  5.370e-02,  3.220e-01,\n",
       "          8.510e-02,  1.031e-01,  1.587e-01,  1.400e-02,  4.840e-02,\n",
       "         -5.910e-02,  2.890e-02, -6.470e-02,  6.790e-02, -1.051e-01,\n",
       "         -2.098e-01, -9.090e-02,  8.330e-02, -4.690e-02,  2.224e-01,\n",
       "         -2.740e-02,  7.550e-02, -8.950e-02, -1.203e-01,  5.700e-03,\n",
       "          5.600e-03, -9.220e-02,  8.020e-02,  3.570e-02,  6.900e-03,\n",
       "          2.690e-02, -3.700e-03,  1.380e-02,  1.470e-02,  8.000e-02,\n",
       "         -1.681e-01, -5.350e-02,  2.224e-01, -2.410e-02,  4.340e-02,\n",
       "         -6.260e-02, -5.560e-02,  1.571e-01, -3.960e-02,  9.150e-02,\n",
       "          9.800e-03,  1.086e-01,  3.460e-02,  8.570e-02,  1.466e-01,\n",
       "         -2.067e-01,  7.700e-03,  1.802e-01, -3.940e-02, -2.430e-02],\n",
       "        [ 6.260e-02,  6.530e-02,  1.540e-02,  1.860e-02,  1.126e-01,\n",
       "          2.356e-01,  4.160e-02,  1.853e-01,  9.290e-02, -5.060e-02,\n",
       "          6.450e-02,  1.107e-01,  2.910e-02,  2.816e-01, -6.460e-02,\n",
       "          1.320e-01,  2.574e-01,  3.200e-02, -1.705e-01,  7.970e-02,\n",
       "         -4.090e-02, -7.810e-02,  1.010e-01, -3.180e-02, -9.000e-02,\n",
       "         -1.826e-01, -1.078e-01, -1.159e-01, -1.250e-01, -1.841e-01,\n",
       "         -8.330e-02,  1.008e-01, -1.596e-01, -4.770e-02, -8.120e-02,\n",
       "          3.590e-02, -2.600e-02, -1.806e-01, -4.300e-02, -2.082e-01,\n",
       "         -2.400e-02,  7.860e-02,  4.120e-02, -1.172e-01, -6.780e-02,\n",
       "         -4.050e-02, -2.050e-02, -1.798e-01, -9.900e-03,  1.190e-01,\n",
       "          7.270e-02,  2.198e-01, -7.324e-01,  1.767e-01, -1.630e-02,\n",
       "          1.440e-02,  2.740e-02,  1.974e-01,  2.120e-02, -4.140e-02,\n",
       "         -6.500e-03, -2.740e-02, -1.250e-01,  1.970e-02,  1.173e-01,\n",
       "         -1.140e-02,  1.500e-02, -1.237e-01, -4.260e-02, -1.005e-01,\n",
       "         -1.254e-01, -5.140e-02,  5.160e-02,  1.487e-01,  7.100e-02,\n",
       "          6.880e-02,  9.380e-02,  1.299e-01, -2.681e-01,  1.584e-01,\n",
       "         -2.140e-02, -1.650e-01, -4.020e-02, -5.720e-02,  6.470e-02,\n",
       "          1.044e-01,  8.650e-02, -4.300e-02, -2.730e-02,  1.152e-01,\n",
       "          9.480e-02,  8.760e-02,  1.030e-02, -2.700e-02,  2.234e-01,\n",
       "         -4.660e-02,  2.237e-01, -7.430e-02, -5.510e-02,  9.150e-02,\n",
       "         -3.112e-01,  2.797e-01, -7.990e-02, -4.500e-03, -3.470e-02,\n",
       "         -1.950e-02,  1.009e-01,  6.310e-02,  1.120e-01,  3.130e-02,\n",
       "          5.070e-02,  1.143e-01, -1.649e-01, -6.480e-02, -1.697e-01,\n",
       "          1.022e-01, -2.410e-02,  1.576e-01, -1.654e-01, -4.020e-01,\n",
       "          9.520e-02,  5.710e-02, -2.012e-01, -2.990e-02,  3.800e-02,\n",
       "          2.372e-01,  9.610e-02,  1.305e-01,  1.183e-01, -2.301e-01,\n",
       "         -1.400e-01,  1.873e-01,  2.910e-02,  4.700e-02, -5.900e-03,\n",
       "          1.422e-01,  5.010e-02, -4.810e-02,  1.164e-01, -4.890e-02,\n",
       "         -1.440e-02,  8.810e-02,  4.400e-02,  1.135e-01,  1.131e-01,\n",
       "         -5.200e-03,  1.063e-01, -3.230e-02,  1.185e-01,  6.820e-02,\n",
       "         -4.680e-02, -2.530e-02,  3.370e-02, -1.128e-01,  3.600e-03,\n",
       "         -1.011e-01,  4.840e-02,  3.480e-02,  3.920e-02,  3.450e-02,\n",
       "         -1.011e-01, -7.090e-02, -2.430e-02, -2.870e-02, -1.568e-01,\n",
       "         -1.350e-02,  1.412e-01,  1.427e-01,  1.318e-01, -3.660e-02,\n",
       "          2.855e-01,  1.761e-01,  6.350e-02,  7.100e-02, -7.710e-02,\n",
       "          1.043e-01,  1.815e-01, -2.290e-01,  1.413e-01,  1.340e-01,\n",
       "         -3.710e-02,  8.600e-03, -1.318e-01, -1.100e-01, -5.530e-02,\n",
       "         -3.273e-01,  8.300e-03, -6.400e-02,  1.648e-01,  8.400e-02,\n",
       "          1.769e-01,  4.140e-02,  4.600e-03,  4.780e-02, -1.306e-01,\n",
       "          7.920e-02, -1.142e-01,  2.340e-02,  1.331e-01, -5.360e-02,\n",
       "          7.000e-04,  5.140e-02, -1.502e-01, -1.050e-02,  2.860e-02,\n",
       "          1.105e-01,  1.259e-01, -1.060e-02, -5.700e-03, -8.560e-02,\n",
       "         -1.660e-02, -4.980e-02, -8.160e-02,  5.100e-03, -3.560e-02,\n",
       "         -7.950e-02,  5.200e-02,  1.291e-01, -6.590e-02,  5.630e-02,\n",
       "         -1.894e-01,  6.440e-02,  3.410e-02, -7.330e-02,  6.490e-02,\n",
       "         -1.763e-01, -1.280e-02,  3.710e-02,  1.330e-02,  1.970e-02,\n",
       "         -3.650e-01,  1.163e-01,  2.322e-01,  2.061e-01, -8.200e-03,\n",
       "         -2.310e-01, -2.431e-01,  1.219e-01, -2.312e-01,  6.870e-02,\n",
       "          4.800e-02, -7.610e-02,  1.000e-01, -1.866e-01,  2.580e-02,\n",
       "         -4.030e-02, -1.057e-01, -6.590e-02,  5.760e-02,  3.124e-01,\n",
       "         -6.860e-02,  2.410e-02,  5.390e-02,  3.990e-02,  6.080e-02,\n",
       "          7.480e-02,  1.271e-01,  1.850e-02,  4.600e-02, -1.170e-02,\n",
       "          1.490e-02, -4.600e-02, -3.110e-02,  3.840e-02, -2.620e-02,\n",
       "          8.730e-02, -5.400e-03,  7.910e-02, -9.310e-02, -9.210e-02,\n",
       "         -7.100e-02, -1.780e-01, -1.145e-01, -7.070e-02, -7.070e-02,\n",
       "          1.422e-01,  5.930e-02, -2.870e-02,  1.802e-01, -1.734e-01,\n",
       "         -7.740e-02, -7.570e-02,  5.100e-02, -7.700e-02,  2.350e-01,\n",
       "         -7.690e-02, -6.800e-03, -1.150e-02, -2.970e-02,  9.670e-02,\n",
       "          3.320e-02,  4.750e-02,  2.730e-02,  2.700e-03, -1.130e-02,\n",
       "         -1.498e-01, -9.090e-02,  2.155e-01, -1.611e-01,  3.970e-02]],\n",
       "       dtype=float32),\n",
       " array([[ 6.220e-02,  6.280e-02,  2.393e-01,  1.030e-02,  3.810e-02,\n",
       "          1.586e-01,  5.310e-02, -4.900e-03, -3.270e-02, -2.283e-01,\n",
       "          4.800e-03,  2.000e-03, -1.032e-01,  8.110e-02, -1.228e-01,\n",
       "          2.010e-02, -2.330e-02,  1.321e-01,  3.720e-02,  7.090e-02,\n",
       "          4.800e-03,  5.590e-02,  5.600e-02,  3.120e-02,  2.030e-02,\n",
       "          9.290e-02,  5.100e-03, -1.637e-01, -1.068e-01, -2.248e-01,\n",
       "         -6.450e-02,  3.500e-02,  1.022e-01,  4.370e-02, -1.600e-03,\n",
       "          1.540e-02,  2.100e-03, -1.940e-01,  1.418e-01, -7.660e-02,\n",
       "         -3.180e-02,  1.209e-01, -2.086e-01, -4.030e-02, -1.605e-01,\n",
       "         -6.030e-02,  9.550e-02, -1.800e-01,  7.580e-02,  1.360e-01,\n",
       "         -2.710e-02,  2.020e-01, -6.912e-01,  6.750e-02, -1.057e-01,\n",
       "          3.340e-02, -1.053e-01,  1.560e-01,  3.610e-02, -4.110e-02,\n",
       "          3.700e-02, -5.760e-02,  2.320e-02, -5.360e-02, -1.189e-01,\n",
       "         -1.020e-02,  5.030e-02,  1.340e-02, -1.668e-01,  1.040e-02,\n",
       "          9.160e-02,  3.150e-02,  9.320e-02,  2.704e-01, -1.144e-01,\n",
       "         -4.750e-02,  6.480e-02,  5.780e-02, -3.400e-03, -4.800e-02,\n",
       "          2.610e-02, -6.490e-02,  9.560e-02, -2.246e-01,  2.750e-02,\n",
       "          4.160e-02,  1.630e-02, -2.600e-02, -9.030e-02,  9.210e-02,\n",
       "          3.180e-02,  8.000e-04,  4.600e-02, -1.040e-01,  2.930e-02,\n",
       "          8.060e-02, -4.660e-02, -2.990e-02, -5.180e-02, -8.540e-02,\n",
       "         -1.630e-01,  8.680e-02,  4.060e-02, -9.390e-02, -2.146e-01,\n",
       "         -8.160e-02,  1.847e-01, -6.970e-02,  1.462e-01, -1.044e-01,\n",
       "          9.980e-02, -1.972e-01, -8.770e-02, -5.190e-02,  3.850e-02,\n",
       "          6.550e-02, -4.420e-02, -4.800e-02,  1.144e-01, -3.020e-01,\n",
       "          3.150e-02,  1.520e-02, -4.960e-02,  1.340e-01, -7.200e-02,\n",
       "          1.974e-01, -1.870e-02,  1.990e-01, -2.750e-02,  4.160e-02,\n",
       "          3.160e-02,  1.762e-01,  1.070e-02,  2.796e-01,  8.430e-02,\n",
       "         -1.926e-01,  4.520e-02, -8.650e-02, -9.430e-02, -8.730e-02,\n",
       "         -2.610e-02,  8.300e-02,  1.460e-02,  2.599e-01,  1.602e-01,\n",
       "         -3.350e-02,  4.520e-02, -2.124e-01,  5.730e-02,  5.610e-02,\n",
       "          9.720e-02, -1.218e-01,  4.180e-02,  2.820e-02,  1.457e-01,\n",
       "         -9.600e-03, -3.280e-02,  4.140e-02,  1.230e-02,  1.438e-01,\n",
       "         -2.392e-01,  1.950e-02, -8.260e-02,  2.220e-02, -3.630e-02,\n",
       "         -2.060e-02,  1.029e-01,  7.790e-02, -1.540e-02,  5.300e-03,\n",
       "          2.676e-01, -2.140e-02, -1.084e-01, -5.190e-02,  5.520e-02,\n",
       "         -1.000e-03,  2.606e-01,  1.790e-02,  5.800e-03,  9.900e-03,\n",
       "         -1.066e-01,  2.458e-01, -1.551e-01, -2.940e-02,  5.040e-02,\n",
       "         -2.578e-01, -5.590e-02, -1.224e-01,  1.569e-01,  2.395e-01,\n",
       "         -7.780e-02,  2.030e-02, -7.650e-02, -6.510e-02, -3.510e-02,\n",
       "          5.130e-02, -9.800e-03,  2.830e-02,  1.340e-01,  5.560e-02,\n",
       "          1.021e-01, -5.670e-02,  1.682e-01, -3.360e-02,  1.151e-01,\n",
       "          1.223e-01, -1.974e-01, -3.760e-02, -1.560e-01,  7.870e-02,\n",
       "         -3.780e-02, -9.080e-02,  6.980e-02,  1.234e-01,  6.920e-02,\n",
       "          1.020e-02, -6.030e-02, -6.370e-02,  5.190e-02,  1.399e-01,\n",
       "          7.400e-03, -4.550e-02,  8.920e-02, -1.100e-02, -1.026e-01,\n",
       "         -3.300e-02, -4.830e-02, -4.950e-02, -5.810e-02, -9.190e-02,\n",
       "         -5.610e-02, -1.310e-02,  2.519e-01,  1.543e-01,  2.680e-02,\n",
       "         -2.500e-03, -5.890e-02,  1.284e-01, -2.187e-01,  8.900e-03,\n",
       "          1.070e-02, -1.597e-01, -1.143e-01,  2.280e-02, -1.590e-02,\n",
       "          8.460e-02,  3.750e-02, -1.131e-01,  5.370e-02,  3.220e-01,\n",
       "          8.510e-02,  1.031e-01,  1.587e-01,  1.400e-02,  4.840e-02,\n",
       "         -5.910e-02,  2.890e-02, -6.470e-02,  6.790e-02, -1.051e-01,\n",
       "         -2.098e-01, -9.090e-02,  8.330e-02, -4.690e-02,  2.224e-01,\n",
       "         -2.740e-02,  7.550e-02, -8.950e-02, -1.203e-01,  5.700e-03,\n",
       "          5.600e-03, -9.220e-02,  8.020e-02,  3.570e-02,  6.900e-03,\n",
       "          2.690e-02, -3.700e-03,  1.380e-02,  1.470e-02,  8.000e-02,\n",
       "         -1.681e-01, -5.350e-02,  2.224e-01, -2.410e-02,  4.340e-02,\n",
       "         -6.260e-02, -5.560e-02,  1.571e-01, -3.960e-02,  9.150e-02,\n",
       "          9.800e-03,  1.086e-01,  3.460e-02,  8.570e-02,  1.466e-01,\n",
       "         -2.067e-01,  7.700e-03,  1.802e-01, -3.940e-02, -2.430e-02],\n",
       "        [ 6.260e-02,  6.530e-02,  1.540e-02,  1.860e-02,  1.126e-01,\n",
       "          2.356e-01,  4.160e-02,  1.853e-01,  9.290e-02, -5.060e-02,\n",
       "          6.450e-02,  1.107e-01,  2.910e-02,  2.816e-01, -6.460e-02,\n",
       "          1.320e-01,  2.574e-01,  3.200e-02, -1.705e-01,  7.970e-02,\n",
       "         -4.090e-02, -7.810e-02,  1.010e-01, -3.180e-02, -9.000e-02,\n",
       "         -1.826e-01, -1.078e-01, -1.159e-01, -1.250e-01, -1.841e-01,\n",
       "         -8.330e-02,  1.008e-01, -1.596e-01, -4.770e-02, -8.120e-02,\n",
       "          3.590e-02, -2.600e-02, -1.806e-01, -4.300e-02, -2.082e-01,\n",
       "         -2.400e-02,  7.860e-02,  4.120e-02, -1.172e-01, -6.780e-02,\n",
       "         -4.050e-02, -2.050e-02, -1.798e-01, -9.900e-03,  1.190e-01,\n",
       "          7.270e-02,  2.198e-01, -7.324e-01,  1.767e-01, -1.630e-02,\n",
       "          1.440e-02,  2.740e-02,  1.974e-01,  2.120e-02, -4.140e-02,\n",
       "         -6.500e-03, -2.740e-02, -1.250e-01,  1.970e-02,  1.173e-01,\n",
       "         -1.140e-02,  1.500e-02, -1.237e-01, -4.260e-02, -1.005e-01,\n",
       "         -1.254e-01, -5.140e-02,  5.160e-02,  1.487e-01,  7.100e-02,\n",
       "          6.880e-02,  9.380e-02,  1.299e-01, -2.681e-01,  1.584e-01,\n",
       "         -2.140e-02, -1.650e-01, -4.020e-02, -5.720e-02,  6.470e-02,\n",
       "          1.044e-01,  8.650e-02, -4.300e-02, -2.730e-02,  1.152e-01,\n",
       "          9.480e-02,  8.760e-02,  1.030e-02, -2.700e-02,  2.234e-01,\n",
       "         -4.660e-02,  2.237e-01, -7.430e-02, -5.510e-02,  9.150e-02,\n",
       "         -3.112e-01,  2.797e-01, -7.990e-02, -4.500e-03, -3.470e-02,\n",
       "         -1.950e-02,  1.009e-01,  6.310e-02,  1.120e-01,  3.130e-02,\n",
       "          5.070e-02,  1.143e-01, -1.649e-01, -6.480e-02, -1.697e-01,\n",
       "          1.022e-01, -2.410e-02,  1.576e-01, -1.654e-01, -4.020e-01,\n",
       "          9.520e-02,  5.710e-02, -2.012e-01, -2.990e-02,  3.800e-02,\n",
       "          2.372e-01,  9.610e-02,  1.305e-01,  1.183e-01, -2.301e-01,\n",
       "         -1.400e-01,  1.873e-01,  2.910e-02,  4.700e-02, -5.900e-03,\n",
       "          1.422e-01,  5.010e-02, -4.810e-02,  1.164e-01, -4.890e-02,\n",
       "         -1.440e-02,  8.810e-02,  4.400e-02,  1.135e-01,  1.131e-01,\n",
       "         -5.200e-03,  1.063e-01, -3.230e-02,  1.185e-01,  6.820e-02,\n",
       "         -4.680e-02, -2.530e-02,  3.370e-02, -1.128e-01,  3.600e-03,\n",
       "         -1.011e-01,  4.840e-02,  3.480e-02,  3.920e-02,  3.450e-02,\n",
       "         -1.011e-01, -7.090e-02, -2.430e-02, -2.870e-02, -1.568e-01,\n",
       "         -1.350e-02,  1.412e-01,  1.427e-01,  1.318e-01, -3.660e-02,\n",
       "          2.855e-01,  1.761e-01,  6.350e-02,  7.100e-02, -7.710e-02,\n",
       "          1.043e-01,  1.815e-01, -2.290e-01,  1.413e-01,  1.340e-01,\n",
       "         -3.710e-02,  8.600e-03, -1.318e-01, -1.100e-01, -5.530e-02,\n",
       "         -3.273e-01,  8.300e-03, -6.400e-02,  1.648e-01,  8.400e-02,\n",
       "          1.769e-01,  4.140e-02,  4.600e-03,  4.780e-02, -1.306e-01,\n",
       "          7.920e-02, -1.142e-01,  2.340e-02,  1.331e-01, -5.360e-02,\n",
       "          7.000e-04,  5.140e-02, -1.502e-01, -1.050e-02,  2.860e-02,\n",
       "          1.105e-01,  1.259e-01, -1.060e-02, -5.700e-03, -8.560e-02,\n",
       "         -1.660e-02, -4.980e-02, -8.160e-02,  5.100e-03, -3.560e-02,\n",
       "         -7.950e-02,  5.200e-02,  1.291e-01, -6.590e-02,  5.630e-02,\n",
       "         -1.894e-01,  6.440e-02,  3.410e-02, -7.330e-02,  6.490e-02,\n",
       "         -1.763e-01, -1.280e-02,  3.710e-02,  1.330e-02,  1.970e-02,\n",
       "         -3.650e-01,  1.163e-01,  2.322e-01,  2.061e-01, -8.200e-03,\n",
       "         -2.310e-01, -2.431e-01,  1.219e-01, -2.312e-01,  6.870e-02,\n",
       "          4.800e-02, -7.610e-02,  1.000e-01, -1.866e-01,  2.580e-02,\n",
       "         -4.030e-02, -1.057e-01, -6.590e-02,  5.760e-02,  3.124e-01,\n",
       "         -6.860e-02,  2.410e-02,  5.390e-02,  3.990e-02,  6.080e-02,\n",
       "          7.480e-02,  1.271e-01,  1.850e-02,  4.600e-02, -1.170e-02,\n",
       "          1.490e-02, -4.600e-02, -3.110e-02,  3.840e-02, -2.620e-02,\n",
       "          8.730e-02, -5.400e-03,  7.910e-02, -9.310e-02, -9.210e-02,\n",
       "         -7.100e-02, -1.780e-01, -1.145e-01, -7.070e-02, -7.070e-02,\n",
       "          1.422e-01,  5.930e-02, -2.870e-02,  1.802e-01, -1.734e-01,\n",
       "         -7.740e-02, -7.570e-02,  5.100e-02, -7.700e-02,  2.350e-01,\n",
       "         -7.690e-02, -6.800e-03, -1.150e-02, -2.970e-02,  9.670e-02,\n",
       "          3.320e-02,  4.750e-02,  2.730e-02,  2.700e-03, -1.130e-02,\n",
       "         -1.498e-01, -9.090e-02,  2.155e-01, -1.611e-01,  3.970e-02],\n",
       "        [ 1.040e-02,  1.101e-01, -9.820e-02, -1.060e-02, -6.960e-02,\n",
       "          3.900e-02,  2.360e-02,  1.444e-01,  7.800e-02, -1.130e-02,\n",
       "         -6.640e-02, -7.300e-03,  4.870e-02,  3.760e-02,  5.900e-03,\n",
       "          8.900e-03,  1.061e-01, -4.200e-02, -2.031e-01,  5.780e-02,\n",
       "         -7.660e-02, -2.400e-03,  6.170e-02, -9.100e-02,  7.000e-03,\n",
       "         -5.200e-02, -7.300e-03,  2.290e-01, -1.300e-03, -6.730e-02,\n",
       "          7.230e-02,  1.570e-02,  1.800e-02,  1.430e-02, -4.590e-02,\n",
       "          7.820e-02, -7.740e-02,  2.510e-02, -2.830e-02,  2.670e-02,\n",
       "          7.020e-02, -2.800e-03, -7.000e-04,  1.750e-02, -7.410e-02,\n",
       "         -8.420e-02,  9.150e-02, -7.170e-02,  3.170e-02, -5.000e-04,\n",
       "         -1.940e-02, -1.038e-01, -5.677e-01, -5.480e-02,  6.130e-02,\n",
       "         -4.100e-02,  4.010e-02, -3.490e-02,  9.580e-02, -7.380e-02,\n",
       "          9.770e-02, -1.166e-01, -9.180e-02,  4.710e-02, -3.740e-02,\n",
       "         -1.113e-01,  3.230e-02,  6.010e-02, -7.560e-02,  1.760e-02,\n",
       "         -6.490e-02, -4.780e-02, -8.750e-02,  2.620e-02, -2.250e-02,\n",
       "          2.740e-02, -2.030e-02, -5.130e-02,  4.960e-02,  2.361e-01,\n",
       "          2.090e-02,  1.940e-02, -8.970e-02, -1.629e-01, -2.270e-02,\n",
       "         -2.040e-02,  1.340e-01, -6.000e-04,  1.075e-01, -3.520e-02,\n",
       "          3.610e-02, -1.570e-02, -9.000e-03, -7.540e-02, -2.890e-02,\n",
       "          1.240e-02, -7.520e-02,  3.090e-02,  1.522e-01,  6.110e-02,\n",
       "         -1.237e-01, -4.640e-02,  6.860e-02, -9.860e-02, -3.450e-01,\n",
       "          1.120e-02, -2.370e-02, -4.610e-02,  2.000e-04, -8.710e-02,\n",
       "          6.060e-02,  6.110e-02, -6.700e-03,  6.700e-03,  4.160e-02,\n",
       "         -1.548e-01,  3.410e-02, -2.010e-02,  1.600e-03, -3.621e-01,\n",
       "          2.780e-02, -8.100e-03, -4.390e-02,  1.110e-01,  4.750e-02,\n",
       "          1.615e-01,  1.041e-01,  7.930e-02, -6.590e-02,  1.360e-02,\n",
       "         -6.320e-02,  4.170e-02, -1.660e-02,  8.050e-02, -1.167e-01,\n",
       "         -1.179e-01, -4.400e-03, -3.500e-03,  1.610e-01, -4.330e-02,\n",
       "         -4.030e-02,  1.410e-02, -1.430e-02,  3.071e-01, -5.370e-02,\n",
       "          2.470e-02,  1.160e-02, -5.470e-02,  3.800e-03, -5.680e-02,\n",
       "         -5.370e-02, -5.090e-02,  1.990e-02,  3.680e-02,  1.570e-02,\n",
       "         -6.290e-02,  4.320e-02, -5.400e-03,  8.640e-02, -4.230e-02,\n",
       "          1.810e-02,  5.000e-03,  8.100e-02, -1.374e-01, -4.190e-02,\n",
       "         -4.330e-02,  8.460e-02, -8.890e-02, -7.210e-02,  1.480e-02,\n",
       "         -6.200e-02, -3.480e-02,  4.000e-04,  1.515e-01,  1.205e-01,\n",
       "         -1.230e-02,  1.621e-01,  3.035e-01,  1.310e-02,  1.352e-01,\n",
       "          8.800e-02,  1.029e-01,  3.680e-02,  2.970e-02, -3.950e-02,\n",
       "          3.310e-02, -7.410e-02, -1.205e-01, -2.320e-01, -8.000e-03,\n",
       "         -1.340e-02, -5.450e-02,  2.760e-02,  2.520e-02, -5.470e-02,\n",
       "          3.200e-02, -1.028e-01,  2.600e-02,  1.825e-01, -1.410e-02,\n",
       "         -7.350e-02, -1.215e-01, -5.160e-02,  2.760e-02,  1.636e-01,\n",
       "         -2.550e-02,  3.350e-02, -7.510e-02, -6.130e-02,  9.800e-03,\n",
       "         -9.600e-03,  1.900e-03, -1.141e-01,  9.400e-03,  6.660e-02,\n",
       "          3.230e-02, -1.211e-01,  1.040e-02, -1.071e-01,  1.730e-02,\n",
       "          1.065e-01,  6.270e-02, -1.356e-01,  1.173e-01,  2.300e-03,\n",
       "          1.258e-01, -1.000e-04, -1.340e-02,  1.400e-03, -3.660e-02,\n",
       "          5.610e-02, -8.310e-02,  3.355e-01, -5.040e-02, -3.110e-02,\n",
       "         -4.380e-02,  4.750e-02,  1.368e-01, -2.439e-01,  1.537e-01,\n",
       "         -8.040e-02, -2.430e-02,  9.300e-03, -1.510e-02, -6.000e-03,\n",
       "          6.170e-02,  2.460e-02,  1.273e-01, -1.280e-02,  3.310e-01,\n",
       "          7.850e-02,  1.123e-01,  1.620e-02,  6.200e-03,  3.092e-01,\n",
       "          1.521e-01, -5.420e-02, -2.390e-02, -7.900e-03, -3.360e-02,\n",
       "          4.910e-02,  6.380e-02,  7.270e-02, -7.760e-02, -6.799e-01,\n",
       "          4.870e-02, -2.570e-02,  5.000e-02,  2.450e-02,  9.260e-02,\n",
       "          5.130e-02,  9.150e-02,  5.000e-03, -1.723e-01, -2.950e-02,\n",
       "          1.560e-02, -2.650e-02, -1.024e-01,  7.150e-02, -5.870e-02,\n",
       "         -4.600e-03, -6.060e-02,  6.560e-02, -1.080e-02,  2.080e-02,\n",
       "          2.010e-02,  8.610e-02, -4.880e-02, -6.620e-02, -3.860e-02,\n",
       "         -4.180e-02, -8.740e-02,  4.500e-03, -1.039e-01, -1.243e-01,\n",
       "         -2.870e-02, -9.540e-02,  1.598e-01, -3.290e-02,  7.980e-02]],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53460"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2=np.array(X_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53460, 3, 300)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder=LabelEncoder()\n",
    "encoder.fit(y_1)\n",
    "y_1=encoder.transform(y_1)\n",
    "y=np_utils.to_categorical(y_1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_1, y, test_size = 0.2, random_state = 0)\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.array(X_train)\n",
    "X_test=np.array(X_test)\n",
    "y_train=np.array(y_train)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10692, 7)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42768, 7)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42768"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53460, 3, 300)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53460,)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicholas\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  \"\"\"\n",
      "C:\\Users\\Nicholas\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(units=50, return_sequences=True, input_shape=(None, 300...)`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Initialising the RNN\n",
    "regressor = Sequential()\n",
    "\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_dim=300))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "42768/42768 [==============================] - 18s 419us/step - loss: 0.0495 - acc: 0.7586\n",
      "Epoch 2/25\n",
      "42768/42768 [==============================] - 15s 358us/step - loss: 0.0490 - acc: 0.7635\n",
      "Epoch 3/25\n",
      "42768/42768 [==============================] - 15s 358us/step - loss: 0.0488 - acc: 0.7621\n",
      "Epoch 4/25\n",
      "42768/42768 [==============================] - 15s 359us/step - loss: 0.0488 - acc: 0.7621\n",
      "Epoch 5/25\n",
      "42768/42768 [==============================] - 15s 359us/step - loss: 0.0486 - acc: 0.7650\n",
      "Epoch 6/25\n",
      "42768/42768 [==============================] - 15s 360us/step - loss: 0.0487 - acc: 0.7630\n",
      "Epoch 7/25\n",
      "42768/42768 [==============================] - 15s 362us/step - loss: 0.0485 - acc: 0.7640\n",
      "Epoch 8/25\n",
      "42768/42768 [==============================] - 16s 370us/step - loss: 0.0481 - acc: 0.7680\n",
      "Epoch 9/25\n",
      "42768/42768 [==============================] - 16s 367us/step - loss: 0.0481 - acc: 0.7662\n",
      "Epoch 10/25\n",
      "42768/42768 [==============================] - 16s 384us/step - loss: 0.0480 - acc: 0.7675\n",
      "Epoch 11/25\n",
      "42768/42768 [==============================] - 16s 369us/step - loss: 0.0479 - acc: 0.7684\n",
      "Epoch 12/25\n",
      "42768/42768 [==============================] - 16s 364us/step - loss: 0.0476 - acc: 0.7698\n",
      "Epoch 13/25\n",
      "42768/42768 [==============================] - 16s 369us/step - loss: 0.0473 - acc: 0.7725\n",
      "Epoch 14/25\n",
      "42768/42768 [==============================] - 17s 386us/step - loss: 0.0474 - acc: 0.7710\n",
      "Epoch 15/25\n",
      "42768/42768 [==============================] - 16s 371us/step - loss: 0.0474 - acc: 0.7715\n",
      "Epoch 16/25\n",
      "42768/42768 [==============================] - 17s 408us/step - loss: 0.0468 - acc: 0.7753\n",
      "Epoch 17/25\n",
      "42768/42768 [==============================] - 16s 376us/step - loss: 0.0470 - acc: 0.7736\n",
      "Epoch 18/25\n",
      "42768/42768 [==============================] - 16s 378us/step - loss: 0.0466 - acc: 0.7755\n",
      "Epoch 19/25\n",
      "42768/42768 [==============================] - 16s 384us/step - loss: 0.0466 - acc: 0.7751\n",
      "Epoch 20/25\n",
      "42768/42768 [==============================] - 16s 367us/step - loss: 0.0464 - acc: 0.7778\n",
      "Epoch 21/25\n",
      "42768/42768 [==============================] - 16s 367us/step - loss: 0.0462 - acc: 0.7777\n",
      "Epoch 22/25\n",
      "42768/42768 [==============================] - 16s 369us/step - loss: 0.0460 - acc: 0.7771\n",
      "Epoch 23/25\n",
      "42768/42768 [==============================] - 17s 392us/step - loss: 0.0461 - acc: 0.7789\n",
      "Epoch 24/25\n",
      "42768/42768 [==============================] - 16s 365us/step - loss: 0.0462 - acc: 0.7768\n",
      "Epoch 25/25\n",
      "42768/42768 [==============================] - 17s 398us/step - loss: 0.0456 - acc: 0.7794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x53bbc5c0>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = 'adam', metrics=['accuracy'], loss = 'mean_squared_error')\n",
    "regressor.fit(X_train, y_train, epochs = 25, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10692/10692 [==============================] - 1s 117us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10446360716760003, 0.48110736999625886]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Initial model with .48 test accuracy</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Saving and loading</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = regressor.to_json()\n",
    "with open(\"emotions_model_6.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "regressor.save_weights(\"emotions_model_6.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('emotions_regressor.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"emotions_regressor.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.09755597 0.04315098 0.17637494 0.07367538 0.43375415 0.07726857\n",
      "  0.09988091]\n",
      " [0.56483126 0.07285608 0.13253172 0.04942662 0.09893434 0.02065588\n",
      "  0.0610196 ]]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(loaded_model.predict(transform_input('I like pie a whole bunch a lot')))\n",
    "except ValueError:\n",
    "    print('Input size too small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_avg(text):\n",
    "    X, X_len=transform_input(text)\n",
    "    prediction=loaded_model.predict(transform_input(text)[0])\n",
    "    prediction=np.mean(prediction, axis=0)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02197286, 0.90678847, 0.01035543, 0.01425846, 0.00490067,\n",
       "       0.01707822, 0.01889859], dtype=float32)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pie_mat=predict_avg('I hate all aliens they are evil bastards')\n",
    "pie_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0:anger\n",
    "\n",
    "1:disgust\n",
    "\n",
    "2:fear\n",
    "\n",
    "3:guilt\n",
    "\n",
    "4: joy\n",
    "\n",
    "5:sadness\n",
    "\n",
    "6:shame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loaded_model (model 1) doesn't do very well. Let's try to make another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Model with unknown timespan</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=isear[1]\n",
    "X=X.apply(clean)\n",
    "y=isear[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits=word_splits(X)\n",
    "numbers_series=splits.apply(vec_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_no_window(text):\n",
    "    X=pd.Series(text).apply(clean)\n",
    "    splits=word_splits(X)\n",
    "    numbers_series=splits.apply(vec_word)\n",
    "    return numbers_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.apply(transform_no_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1=X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [[0.032, 0.0381, -0.0299, -0.0745, -0.0624, -0...\n",
       "1       [[-0.0036, -0.1675, 0.0635, -0.0249, 0.0098, -...\n",
       "2       [[0.079, -0.0397, 0.005, 0.0136, -0.0226, -0.0...\n",
       "3       [[-0.0432, 0.037, -0.0039, 0.0524, -0.1216, -0...\n",
       "4       [[0.0586, -0.037, -0.081, -0.1985, -0.1255, -0...\n",
       "5       [[0.1129, -0.0975, 0.0769, -0.071, 0.0645, -0....\n",
       "6       [[-0.0372, 0.0615, 0.0167, -0.0382, 0.0207, -0...\n",
       "7       [[0.1912, -0.0745, 0.0554, -0.0277, -0.0276, 0...\n",
       "8       [[0.0092, -0.0123, -0.0336, 0.0269, 0.031, 0.0...\n",
       "9       [[-0.016, -0.0003, -0.1684, 0.0899, -0.02, -0....\n",
       "10      [[0.0103, 0.0984, 0.1326, 0.0845, 0.0898, -0.1...\n",
       "11      [[-0.0368, -0.0336, 0.0182, 0.0258, -0.0327, -...\n",
       "12      [[-0.1362, 0.1148, -0.0027, -0.0033, 0.1185, -...\n",
       "13      [[-0.0432, 0.037, -0.0039, 0.0524, -0.1216, -0...\n",
       "14      [[-0.0079, -0.0009, -0.0813, -0.2044, 0.1367, ...\n",
       "15      [[0.0458, -0.0362, 0.0156, 0.0027, -0.053, 0.0...\n",
       "16      [[0.0458, -0.0362, 0.0156, 0.0027, -0.053, 0.0...\n",
       "17      [[0.0458, -0.0362, 0.0156, 0.0027, -0.053, 0.0...\n",
       "18      [[0.0458, -0.0362, 0.0156, 0.0027, -0.053, 0.0...\n",
       "19      [[0.0458, -0.0362, 0.0156, 0.0027, -0.053, 0.0...\n",
       "20      [[0.0458, -0.0362, 0.0156, 0.0027, -0.053, 0.0...\n",
       "21      [[-0.1781, 0.0768, 0.1997, -0.1367, -0.0278, -...\n",
       "22      [[-0.1634, 0.0061, -0.0523, -0.0952, -0.2584, ...\n",
       "23      [[-0.0329, 0.0098, -0.0657, 0.0019, 0.066, -0....\n",
       "24      [[0.0534, 0.023, 0.0731, -0.1413, -0.0934, 0.0...\n",
       "25      [[-0.0072, 0.0567, -0.0194, 0.0643, 0.1007, 0....\n",
       "26      [[0.1449, -0.0717, 0.0755, -0.0863, -0.0139, 0...\n",
       "27      [[-0.1182, 0.0039, 0.074, -0.0782, -0.143, -0....\n",
       "28      [[-0.0217, -0.1088, 0.1682, 0.0173, 0.1315, -0...\n",
       "29      [[-0.0781, -0.0677, 0.1376, -0.0176, 0.0218, 0...\n",
       "                              ...                        \n",
       "7486    [[0.0351, 0.0176, 0.0075, -0.0584, 0.1963, -0....\n",
       "7487    [[-0.224, -0.1629, -0.0855, -0.1952, 0.0535, 0...\n",
       "7488    [[0.0979, -0.1433, 0.0157, 0.0823, 0.0436, 0.0...\n",
       "7489    [[0.1365, -0.03, -0.1251, -0.003, -0.0226, -0....\n",
       "7490    [[-0.0781, -0.0677, 0.1376, -0.0176, 0.0218, 0...\n",
       "7491    [[-0.2699, -0.1004, -0.1057, 0.0608, 0.1755, 0...\n",
       "7492    [[-0.0183, -0.082, -0.1086, -0.0261, -0.0004, ...\n",
       "7493    [[-0.0109, -0.0306, -0.118, -0.0267, 0.2778, 0...\n",
       "7494    [[0.0445, -0.0083, 0.005, -0.1467, -0.0026, -0...\n",
       "7495    [[0.0092, -0.0123, -0.0336, 0.0269, 0.031, 0.0...\n",
       "7496    [[-0.0798, 0.0482, -0.0422, 0.0111, 0.0124, -0...\n",
       "7497    [[-0.0558, -0.0681, -0.0805, 0.0409, -0.2693, ...\n",
       "7498    [[0.0315, -0.0698, -0.0005, 0.0365, 0.0015, -0...\n",
       "7499    [[0.0949, -0.0875, 0.0512, -0.1082, 0.0241, 0....\n",
       "7500    [[0.0789, -0.0313, 0.1218, -0.0199, -0.0013, 0...\n",
       "7501    [[0.0382, 0.083, -0.0656, -0.1296, 0.0654, 0.0...\n",
       "7502    [[-0.0752, -0.0111, -0.136, -0.0281, 0.0766, 0...\n",
       "7503    [[0.0108, -0.0204, -0.0371, 0.0167, -0.0105, 0...\n",
       "7504    [[0.0897, -0.089, -0.1608, -0.0915, 0.1564, 0....\n",
       "7505    [[0.0322, -0.0539, 0.0034, -0.03, -0.0082, 0.1...\n",
       "7506    [[0.0938, 0.014, 0.1099, 0.0604, -0.0615, 0.11...\n",
       "7507    [[0.111, -0.0062, -0.0553, -0.0384, 0.0806, 0....\n",
       "7508    [[0.3411, -0.0711, 0.0519, -0.0978, 0.0126, -0...\n",
       "7509    [[-0.0382, -0.0043, 0.2217, -0.0783, -0.0764, ...\n",
       "7510    [[0.0256, 0.1352, 0.0608, -0.0799, -0.0198, -0...\n",
       "7511    [[0.0134, 0.0171, -0.0344, 0.0912, -0.014, 0.0...\n",
       "7512    [[0.1171, -0.0058, 0.0053, -0.0278, 0.0515, -0...\n",
       "7513    [[0.1576, 0.0211, 0.0195, 0.0959, 0.0006, 0.08...\n",
       "7514    [[-0.1756, 0.0695, 0.0847, 0.0988, -0.1196, -0...\n",
       "7515    [[-0.0817, -0.0154, 0.042, 0.0736, 0.0636, -0....\n",
       "Name: 0, Length: 7516, dtype: object"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1=X_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7516,)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2=np.array(X_1)\n",
    "X_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([[ 0.032 ,  0.0381, -0.0299, ...,  0.1316,  0.1363,  0.044 ],\n",
       "       [-0.0372,  0.0615,  0.0167, ...,  0.1405, -0.0883, -0.1164],\n",
       "       [ 0.0622,  0.0628,  0.2393, ...,  0.1802, -0.0394, -0.0243],\n",
       "       ...,\n",
       "       [ 0.0104,  0.1101, -0.0982, ...,  0.1598, -0.0329,  0.0798],\n",
       "       [ 0.0055, -0.1195,  0.0729, ...,  0.2087, -0.0779, -0.0624],\n",
       "       [-0.1902, -0.1442, -0.1249, ...,  0.2267, -0.0037,  0.0915]],\n",
       "      dtype=float32),\n",
       "       array([[-0.0036, -0.1675,  0.0635, ...,  0.1275,  0.1066, -0.0399],\n",
       "       [ 0.0863, -0.0405,  0.0437, ...,  0.1703, -0.3191, -0.0287],\n",
       "       [-0.1006, -0.0988, -0.1582, ...,  0.2289,  0.1009, -0.018 ],\n",
       "       ...,\n",
       "       [ 0.1084,  0.1093, -0.1632, ..., -0.0037, -0.2236, -0.2337],\n",
       "       [-0.0112, -0.1144, -0.0171, ...,  0.1761,  0.0193, -0.0004],\n",
       "       [ 0.1013,  0.0365,  0.0062, ...,  0.0657,  0.0512, -0.0055]],\n",
       "      dtype=float32),\n",
       "       array([[ 0.079 , -0.0397,  0.005 , ...,  0.1426, -0.1237, -0.0863],\n",
       "       [ 0.1821, -0.0348, -0.0131, ...,  0.1844, -0.0406,  0.1185],\n",
       "       [ 0.1273, -0.1795,  0.2076, ...,  0.1616, -0.0369,  0.0505],\n",
       "       [ 0.0515, -0.0238, -0.0343, ...,  0.153 ,  0.137 , -0.0806],\n",
       "       [-0.1741, -0.1503, -0.0835, ...,  0.3085, -0.1184,  0.0525]],\n",
       "      dtype=float32)], dtype=object)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder=LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y=encoder.transform(y)\n",
    "y=np_utils.to_categorical(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 300)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input shape\n",
    "\n",
    "3D tensor with shape (batch_size, timesteps, input_dim)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicholas\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  \"\"\"\n",
      "C:\\Users\\Nicholas\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(units=50, return_sequences=True, input_shape=(None, 300...)`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Initialising the RNN\n",
    "regressor = Sequential()\n",
    "\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_dim=300))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = 'adam', metrics=['accuracy'], loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(new_input, y_train, epochs = 25, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = Input(shape=(None, 300)) # unknown timespan, fixed feature size\n",
    "lstm = LSTM(20)\n",
    "dense=Dense(units = 7)\n",
    "dense_out=dense(I)\n",
    "f = K.function(inputs=[I], outputs=[lstm(I)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_input=list(new_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(new_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(input=[I], output=[dense_out])\n",
    "model.compile(optimizer = 'adam', metrics=['accuracy'], loss = 'mean_squared_error')\n",
    "model.fit(new_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 300)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_input=list(X_train)\n",
    "new_input=[np.reshape(arr, (1, arr.shape[0], 300)) for arr in new_input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.00189861, -0.02905425,  0.01028993,  0.05693588,  0.12599891,\n",
       "         -0.07233123, -0.15039034, -0.03753458,  0.0746619 ,  0.03368369,\n",
       "         -0.01838236, -0.05823456, -0.0047072 , -0.00749667, -0.03643454,\n",
       "          0.03162642,  0.02647312,  0.02489861,  0.06106438,  0.00751286]],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(new_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#window\n",
    "X_1 = []\n",
    "    for index in range(0, len(numbers_series)):\n",
    "        doc=numbers_series.iloc[index]\n",
    "        for i in range(3, len(doc)):\n",
    "            X_1.append(doc[i-3:i])\n",
    "    return np.array(X_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Second model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicholas\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  \"\"\"\n",
      "C:\\Users\\Nicholas\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(units=100, return_sequences=True, input_shape=(None, 300...)`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Initialising the RNN\n",
    "regressor = Sequential()\n",
    "\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 100, return_sequences = True, input_dim=300))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 100, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 100, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 100, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 100, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 100))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 7, kernel_initializer = 'uniform', activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam=Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = adam, metrics=['accuracy'], loss = 'categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "42768/42768 [==============================] - 32s 748us/step - loss: 0.8835 - acc: 0.6842\n",
      "Epoch 2/25\n",
      "42768/42768 [==============================] - 32s 737us/step - loss: 0.8675 - acc: 0.6885\n",
      "Epoch 3/25\n",
      "42768/42768 [==============================] - 32s 743us/step - loss: 0.8545 - acc: 0.6947\n",
      "Epoch 4/25\n",
      "42768/42768 [==============================] - 31s 735us/step - loss: 0.8418 - acc: 0.7000\n",
      "Epoch 5/25\n",
      "42768/42768 [==============================] - 31s 732us/step - loss: 0.8274 - acc: 0.7037\n",
      "Epoch 6/25\n",
      "42768/42768 [==============================] - 31s 732us/step - loss: 0.8193 - acc: 0.7093\n",
      "Epoch 7/25\n",
      "42768/42768 [==============================] - 32s 750us/step - loss: 0.8059 - acc: 0.71211s - l\n",
      "Epoch 8/25\n",
      "42768/42768 [==============================] - 32s 747us/step - loss: 0.8002 - acc: 0.7122\n",
      "Epoch 9/25\n",
      "42768/42768 [==============================] - 32s 757us/step - loss: 0.7883 - acc: 0.7179\n",
      "Epoch 10/25\n",
      "42768/42768 [==============================] - 33s 765us/step - loss: 0.7722 - acc: 0.7258\n",
      "Epoch 11/25\n",
      "42768/42768 [==============================] - 32s 758us/step - loss: 0.7584 - acc: 0.7316\n",
      "Epoch 12/25\n",
      "42768/42768 [==============================] - 32s 751us/step - loss: 0.7558 - acc: 0.7318\n",
      "Epoch 13/25\n",
      "42768/42768 [==============================] - 32s 751us/step - loss: 0.7494 - acc: 0.7315\n",
      "Epoch 14/25\n",
      "42768/42768 [==============================] - 32s 753us/step - loss: 0.7293 - acc: 0.7412\n",
      "Epoch 15/25\n",
      "42768/42768 [==============================] - 32s 754us/step - loss: 0.7254 - acc: 0.7419\n",
      "Epoch 16/25\n",
      "42768/42768 [==============================] - 32s 747us/step - loss: 0.7128 - acc: 0.7475\n",
      "Epoch 17/25\n",
      "42768/42768 [==============================] - 32s 745us/step - loss: 0.7022 - acc: 0.7511\n",
      "Epoch 18/25\n",
      "42768/42768 [==============================] - 32s 748us/step - loss: 0.6936 - acc: 0.7562\n",
      "Epoch 19/25\n",
      "42768/42768 [==============================] - 32s 748us/step - loss: 0.6867 - acc: 0.7577\n",
      "Epoch 20/25\n",
      "42768/42768 [==============================] - 32s 749us/step - loss: 0.6770 - acc: 0.7605\n",
      "Epoch 21/25\n",
      "42768/42768 [==============================] - 32s 756us/step - loss: 0.6689 - acc: 0.7668\n",
      "Epoch 22/25\n",
      "42768/42768 [==============================] - 34s 792us/step - loss: 0.6641 - acc: 0.7670\n",
      "Epoch 23/25\n",
      "42768/42768 [==============================] - 33s 771us/step - loss: 0.6543 - acc: 0.7704\n",
      "Epoch 24/25\n",
      "42768/42768 [==============================] - 32s 746us/step - loss: 0.6436 - acc: 0.7735\n",
      "Epoch 25/25\n",
      "42768/42768 [==============================] - 34s 804us/step - loss: 0.6421 - acc: 0.7752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xe51b8940>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train, y_train, epochs = 25, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10692/10692 [==============================] - 2s 215us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.791913282456489, 0.48054620276842497]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = regressor.to_json()\n",
    "with open(\"emotions_regressor_2.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "regressor.save_weights(\"emotions_regressor_2.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Third model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicholas\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  \"\"\"\n",
      "C:\\Users\\Nicholas\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(units=100, return_sequences=True, input_shape=(None, 300...)`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Initialising the RNN\n",
    "regressor = Sequential()\n",
    "\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 100, return_sequences = True, input_dim=300))\n",
    "regressor.add(Dropout(0.5))\n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 100, return_sequences = True))\n",
    "regressor.add(Dropout(0.5))\n",
    "\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 100, return_sequences = True))\n",
    "regressor.add(Dropout(0.5))\n",
    "\n",
    "# Adding a LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 100, return_sequences = True))\n",
    "regressor.add(Dropout(0.5))\n",
    "\n",
    "# Adding a LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 100, return_sequences = True))\n",
    "regressor.add(Dropout(0.5))\n",
    "\n",
    "# Adding a LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 100))\n",
    "regressor.add(Dropout(0.5))\n",
    "\n",
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 7, kernel_initializer = 'uniform', activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam=Adam(lr=0.0007, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = adam, metrics=['accuracy'], loss = 'categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42768 samples, validate on 10692 samples\n",
      "Epoch 1/100\n",
      "42768/42768 [==============================] - 33s 783us/step - loss: 0.5579 - acc: 0.8134 - val_loss: 2.3434 - val_acc: 0.4560\n",
      "Epoch 2/100\n",
      " 3776/42768 [=>............................] - ETA: 28s - loss: 0.5140 - acc: 0.8284"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-196-2bf9d2c89e9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1002\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1003\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1236\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1237\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2482\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2483\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist=regressor.fit(X_train, y_train, epochs = 100, batch_size = 32, validation_data=(X_test, y_test), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10692/10692 [==============================] - 2s 215us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.214059761745226, 0.4675458286569398]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(hist.history['loss'][500:])\n",
    "pyplot.plot(hist.history['val_loss'][500:])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Fourth model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicholas\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  \"\"\"\n",
      "C:\\Users\\Nicholas\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(units=100, return_sequences=True, input_shape=(None, 300...)`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Initialising the RNN\n",
    "regressor = Sequential()\n",
    "\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 100, return_sequences = True, input_dim=300))\n",
    "regressor.add(SpatialDropout1D(0.5))\n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 100, return_sequences = True))\n",
    "regressor.add(SpatialDropout1D(0.5))\n",
    "\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 100, return_sequences = True))\n",
    "regressor.add(SpatialDropout1D(0.5))\n",
    "\n",
    "# Adding a LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 100, return_sequences = True))\n",
    "regressor.add(SpatialDropout1D(0.5))\n",
    "\n",
    "# Adding a LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 100, return_sequences = True))\n",
    "regressor.add(SpatialDropout1D(0.5))\n",
    "\n",
    "# Adding a LSTM layer\n",
    "regressor.add(LSTM(units = 100))\n",
    "\n",
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 7, kernel_initializer = 'uniform', activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = 'adam', metrics=['accuracy'], loss = 'categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42768 samples, validate on 10692 samples\n",
      "Epoch 1/100\n",
      "42768/42768 [==============================] - 43s 1000us/step - loss: 1.8514 - acc: 0.2293 - val_loss: 1.7700 - val_acc: 0.2788\n",
      "Epoch 2/100\n",
      "42768/42768 [==============================] - 34s 789us/step - loss: 1.7607 - acc: 0.2812 - val_loss: 1.7198 - val_acc: 0.3098\n",
      "Epoch 3/100\n",
      "42768/42768 [==============================] - 34s 789us/step - loss: 1.7203 - acc: 0.3059 - val_loss: 1.6828 - val_acc: 0.3389\n",
      "Epoch 4/100\n",
      "42768/42768 [==============================] - 34s 791us/step - loss: 1.6804 - acc: 0.3327 - val_loss: 1.6587 - val_acc: 0.3534\n",
      "Epoch 5/100\n",
      "42768/42768 [==============================] - 34s 795us/step - loss: 1.6542 - acc: 0.3474 - val_loss: 1.6329 - val_acc: 0.3690\n",
      "Epoch 6/100\n",
      "42768/42768 [==============================] - 34s 789us/step - loss: 1.6295 - acc: 0.3625 - val_loss: 1.6260 - val_acc: 0.3715\n",
      "Epoch 7/100\n",
      "42768/42768 [==============================] - 34s 792us/step - loss: 1.6074 - acc: 0.3700 - val_loss: 1.6168 - val_acc: 0.3734\n",
      "Epoch 8/100\n",
      "42768/42768 [==============================] - 35s 824us/step - loss: 1.5885 - acc: 0.3795 - val_loss: 1.6055 - val_acc: 0.3838\n",
      "Epoch 9/100\n",
      "42768/42768 [==============================] - 34s 791us/step - loss: 1.5681 - acc: 0.3909 - val_loss: 1.5949 - val_acc: 0.3889\n",
      "Epoch 10/100\n",
      "42768/42768 [==============================] - 34s 790us/step - loss: 1.5457 - acc: 0.4021 - val_loss: 1.5926 - val_acc: 0.3923\n",
      "Epoch 11/100\n",
      "42768/42768 [==============================] - 34s 795us/step - loss: 1.5269 - acc: 0.4078 - val_loss: 1.5851 - val_acc: 0.3937\n",
      "Epoch 12/100\n",
      "42768/42768 [==============================] - 34s 795us/step - loss: 1.5076 - acc: 0.4171 - val_loss: 1.5806 - val_acc: 0.4001\n",
      "Epoch 13/100\n",
      "42768/42768 [==============================] - 35s 810us/step - loss: 1.4895 - acc: 0.4273 - val_loss: 1.5758 - val_acc: 0.4022\n",
      "Epoch 14/100\n",
      "42768/42768 [==============================] - 35s 807us/step - loss: 1.4701 - acc: 0.4357 - val_loss: 1.5702 - val_acc: 0.4065\n",
      "Epoch 15/100\n",
      "42768/42768 [==============================] - 35s 809us/step - loss: 1.4512 - acc: 0.4448 - val_loss: 1.5654 - val_acc: 0.4126\n",
      "Epoch 16/100\n",
      "42768/42768 [==============================] - 34s 797us/step - loss: 1.4336 - acc: 0.4531 - val_loss: 1.5682 - val_acc: 0.4111\n",
      "Epoch 17/100\n",
      "42768/42768 [==============================] - 34s 798us/step - loss: 1.4111 - acc: 0.4609 - val_loss: 1.5681 - val_acc: 0.4151\n",
      "Epoch 18/100\n",
      "42768/42768 [==============================] - 35s 824us/step - loss: 1.3965 - acc: 0.4684 - val_loss: 1.5747 - val_acc: 0.4115\n",
      "Epoch 19/100\n",
      "42768/42768 [==============================] - 34s 797us/step - loss: 1.3815 - acc: 0.4737 - val_loss: 1.5693 - val_acc: 0.4152\n",
      "Epoch 20/100\n",
      "42768/42768 [==============================] - 34s 796us/step - loss: 1.3642 - acc: 0.4814 - val_loss: 1.5850 - val_acc: 0.4150\n",
      "Epoch 21/100\n",
      "42768/42768 [==============================] - 34s 796us/step - loss: 1.3480 - acc: 0.4892 - val_loss: 1.5762 - val_acc: 0.4215\n",
      "Epoch 22/100\n",
      "42768/42768 [==============================] - 34s 801us/step - loss: 1.3335 - acc: 0.4940 - val_loss: 1.5699 - val_acc: 0.4179\n",
      "Epoch 23/100\n",
      "42768/42768 [==============================] - 34s 798us/step - loss: 1.3175 - acc: 0.5024 - val_loss: 1.5783 - val_acc: 0.4199\n",
      "Epoch 24/100\n",
      "42768/42768 [==============================] - 34s 798us/step - loss: 1.3008 - acc: 0.5097 - val_loss: 1.5713 - val_acc: 0.4220\n",
      "Epoch 25/100\n",
      "42768/42768 [==============================] - 34s 801us/step - loss: 1.2875 - acc: 0.5126 - val_loss: 1.5693 - val_acc: 0.4212\n",
      "Epoch 26/100\n",
      "42768/42768 [==============================] - 34s 801us/step - loss: 1.2721 - acc: 0.5207 - val_loss: 1.5945 - val_acc: 0.4198\n",
      "Epoch 27/100\n",
      "42768/42768 [==============================] - 34s 801us/step - loss: 1.2606 - acc: 0.5260 - val_loss: 1.5812 - val_acc: 0.4229\n",
      "Epoch 28/100\n",
      "42768/42768 [==============================] - 34s 802us/step - loss: 1.2416 - acc: 0.5303 - val_loss: 1.5680 - val_acc: 0.4298\n",
      "Epoch 29/100\n",
      "42768/42768 [==============================] - 35s 807us/step - loss: 1.2321 - acc: 0.5362 - val_loss: 1.5716 - val_acc: 0.4314\n",
      "Epoch 30/100\n",
      "42768/42768 [==============================] - 34s 805us/step - loss: 1.2163 - acc: 0.5418 - val_loss: 1.5965 - val_acc: 0.4321\n",
      "Epoch 31/100\n",
      "42768/42768 [==============================] - 34s 804us/step - loss: 1.2094 - acc: 0.5447 - val_loss: 1.6050 - val_acc: 0.4239\n",
      "Epoch 32/100\n",
      "42768/42768 [==============================] - 35s 807us/step - loss: 1.1934 - acc: 0.5533 - val_loss: 1.6068 - val_acc: 0.4275\n",
      "Epoch 33/100\n",
      "42768/42768 [==============================] - 35s 810us/step - loss: 1.1802 - acc: 0.5576 - val_loss: 1.5984 - val_acc: 0.4238\n",
      "Epoch 34/100\n",
      "42768/42768 [==============================] - 34s 805us/step - loss: 1.1694 - acc: 0.5632 - val_loss: 1.5965 - val_acc: 0.4297\n",
      "Epoch 35/100\n",
      "42768/42768 [==============================] - 34s 806us/step - loss: 1.1566 - acc: 0.5704 - val_loss: 1.6290 - val_acc: 0.4228\n",
      "Epoch 36/100\n",
      "42768/42768 [==============================] - 35s 809us/step - loss: 1.1451 - acc: 0.5739 - val_loss: 1.6159 - val_acc: 0.4234\n",
      "Epoch 37/100\n",
      "42768/42768 [==============================] - 35s 812us/step - loss: 1.1327 - acc: 0.5764 - val_loss: 1.6349 - val_acc: 0.4266\n",
      "Epoch 38/100\n",
      "42768/42768 [==============================] - 35s 811us/step - loss: 1.1229 - acc: 0.5822 - val_loss: 1.6340 - val_acc: 0.4305\n",
      "Epoch 39/100\n",
      "42768/42768 [==============================] - 36s 851us/step - loss: 1.1099 - acc: 0.5889 - val_loss: 1.6357 - val_acc: 0.4316\n",
      "Epoch 40/100\n",
      "42768/42768 [==============================] - 38s 881us/step - loss: 1.1009 - acc: 0.5920 - val_loss: 1.6566 - val_acc: 0.4288\n",
      "Epoch 41/100\n",
      "42768/42768 [==============================] - 38s 883us/step - loss: 1.0905 - acc: 0.5983 - val_loss: 1.6533 - val_acc: 0.4309\n",
      "Epoch 42/100\n",
      "42768/42768 [==============================] - 35s 828us/step - loss: 1.0816 - acc: 0.5994 - val_loss: 1.6633 - val_acc: 0.4313\n",
      "Epoch 43/100\n",
      "42768/42768 [==============================] - 37s 862us/step - loss: 1.0719 - acc: 0.6044 - val_loss: 1.6786 - val_acc: 0.4314\n",
      "Epoch 44/100\n",
      "42768/42768 [==============================] - 39s 923us/step - loss: 1.0565 - acc: 0.6099 - val_loss: 1.6864 - val_acc: 0.4361\n",
      "Epoch 45/100\n",
      "42768/42768 [==============================] - 36s 838us/step - loss: 1.0485 - acc: 0.6152 - val_loss: 1.6755 - val_acc: 0.4356\n",
      "Epoch 46/100\n",
      "42768/42768 [==============================] - 37s 863us/step - loss: 1.0411 - acc: 0.6156 - val_loss: 1.6822 - val_acc: 0.4369\n",
      "Epoch 47/100\n",
      "42768/42768 [==============================] - 36s 834us/step - loss: 1.0383 - acc: 0.6189 - val_loss: 1.6861 - val_acc: 0.4335\n",
      "Epoch 48/100\n",
      "42768/42768 [==============================] - 36s 832us/step - loss: 1.0215 - acc: 0.6267 - val_loss: 1.7073 - val_acc: 0.4366\n",
      "Epoch 49/100\n",
      "42768/42768 [==============================] - 38s 891us/step - loss: 1.0156 - acc: 0.6290 - val_loss: 1.7236 - val_acc: 0.4357\n",
      "Epoch 50/100\n",
      "42768/42768 [==============================] - 37s 869us/step - loss: 1.0002 - acc: 0.6333 - val_loss: 1.7242 - val_acc: 0.4332\n",
      "Epoch 51/100\n",
      "42768/42768 [==============================] - 34s 802us/step - loss: 0.9981 - acc: 0.6357 - val_loss: 1.7567 - val_acc: 0.4338\n",
      "Epoch 52/100\n",
      "42768/42768 [==============================] - 32s 758us/step - loss: 0.9872 - acc: 0.6387 - val_loss: 1.7581 - val_acc: 0.4358\n",
      "Epoch 53/100\n",
      "42768/42768 [==============================] - 33s 762us/step - loss: 0.9731 - acc: 0.6479 - val_loss: 1.7419 - val_acc: 0.4379\n",
      "Epoch 54/100\n",
      "42768/42768 [==============================] - 32s 756us/step - loss: 0.9679 - acc: 0.6469 - val_loss: 1.7363 - val_acc: 0.4397\n",
      "Epoch 55/100\n",
      "42768/42768 [==============================] - 32s 755us/step - loss: 0.9615 - acc: 0.6505 - val_loss: 1.7338 - val_acc: 0.4406\n",
      "Epoch 56/100\n",
      "42768/42768 [==============================] - 32s 753us/step - loss: 0.9517 - acc: 0.6560 - val_loss: 1.7362 - val_acc: 0.4427\n",
      "Epoch 57/100\n",
      "42768/42768 [==============================] - 32s 756us/step - loss: 0.9428 - acc: 0.6591 - val_loss: 1.7801 - val_acc: 0.4376\n",
      "Epoch 58/100\n",
      "42768/42768 [==============================] - 32s 754us/step - loss: 0.9382 - acc: 0.6615 - val_loss: 1.7783 - val_acc: 0.4426\n",
      "Epoch 59/100\n",
      "42768/42768 [==============================] - 32s 753us/step - loss: 0.9305 - acc: 0.6656 - val_loss: 1.7981 - val_acc: 0.4419\n",
      "Epoch 60/100\n",
      "42768/42768 [==============================] - 32s 755us/step - loss: 0.9241 - acc: 0.6659 - val_loss: 1.8278 - val_acc: 0.4425\n",
      "Epoch 61/100\n",
      "42768/42768 [==============================] - 32s 753us/step - loss: 0.9144 - acc: 0.6686 - val_loss: 1.8162 - val_acc: 0.4393\n",
      "Epoch 62/100\n",
      "42768/42768 [==============================] - 32s 753us/step - loss: 0.9015 - acc: 0.6767 - val_loss: 1.7962 - val_acc: 0.4432\n",
      "Epoch 63/100\n",
      "42768/42768 [==============================] - 32s 754us/step - loss: 0.8953 - acc: 0.6770 - val_loss: 1.8196 - val_acc: 0.4388\n",
      "Epoch 64/100\n",
      "42768/42768 [==============================] - 32s 755us/step - loss: 0.8948 - acc: 0.6779 - val_loss: 1.8400 - val_acc: 0.4416\n",
      "Epoch 65/100\n",
      "42768/42768 [==============================] - 33s 764us/step - loss: 0.8881 - acc: 0.6859 - val_loss: 1.8124 - val_acc: 0.4378\n",
      "Epoch 66/100\n",
      "42768/42768 [==============================] - 32s 753us/step - loss: 0.8762 - acc: 0.6853 - val_loss: 1.8170 - val_acc: 0.4442\n",
      "Epoch 67/100\n",
      "42768/42768 [==============================] - 32s 752us/step - loss: 0.8703 - acc: 0.6900 - val_loss: 1.8558 - val_acc: 0.4466\n",
      "Epoch 68/100\n",
      "42768/42768 [==============================] - 32s 755us/step - loss: 0.8638 - acc: 0.6872 - val_loss: 1.8627 - val_acc: 0.4441\n",
      "Epoch 69/100\n",
      "42768/42768 [==============================] - 32s 754us/step - loss: 0.8595 - acc: 0.6946 - val_loss: 1.8735 - val_acc: 0.4395\n",
      "Epoch 70/100\n",
      "42768/42768 [==============================] - 32s 753us/step - loss: 0.8512 - acc: 0.6961 - val_loss: 1.8819 - val_acc: 0.4430\n",
      "Epoch 71/100\n",
      "42768/42768 [==============================] - 32s 752us/step - loss: 0.8451 - acc: 0.6983 - val_loss: 1.8719 - val_acc: 0.4418\n",
      "Epoch 72/100\n",
      "42768/42768 [==============================] - 33s 769us/step - loss: 0.8416 - acc: 0.6983 - val_loss: 1.8967 - val_acc: 0.4416\n",
      "Epoch 73/100\n",
      "42768/42768 [==============================] - 32s 753us/step - loss: 0.8273 - acc: 0.7044 - val_loss: 1.8871 - val_acc: 0.4418\n",
      "Epoch 74/100\n",
      "42768/42768 [==============================] - 32s 751us/step - loss: 0.8301 - acc: 0.7060 - val_loss: 1.8671 - val_acc: 0.4438\n",
      "Epoch 75/100\n",
      "42768/42768 [==============================] - 32s 753us/step - loss: 0.8278 - acc: 0.7054 - val_loss: 1.8937 - val_acc: 0.4441\n",
      "Epoch 76/100\n",
      "42768/42768 [==============================] - 32s 753us/step - loss: 0.8173 - acc: 0.7111 - val_loss: 1.9048 - val_acc: 0.4480\n",
      "Epoch 77/100\n",
      "42768/42768 [==============================] - 32s 752us/step - loss: 0.8072 - acc: 0.7157 - val_loss: 1.9409 - val_acc: 0.4394\n",
      "Epoch 78/100\n",
      "42768/42768 [==============================] - 32s 753us/step - loss: 0.8039 - acc: 0.7150 - val_loss: 1.9232 - val_acc: 0.4453\n",
      "Epoch 79/100\n",
      "42768/42768 [==============================] - 32s 755us/step - loss: 0.7995 - acc: 0.7165 - val_loss: 1.9192 - val_acc: 0.4406\n",
      "Epoch 80/100\n",
      "42768/42768 [==============================] - 32s 753us/step - loss: 0.7964 - acc: 0.7184 - val_loss: 1.9511 - val_acc: 0.4361\n",
      "Epoch 81/100\n",
      "42768/42768 [==============================] - 32s 752us/step - loss: 0.7933 - acc: 0.7203 - val_loss: 1.9428 - val_acc: 0.4459\n",
      "Epoch 82/100\n",
      "42768/42768 [==============================] - 32s 753us/step - loss: 0.7881 - acc: 0.7207 - val_loss: 1.9577 - val_acc: 0.4406\n",
      "Epoch 83/100\n",
      "42768/42768 [==============================] - 32s 754us/step - loss: 0.7822 - acc: 0.7225 - val_loss: 1.9676 - val_acc: 0.4409\n",
      "Epoch 84/100\n",
      "42768/42768 [==============================] - 32s 753us/step - loss: 0.7721 - acc: 0.7270 - val_loss: 1.9585 - val_acc: 0.4397\n",
      "Epoch 85/100\n",
      "42768/42768 [==============================] - 32s 753us/step - loss: 0.7625 - acc: 0.7309 - val_loss: 1.9854 - val_acc: 0.4397\n",
      "Epoch 86/100\n",
      "42768/42768 [==============================] - 32s 753us/step - loss: 0.7665 - acc: 0.7301 - val_loss: 1.9704 - val_acc: 0.4424\n",
      "Epoch 87/100\n",
      "42768/42768 [==============================] - 32s 754us/step - loss: 0.7587 - acc: 0.7342 - val_loss: 1.9297 - val_acc: 0.4431\n",
      "Epoch 88/100\n",
      "42768/42768 [==============================] - 32s 753us/step - loss: 0.7546 - acc: 0.7350 - val_loss: 1.9790 - val_acc: 0.4428\n",
      "Epoch 89/100\n",
      "42768/42768 [==============================] - 32s 751us/step - loss: 0.7480 - acc: 0.7384 - val_loss: 1.9934 - val_acc: 0.4399\n",
      "Epoch 90/100\n",
      "42768/42768 [==============================] - 32s 753us/step - loss: 0.7479 - acc: 0.7365 - val_loss: 2.0000 - val_acc: 0.4472\n",
      "Epoch 91/100\n",
      "42768/42768 [==============================] - 32s 752us/step - loss: 0.7403 - acc: 0.7413 - val_loss: 1.9670 - val_acc: 0.4413\n",
      "Epoch 92/100\n",
      "42768/42768 [==============================] - 32s 753us/step - loss: 0.7324 - acc: 0.7437 - val_loss: 2.0213 - val_acc: 0.4395\n",
      "Epoch 93/100\n",
      "42768/42768 [==============================] - 32s 752us/step - loss: 0.7268 - acc: 0.7483 - val_loss: 2.0332 - val_acc: 0.4440\n",
      "Epoch 94/100\n",
      "42768/42768 [==============================] - 32s 754us/step - loss: 0.7279 - acc: 0.7470 - val_loss: 1.9813 - val_acc: 0.4448\n",
      "Epoch 95/100\n",
      "42768/42768 [==============================] - 32s 753us/step - loss: 0.7275 - acc: 0.7451 - val_loss: 2.0423 - val_acc: 0.4447\n",
      "Epoch 96/100\n",
      "42768/42768 [==============================] - 32s 752us/step - loss: 0.7179 - acc: 0.7498 - val_loss: 2.0421 - val_acc: 0.4429\n",
      "Epoch 97/100\n",
      "42768/42768 [==============================] - 32s 753us/step - loss: 0.7180 - acc: 0.7481 - val_loss: 2.0301 - val_acc: 0.4418\n",
      "Epoch 98/100\n",
      "42768/42768 [==============================] - 32s 753us/step - loss: 0.7121 - acc: 0.7531 - val_loss: 2.0658 - val_acc: 0.4461\n",
      "Epoch 99/100\n",
      "42768/42768 [==============================] - 32s 753us/step - loss: 0.7062 - acc: 0.7553 - val_loss: 2.0796 - val_acc: 0.4424\n",
      "Epoch 100/100\n",
      "42768/42768 [==============================] - 32s 752us/step - loss: 0.7071 - acc: 0.7512 - val_loss: 2.0429 - val_acc: 0.4408\n"
     ]
    }
   ],
   "source": [
    "model_4_hist=regressor.fit(X_train, y_train, epochs = 100, batch_size = 32, validation_data=(X_test, y_test), shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Model 5: Stateful learning on size 1 elements</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=isear[1]\n",
    "X=X.apply(clean)\n",
    "y=isear[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_train(text):\n",
    "    X=pd.Series(text).apply(clean)\n",
    "    splits=word_splits(X)\n",
    "    numbers_series=splits.apply(vec_word)\n",
    "    num_words=len(numbers_series)\n",
    "    X_1 = []\n",
    "    y_1=  []\n",
    "    for index in range(0, num_words):\n",
    "        doc=numbers_series.iloc[index]\n",
    "        for i in range(len(doc)):\n",
    "            X_1.append(doc[i])\n",
    "            y_1.append(y.iloc[index])\n",
    "    return X_1, y_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1, y_1=transform_train(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder=LabelEncoder()\n",
    "encoder.fit(y_1)\n",
    "y_1=encoder.transform(y_1)\n",
    "y_1=np_utils.to_categorical(y_1)\n",
    "y_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1=np.array(X_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1=np.reshape(X_1, (X_1.shape[0], 1, X_1.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_1, y_1, test_size = 0.2, random_state = 0)\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58205, 1, 300)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the RNN\n",
    "regressor = Sequential()\n",
    "\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 25, return_sequences = True, stateful=True,  batch_input_shape=(35, 1, 300)))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 25, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 25, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 25))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "58205/58205 [==============================] - 11s 187us/step - loss: 0.1149 - acc: 0.2824\n",
      "Epoch 2/25\n",
      "58205/58205 [==============================] - 8s 140us/step - loss: 0.1150 - acc: 0.2831\n",
      "Epoch 3/25\n",
      "58205/58205 [==============================] - 8s 141us/step - loss: 0.1152 - acc: 0.2803\n",
      "Epoch 4/25\n",
      "58205/58205 [==============================] - 8s 140us/step - loss: 0.1150 - acc: 0.2807\n",
      "Epoch 5/25\n",
      "58205/58205 [==============================] - 8s 141us/step - loss: 0.1151 - acc: 0.2816\n",
      "Epoch 6/25\n",
      "58205/58205 [==============================] - 8s 141us/step - loss: 0.1151 - acc: 0.2788\n",
      "Epoch 7/25\n",
      "58205/58205 [==============================] - 8s 142us/step - loss: 0.1153 - acc: 0.2792\n",
      "Epoch 8/25\n",
      "58205/58205 [==============================] - 8s 141us/step - loss: 0.1153 - acc: 0.2784\n",
      "Epoch 9/25\n",
      "58205/58205 [==============================] - 8s 142us/step - loss: 0.1153 - acc: 0.2774\n",
      "Epoch 10/25\n",
      "58205/58205 [==============================] - 8s 143us/step - loss: 0.1154 - acc: 0.2774\n",
      "Epoch 11/25\n",
      "58205/58205 [==============================] - 8s 141us/step - loss: 0.1154 - acc: 0.2757\n",
      "Epoch 12/25\n",
      "58205/58205 [==============================] - 8s 142us/step - loss: 0.1156 - acc: 0.2738\n",
      "Epoch 13/25\n",
      "58205/58205 [==============================] - 8s 143us/step - loss: 0.1155 - acc: 0.2745\n",
      "Epoch 14/25\n",
      "58205/58205 [==============================] - 8s 143us/step - loss: 0.1157 - acc: 0.2736\n",
      "Epoch 15/25\n",
      "58205/58205 [==============================] - 8s 142us/step - loss: 0.1157 - acc: 0.2722\n",
      "Epoch 16/25\n",
      "58205/58205 [==============================] - 8s 140us/step - loss: 0.1159 - acc: 0.2675\n",
      "Epoch 17/25\n",
      "58205/58205 [==============================] - 8s 141us/step - loss: 0.1162 - acc: 0.2638\n",
      "Epoch 18/25\n",
      "58205/58205 [==============================] - 8s 141us/step - loss: 0.1164 - acc: 0.2621\n",
      "Epoch 19/25\n",
      "58205/58205 [==============================] - 8s 142us/step - loss: 0.1166 - acc: 0.2568\n",
      "Epoch 20/25\n",
      "58205/58205 [==============================] - 8s 142us/step - loss: 0.1168 - acc: 0.2548\n",
      "Epoch 21/25\n",
      "58205/58205 [==============================] - 8s 142us/step - loss: 0.1167 - acc: 0.2520\n",
      "Epoch 22/25\n",
      "58205/58205 [==============================] - 8s 142us/step - loss: 0.1168 - acc: 0.2507\n",
      "Epoch 23/25\n",
      "58205/58205 [==============================] - 8s 142us/step - loss: 0.1168 - acc: 0.2489\n",
      "Epoch 24/25\n",
      "58205/58205 [==============================] - 8s 142us/step - loss: 0.1168 - acc: 0.2497\n",
      "Epoch 25/25\n",
      "58205/58205 [==============================] - 8s 142us/step - loss: 0.1167 - acc: 0.2517\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xdad397f0>"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = 'adam', metrics=['accuracy'], loss = 'mean_squared_error')\n",
    "#Fitting to training set\n",
    "regressor.fit(X_train, y_train, epochs = 25, batch_size = 35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Only run below once </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test= X_test[:13475], y_test[:13475]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13475/13475 [==============================] - 2s 113us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11635366178952254, 0.2500185603106564]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.evaluate(X_test, y_test, batch_size=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Notes on size 1: Not as good as size 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Model 6: timestep size 6 (double of first model)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=isear[1]\n",
    "X=X.apply(clean)\n",
    "y=isear[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_t6_train(text):\n",
    "    X=pd.Series(text).apply(clean)\n",
    "    splits=word_splits(X)\n",
    "    numbers_series=splits.apply(vec_word)\n",
    "    num_docs=len(numbers_series)\n",
    "    X_1 = []\n",
    "    y_1= []\n",
    "    for index in range(0, num_docs):\n",
    "        doc=numbers_series.iloc[index]\n",
    "        for i in range(6, len(doc)):\n",
    "            X_1.append(doc[i-6:i])\n",
    "            y_1.append(y.iloc[index])\n",
    "    return X_1, y_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_t6_input(text):\n",
    "    X=pd.Series(text).apply(clean)\n",
    "    splits=word_splits(X)\n",
    "    numbers_series=splits.apply(vec_word)\n",
    "    num_docs=len(numbers_series)\n",
    "    for index, doc in enumerate(numbers_series):\n",
    "        print(len(doc))\n",
    "        while len(doc)<7:\n",
    "            orig_doc=doc.copy()\n",
    "            orig_doc=list(orig_doc)\n",
    "            doc=list(doc)\n",
    "            for word in orig_doc:\n",
    "                doc.append(word)\n",
    "                #doc=np.insert(doc,(len(doc)),word, axis=0)\n",
    "                #doc=np.append(doc, word, axis=1)\n",
    "            modified=True\n",
    "        numbers_series.iloc[index]=np.array(doc)\n",
    "    X_1 = []\n",
    "    if num_docs>1:\n",
    "        for index in range(0, num_docs):\n",
    "            doc=numbers_series.iloc[index]\n",
    "            for i in range(6, len(doc)):\n",
    "                X_1.append(doc[i-6:i])\n",
    "    else:\n",
    "        doc=numbers_series.iloc[0]\n",
    "        print(doc.shape)\n",
    "        for i in range(6, len(doc)):\n",
    "                X_1.append(doc[i-6:i])\n",
    "    return np.array(X_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "(12, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-0.0637, -0.073 , -0.0434, ...,  0.3121,  0.0271, -0.0763],\n",
       "        [ 0.0705,  0.1689, -0.0022, ...,  0.129 , -0.0185, -0.0177],\n",
       "        [-0.0247,  0.0319, -0.0316, ...,  0.0492,  0.0701, -0.1973],\n",
       "        [-0.0485,  0.0401, -0.1415, ...,  0.2272,  0.0257,  0.0628],\n",
       "        [-0.2057,  0.092 , -0.0411, ...,  0.1585, -0.0718, -0.0868],\n",
       "        [-0.1207,  0.0057, -0.0253, ...,  0.1913, -0.0189, -0.0659]],\n",
       "\n",
       "       [[ 0.0705,  0.1689, -0.0022, ...,  0.129 , -0.0185, -0.0177],\n",
       "        [-0.0247,  0.0319, -0.0316, ...,  0.0492,  0.0701, -0.1973],\n",
       "        [-0.0485,  0.0401, -0.1415, ...,  0.2272,  0.0257,  0.0628],\n",
       "        [-0.2057,  0.092 , -0.0411, ...,  0.1585, -0.0718, -0.0868],\n",
       "        [-0.1207,  0.0057, -0.0253, ...,  0.1913, -0.0189, -0.0659],\n",
       "        [-0.0637, -0.073 , -0.0434, ...,  0.3121,  0.0271, -0.0763]],\n",
       "\n",
       "       [[-0.0247,  0.0319, -0.0316, ...,  0.0492,  0.0701, -0.1973],\n",
       "        [-0.0485,  0.0401, -0.1415, ...,  0.2272,  0.0257,  0.0628],\n",
       "        [-0.2057,  0.092 , -0.0411, ...,  0.1585, -0.0718, -0.0868],\n",
       "        [-0.1207,  0.0057, -0.0253, ...,  0.1913, -0.0189, -0.0659],\n",
       "        [-0.0637, -0.073 , -0.0434, ...,  0.3121,  0.0271, -0.0763],\n",
       "        [ 0.0705,  0.1689, -0.0022, ...,  0.129 , -0.0185, -0.0177]],\n",
       "\n",
       "       [[-0.0485,  0.0401, -0.1415, ...,  0.2272,  0.0257,  0.0628],\n",
       "        [-0.2057,  0.092 , -0.0411, ...,  0.1585, -0.0718, -0.0868],\n",
       "        [-0.1207,  0.0057, -0.0253, ...,  0.1913, -0.0189, -0.0659],\n",
       "        [-0.0637, -0.073 , -0.0434, ...,  0.3121,  0.0271, -0.0763],\n",
       "        [ 0.0705,  0.1689, -0.0022, ...,  0.129 , -0.0185, -0.0177],\n",
       "        [-0.0247,  0.0319, -0.0316, ...,  0.0492,  0.0701, -0.1973]],\n",
       "\n",
       "       [[-0.2057,  0.092 , -0.0411, ...,  0.1585, -0.0718, -0.0868],\n",
       "        [-0.1207,  0.0057, -0.0253, ...,  0.1913, -0.0189, -0.0659],\n",
       "        [-0.0637, -0.073 , -0.0434, ...,  0.3121,  0.0271, -0.0763],\n",
       "        [ 0.0705,  0.1689, -0.0022, ...,  0.129 , -0.0185, -0.0177],\n",
       "        [-0.0247,  0.0319, -0.0316, ...,  0.0492,  0.0701, -0.1973],\n",
       "        [-0.0485,  0.0401, -0.1415, ...,  0.2272,  0.0257,  0.0628]],\n",
       "\n",
       "       [[-0.1207,  0.0057, -0.0253, ...,  0.1913, -0.0189, -0.0659],\n",
       "        [-0.0637, -0.073 , -0.0434, ...,  0.3121,  0.0271, -0.0763],\n",
       "        [ 0.0705,  0.1689, -0.0022, ...,  0.129 , -0.0185, -0.0177],\n",
       "        [-0.0247,  0.0319, -0.0316, ...,  0.0492,  0.0701, -0.1973],\n",
       "        [-0.0485,  0.0401, -0.1415, ...,  0.2272,  0.0257,  0.0628],\n",
       "        [-0.2057,  0.092 , -0.0411, ...,  0.1585, -0.0718, -0.0868]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pie=transform_t6_input('I like to eat pie a lot it is yummy and very delicious')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1, y_1=transform_t6_train(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32468, 6, 300)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1=np.array(X_1)\n",
    "X_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder=LabelEncoder()\n",
    "encoder.fit(y_1)\n",
    "y_1=encoder.transform(y_1)\n",
    "y_1=np_utils.to_categorical(y_1)\n",
    "y_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_1, y_1, test_size = 0.2, random_state = 0)\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicholas\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  \"\"\"\n",
      "C:\\Users\\Nicholas\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(units=25, return_sequences=True, input_shape=(None, 300...)`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Initialising the RNN\n",
    "regressor = Sequential()\n",
    "\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 25, return_sequences = True, input_dim=300))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 25, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 25, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 25))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "25974/25974 [==============================] - 17s 637us/step - loss: 0.0240 - acc: 0.9157\n",
      "Epoch 2/25\n",
      "25974/25974 [==============================] - 12s 470us/step - loss: 0.0236 - acc: 0.9177\n",
      "Epoch 3/25\n",
      "25974/25974 [==============================] - 12s 462us/step - loss: 0.0239 - acc: 0.9175\n",
      "Epoch 4/25\n",
      "25974/25974 [==============================] - 12s 470us/step - loss: 0.0238 - acc: 0.9171\n",
      "Epoch 5/25\n",
      "25974/25974 [==============================] - 12s 468us/step - loss: 0.0233 - acc: 0.9191\n",
      "Epoch 6/25\n",
      "25974/25974 [==============================] - 12s 467us/step - loss: 0.0237 - acc: 0.9173\n",
      "Epoch 7/25\n",
      "25974/25974 [==============================] - 12s 472us/step - loss: 0.0232 - acc: 0.9202\n",
      "Epoch 8/25\n",
      "25974/25974 [==============================] - 12s 468us/step - loss: 0.0232 - acc: 0.9205\n",
      "Epoch 9/25\n",
      "25974/25974 [==============================] - 12s 473us/step - loss: 0.0232 - acc: 0.9193\n",
      "Epoch 10/25\n",
      "25974/25974 [==============================] - 12s 469us/step - loss: 0.0231 - acc: 0.9212\n",
      "Epoch 11/25\n",
      "25974/25974 [==============================] - 12s 473us/step - loss: 0.0235 - acc: 0.9196\n",
      "Epoch 12/25\n",
      "25974/25974 [==============================] - 12s 473us/step - loss: 0.0227 - acc: 0.9234\n",
      "Epoch 13/25\n",
      "25974/25974 [==============================] - 12s 471us/step - loss: 0.0230 - acc: 0.9216\n",
      "Epoch 14/25\n",
      "25974/25974 [==============================] - 12s 469us/step - loss: 0.0233 - acc: 0.9204\n",
      "Epoch 15/25\n",
      "25974/25974 [==============================] - 12s 469us/step - loss: 0.0230 - acc: 0.9221\n",
      "Epoch 16/25\n",
      "25974/25974 [==============================] - 12s 473us/step - loss: 0.0229 - acc: 0.9223\n",
      "Epoch 17/25\n",
      "25974/25974 [==============================] - 13s 491us/step - loss: 0.0230 - acc: 0.9215\n",
      "Epoch 18/25\n",
      "25974/25974 [==============================] - 12s 471us/step - loss: 0.0223 - acc: 0.9243\n",
      "Epoch 19/25\n",
      "25974/25974 [==============================] - 12s 474us/step - loss: 0.0224 - acc: 0.9244\n",
      "Epoch 20/25\n",
      "25974/25974 [==============================] - 12s 478us/step - loss: 0.0224 - acc: 0.9245\n",
      "Epoch 21/25\n",
      "25974/25974 [==============================] - 12s 475us/step - loss: 0.0227 - acc: 0.9233\n",
      "Epoch 22/25\n",
      "25974/25974 [==============================] - 12s 472us/step - loss: 0.0219 - acc: 0.9258\n",
      "Epoch 23/25\n",
      "25974/25974 [==============================] - 12s 475us/step - loss: 0.0227 - acc: 0.9237\n",
      "Epoch 24/25\n",
      "25974/25974 [==============================] - 12s 475us/step - loss: 0.0219 - acc: 0.9268\n",
      "Epoch 25/25\n",
      "25974/25974 [==============================] - 12s 471us/step - loss: 0.0219 - acc: 0.9275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xdac10b70>"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = 'adam', metrics=['accuracy'], loss = 'mean_squared_error')\n",
    "#Fitting to training set\n",
    "regressor.fit(X_train, y_train, epochs = 25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't pickle _thread.RLock objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-589-10d6e0578ea9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# save pkl file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregressor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'LSTM.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: can't pickle _thread.RLock objects"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# save pkl file\n",
    "pickle.dump(regressor, open('LSTM.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6494/6494 [==============================] - 2s 297us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05276456107346735, 0.7685555896466792]"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(text):\n",
    "    vec_text=transform_t6_input(text)\n",
    "    pred=regressor.predict(vec_text)\n",
    "    pred=np.mean(pred, axis=0)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_duplicator(text):\n",
    "    X=pd.Series(text).apply(clean)\n",
    "    splits=word_splits(X)\n",
    "    numbers_series=splits\n",
    "    num_docs=len(numbers_series)\n",
    "    for index, doc in enumerate(numbers_series):\n",
    "        print(len(doc))\n",
    "        while len(doc)<7:\n",
    "            orig_doc=doc.copy()\n",
    "            orig_doc=list(orig_doc)\n",
    "            doc=list(doc)\n",
    "            for word in orig_doc:\n",
    "                doc.append(word)\n",
    "                #doc=np.insert(doc,(len(doc)),word, axis=0)\n",
    "                #doc=np.append(doc, word, axis=1)\n",
    "            modified=True\n",
    "        numbers_series.iloc[index]=np.array(doc)\n",
    "    X_1 = []\n",
    "    if num_docs>1:\n",
    "        for index in range(0, num_docs):\n",
    "            doc=numbers_series.iloc[index]\n",
    "            for i in range(6, len(doc)):\n",
    "                X_1.append(doc[i-6:i])\n",
    "    else:\n",
    "        doc=numbers_series.iloc[0]\n",
    "        print(doc.shape)\n",
    "        for i in range(6, len(doc)):\n",
    "                X_1.append(doc[i-6:i])\n",
    "    return X_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(8,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array(['love', 'everybody', 'love', 'everybody', 'love', 'everybody'],\n",
       "       dtype='<U9'),\n",
       " array(['everybody', 'love', 'everybody', 'love', 'everybody', 'love'],\n",
       "       dtype='<U9')]"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_duplicator('I love everybody')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(8, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 6.0217679e-03,  6.1481744e-03,  1.6123056e-03, -7.1944296e-04,\n",
       "         2.5430262e-02,  9.4908869e-01,  7.6540709e-03],\n",
       "       [ 6.0217679e-03,  6.1481744e-03,  1.6123056e-03, -7.1944296e-04,\n",
       "         2.5430262e-02,  9.4908869e-01,  7.6540709e-03]], dtype=float32)"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction('love')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Importing amazon reviews sample</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews=pd.read_csv(\"amazon_reviews_utf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I bought this umbrella a few months ago and unfortunately, it broke while it was windy out'"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['Review Text'].iloc[1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Star Rating</th>\n",
       "      <th>Verifed Review</th>\n",
       "      <th>Helpful Vote Count</th>\n",
       "      <th>Date</th>\n",
       "      <th>Author</th>\n",
       "      <th>Author Link</th>\n",
       "      <th>Review Link</th>\n",
       "      <th>Review Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So far, so good (and dry)</td>\n",
       "      <td>5</td>\n",
       "      <td>YES</td>\n",
       "      <td>25</td>\n",
       "      <td>November 9, 2016</td>\n",
       "      <td>S. R. Southard</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R3V8GI...</td>\n",
       "      <td>I had my first opportunity to use the umbrella...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not really a lifetime warranty...</td>\n",
       "      <td>2</td>\n",
       "      <td>YES</td>\n",
       "      <td>On</td>\n",
       "      <td>July 10, 2018</td>\n",
       "      <td>Rico</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R1ZA3B...</td>\n",
       "      <td>I bought this umbrella a few months ago and un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"THIS IS THE ONLY UMBRELLA YOU SHOULD EVER PUR...</td>\n",
       "      <td>5</td>\n",
       "      <td>YES</td>\n",
       "      <td>On</td>\n",
       "      <td>January 22, 2018</td>\n",
       "      <td>On The Fly</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/RG5V0S...</td>\n",
       "      <td>First of all: I have no financial interest in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Most good quality umbrellas can't stand up to ...</td>\n",
       "      <td>3</td>\n",
       "      <td>YES</td>\n",
       "      <td>2</td>\n",
       "      <td>April 25, 2018</td>\n",
       "      <td>Linann</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R2EYVB...</td>\n",
       "      <td>I work in New Haven CT, and in the fall, and w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decent umbrella compromised by poor-quality ri...</td>\n",
       "      <td>3</td>\n",
       "      <td>YES</td>\n",
       "      <td>3</td>\n",
       "      <td>October 15, 2017</td>\n",
       "      <td>Edward Ripley-Duggan</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R1L9TU...</td>\n",
       "      <td>The umbrella appears to be robust; I used it r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>it is still like new. Great construction</td>\n",
       "      <td>4</td>\n",
       "      <td>YES</td>\n",
       "      <td>On</td>\n",
       "      <td>August 14, 2016</td>\n",
       "      <td>MC Oddslice</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R2W29X...</td>\n",
       "      <td>Update: Too small! If there is wind, you will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>For a tiny person</td>\n",
       "      <td>2</td>\n",
       "      <td>YES</td>\n",
       "      <td>On</td>\n",
       "      <td>May 25, 2018</td>\n",
       "      <td>AR</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R3FPDT...</td>\n",
       "      <td>I was excited to try out this umbrella based o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decent, a bit pricey?</td>\n",
       "      <td>4</td>\n",
       "      <td>YES</td>\n",
       "      <td>2</td>\n",
       "      <td>September 2, 2017</td>\n",
       "      <td>Alex Wang</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R12Q4A...</td>\n",
       "      <td>This umbrella is pretty good. never had a umbr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Not consistent with reviews or description.</td>\n",
       "      <td>2</td>\n",
       "      <td>YES</td>\n",
       "      <td>3</td>\n",
       "      <td>June 20, 2017</td>\n",
       "      <td>Hannah</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R1UX1K...</td>\n",
       "      <td>I must have received a bad item or something b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Seems well-built and well-designed.</td>\n",
       "      <td>5</td>\n",
       "      <td>YES</td>\n",
       "      <td>0</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>Terende</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R3C9IS...</td>\n",
       "      <td>I bought two of these for my and my spouse's u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Good Quality but Nearly Useless - Umbrella for...</td>\n",
       "      <td>2</td>\n",
       "      <td>YES</td>\n",
       "      <td>0</td>\n",
       "      <td>July 3, 2018</td>\n",
       "      <td>Robert S. Blackie</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R9Y91F...</td>\n",
       "      <td>I cannot argue with the fact that this umbrell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>... have to say this one is by far my favorite...</td>\n",
       "      <td>5</td>\n",
       "      <td>YES</td>\n",
       "      <td>0</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>IJ</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R3TDZY...</td>\n",
       "      <td>I've owned at least 50 umbrellas (some bought ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>classy cute umbrella</td>\n",
       "      <td>5</td>\n",
       "      <td>YES</td>\n",
       "      <td>0</td>\n",
       "      <td>March 25, 2018</td>\n",
       "      <td>lawAbidingCitizen</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R2PYPT...</td>\n",
       "      <td>I have benkii before(less1 year) but i lost it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Well made product, excellent vendor</td>\n",
       "      <td>5</td>\n",
       "      <td>YES</td>\n",
       "      <td>0</td>\n",
       "      <td>April 7, 2018</td>\n",
       "      <td>sherm624</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R2VU5A...</td>\n",
       "      <td>Change from 2 to 5 stars.  After a not-so-grea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>This one goes to 9...</td>\n",
       "      <td>5</td>\n",
       "      <td>YES</td>\n",
       "      <td>On</td>\n",
       "      <td>January 29, 2017</td>\n",
       "      <td>Mergatroid</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R1C6RZ...</td>\n",
       "      <td>Nicely built. The metal shaft is black however...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>support</td>\n",
       "      <td>4</td>\n",
       "      <td>YES</td>\n",
       "      <td>On</td>\n",
       "      <td>January 23, 2018</td>\n",
       "      <td>Robert J. Moser</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R2IXZT...</td>\n",
       "      <td>I am a 67 year old banker, been banking for ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Excellent umbrella- would definitely recommend</td>\n",
       "      <td>5</td>\n",
       "      <td>YES</td>\n",
       "      <td>0</td>\n",
       "      <td>October 18, 2017</td>\n",
       "      <td>G Tan</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R38B28...</td>\n",
       "      <td>I like bullet points, thus: + Excellent build ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Umbrella has lots of good features</td>\n",
       "      <td>4</td>\n",
       "      <td>YES</td>\n",
       "      <td>On</td>\n",
       "      <td>December 2, 2017</td>\n",
       "      <td>Lori C.</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R2MWM3...</td>\n",
       "      <td>3rd party seller very involved, customer servi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NOT \"super light\" or lightweight. Misleading p...</td>\n",
       "      <td>2</td>\n",
       "      <td>YES</td>\n",
       "      <td>On</td>\n",
       "      <td>July 20, 2017</td>\n",
       "      <td>JulieT</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R32MI0...</td>\n",
       "      <td>I was looking for a lightweight umbrella to re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Nope nope nope</td>\n",
       "      <td>1</td>\n",
       "      <td>YES</td>\n",
       "      <td>On</td>\n",
       "      <td>June 15, 2018</td>\n",
       "      <td>BillyP</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R3DZFN...</td>\n",
       "      <td>I moved to San Francisco and needed an umbrell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Not what I had hoped....</td>\n",
       "      <td>2</td>\n",
       "      <td>YES</td>\n",
       "      <td>0</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>Krysrox413</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R1TAZB...</td>\n",
       "      <td>For all the money I paid for this umbrella, I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Nice while it lasted</td>\n",
       "      <td>3</td>\n",
       "      <td>YES</td>\n",
       "      <td>2</td>\n",
       "      <td>January 9, 2017</td>\n",
       "      <td>Ben Perkins</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/RFQF9R...</td>\n",
       "      <td>It's ok, the build quality seemed nice at firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Stands up to tough weather</td>\n",
       "      <td>5</td>\n",
       "      <td>YES</td>\n",
       "      <td>On</td>\n",
       "      <td>August 10, 2017</td>\n",
       "      <td>Alexandria</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/RS0OF5...</td>\n",
       "      <td>I live in Chicago suburbia so I have very litt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Great size.</td>\n",
       "      <td>4</td>\n",
       "      <td>YES</td>\n",
       "      <td>0</td>\n",
       "      <td>June 10, 2018</td>\n",
       "      <td>Seaside Sarah</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/ROM02O...</td>\n",
       "      <td>For a compact umbrella, it's a \"big\" umbrella ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Can withstand powerful wind</td>\n",
       "      <td>5</td>\n",
       "      <td>YES</td>\n",
       "      <td>0</td>\n",
       "      <td>May 6, 2018</td>\n",
       "      <td>Zavage</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R3DKA9...</td>\n",
       "      <td>Being a bachelor, I never really felt the need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Great product and customer service</td>\n",
       "      <td>5</td>\n",
       "      <td>YES</td>\n",
       "      <td>0</td>\n",
       "      <td>January 3, 2017</td>\n",
       "      <td>M.G.M.</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R2N49P...</td>\n",
       "      <td>The umbrella feels sturdy. Haven't experienced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Has potential - top piece unreliable</td>\n",
       "      <td>4</td>\n",
       "      <td>YES</td>\n",
       "      <td>On</td>\n",
       "      <td>June 19, 2017</td>\n",
       "      <td>Kevin Lee</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R111SP...</td>\n",
       "      <td>**Update: I'm updating my review from 2 to 4 s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>well-made umbrella</td>\n",
       "      <td>5</td>\n",
       "      <td>YES</td>\n",
       "      <td>0</td>\n",
       "      <td>February 5, 2018</td>\n",
       "      <td>Mitch</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R2TZXS...</td>\n",
       "      <td>I ordered this during a rainstorm and since it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Good value!</td>\n",
       "      <td>5</td>\n",
       "      <td>YES</td>\n",
       "      <td>0</td>\n",
       "      <td>January 25, 2017</td>\n",
       "      <td>Clifford Carroll</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/RY5UFB...</td>\n",
       "      <td>This umbrella is of better apparent quality th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sturdy and Well-Constructed</td>\n",
       "      <td>4</td>\n",
       "      <td>YES</td>\n",
       "      <td>On</td>\n",
       "      <td>August 17, 2017</td>\n",
       "      <td>Justin Paul</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R3VOD7...</td>\n",
       "      <td>Feels sturdy and a well constructed umbrella. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2370</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>5</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>December 15, 2017</td>\n",
       "      <td>jensb</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R1WOIR...</td>\n",
       "      <td>Great product and fast shipping, thank you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2371</th>\n",
       "      <td>I recommend it.</td>\n",
       "      <td>5</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>June 18, 2016</td>\n",
       "      <td>Keith McCormick</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R32LUL...</td>\n",
       "      <td>It's an expensive umbrella but i assure you th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>5</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>August 19, 2017</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R2QU4V...</td>\n",
       "      <td>Great quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2373</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>5</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>June 18, 2017</td>\n",
       "      <td>Jenny Larkin</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R39NX4...</td>\n",
       "      <td>Great product!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2374</th>\n",
       "      <td>One Star</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>November 26, 2017</td>\n",
       "      <td>Jennifer Franzone</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R2QKJ0...</td>\n",
       "      <td>It was very heavy! Not what I expected.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>5</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>August 30, 2017</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R1ZJUE...</td>\n",
       "      <td>Super product.... excellent value..buy 2!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2376</th>\n",
       "      <td>This is a very good umbrella and functions wel...</td>\n",
       "      <td>4</td>\n",
       "      <td>YES</td>\n",
       "      <td>On</td>\n",
       "      <td>August 29, 2017</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R36FW6...</td>\n",
       "      <td>This is a very good umbrella and functions wel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2377</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>5</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>July 19, 2017</td>\n",
       "      <td>MattSanders</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R204XQ...</td>\n",
       "      <td>Amazing, easy to use umbrella!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>5</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>April 16, 2017</td>\n",
       "      <td>Nicholas Rodriguez</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/RVUQ68...</td>\n",
       "      <td>Sturdy and built to last. These umbrellas are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>5</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>February 22, 2017</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/RQ2D6B...</td>\n",
       "      <td>Feels very sturdy and is a decent size - bigge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2380</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>5</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>May 5, 2017</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R2TGWQ...</td>\n",
       "      <td>Nice quality umbrella. Arrived earlier than ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>Great product from a company that stands behin...</td>\n",
       "      <td>5</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>July 9, 2016</td>\n",
       "      <td>CH</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R31W5S...</td>\n",
       "      <td>Holds up well in the wind. Great product from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>5 stars</td>\n",
       "      <td>5</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>September 30, 2016</td>\n",
       "      <td>berta</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R1UFPQ...</td>\n",
       "      <td>5 stars for this umbrella. Well made with high...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>5</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>March 18, 2017</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/RGAJTW...</td>\n",
       "      <td>So love this umbrella. Very easy to use. I wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2384</th>\n",
       "      <td>honest review</td>\n",
       "      <td>4</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>July 11, 2016</td>\n",
       "      <td>Richard villa olea</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R3EQ9X...</td>\n",
       "      <td>cool product.i recieved for a reduced discount.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2385</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>5</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>August 21, 2017</td>\n",
       "      <td>Zhitun Yang</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R51QEV...</td>\n",
       "      <td>Five Star.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2386</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>5</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>June 9, 2016</td>\n",
       "      <td>Heather</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/RJ8AM2...</td>\n",
       "      <td>Fits in my bag and keeps my hair and clothes d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>5</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>May 3, 2017</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R3SUPI...</td>\n",
       "      <td>A wonderful umbrella at an excellent price!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>5</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>February 19, 2017</td>\n",
       "      <td>D A Sleeter</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R1O2BJ...</td>\n",
       "      <td>solid construction.  haven't had rain yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2389</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>5</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>October 31, 2016</td>\n",
       "      <td>ZIX</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/RQO1A8...</td>\n",
       "      <td>It is a well designed product and worth your m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>5</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>June 11, 2017</td>\n",
       "      <td>hudsonview</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R2V8WY...</td>\n",
       "      <td>Great umbrella!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>5</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>August 25, 2016</td>\n",
       "      <td>kim formby</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R3K1FY...</td>\n",
       "      <td>I received this Umbrella free and LOVE it. It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2392</th>\n",
       "      <td>awesome</td>\n",
       "      <td>5</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>July 16, 2016</td>\n",
       "      <td>caro</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R1UUCR...</td>\n",
       "      <td>The Dupont Teflon feels sturdy and keeps the r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393</th>\n",
       "      <td>Four Stars</td>\n",
       "      <td>4</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>April 5, 2016</td>\n",
       "      <td>Patricia</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R395TG...</td>\n",
       "      <td>love a good walk in the rain, its so relaxing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>very pleased.</td>\n",
       "      <td>5</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>December 11, 2016</td>\n",
       "      <td>KB</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R169R9...</td>\n",
       "      <td>These umbrellas are everything they say they a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>As Advertised</td>\n",
       "      <td>5</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>June 23, 2017</td>\n",
       "      <td>Corrie Kristina Luebke</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/RFGLZK...</td>\n",
       "      <td>Works well so far</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>5</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>April 8, 2017</td>\n",
       "      <td>Rene</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/RDCU3C...</td>\n",
       "      <td>Great umbrella!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>GREAT!</td>\n",
       "      <td>5</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>February 11, 2017</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R3PODB...</td>\n",
       "      <td>Great product! Would recommend to anyone!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>5</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>May 18, 2017</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R10KGM...</td>\n",
       "      <td>Easy and well made</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>Four Stars</td>\n",
       "      <td>4</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>February 4, 2017</td>\n",
       "      <td>Ethan</td>\n",
       "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
       "      <td>https://amazon.com//gp/customer-reviews/R11KOI...</td>\n",
       "      <td>The umbrella is easy to open and close.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2400 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Name  Star Rating  \\\n",
       "0                             So far, so good (and dry)            5   \n",
       "1                     Not really a lifetime warranty...            2   \n",
       "2     \"THIS IS THE ONLY UMBRELLA YOU SHOULD EVER PUR...            5   \n",
       "3     Most good quality umbrellas can't stand up to ...            3   \n",
       "4     Decent umbrella compromised by poor-quality ri...            3   \n",
       "5              it is still like new. Great construction            4   \n",
       "6                                     For a tiny person            2   \n",
       "7                                 Decent, a bit pricey?            4   \n",
       "8           Not consistent with reviews or description.            2   \n",
       "9                   Seems well-built and well-designed.            5   \n",
       "10    Good Quality but Nearly Useless - Umbrella for...            2   \n",
       "11    ... have to say this one is by far my favorite...            5   \n",
       "12                                 classy cute umbrella            5   \n",
       "13                  Well made product, excellent vendor            5   \n",
       "14                                This one goes to 9...            5   \n",
       "15                                              support            4   \n",
       "16       Excellent umbrella- would definitely recommend            5   \n",
       "17                   Umbrella has lots of good features            4   \n",
       "18    NOT \"super light\" or lightweight. Misleading p...            2   \n",
       "19                                       Nope nope nope            1   \n",
       "20                             Not what I had hoped....            2   \n",
       "21                                 Nice while it lasted            3   \n",
       "22                           Stands up to tough weather            5   \n",
       "23                                          Great size.            4   \n",
       "24                          Can withstand powerful wind            5   \n",
       "25                   Great product and customer service            5   \n",
       "26                 Has potential - top piece unreliable            4   \n",
       "27                                   well-made umbrella            5   \n",
       "28                                          Good value!            5   \n",
       "29                          Sturdy and Well-Constructed            4   \n",
       "...                                                 ...          ...   \n",
       "2370                                         Five Stars            5   \n",
       "2371                                    I recommend it.            5   \n",
       "2372                                         Five Stars            5   \n",
       "2373                                         Five Stars            5   \n",
       "2374                                           One Star            1   \n",
       "2375                                         Five Stars            5   \n",
       "2376  This is a very good umbrella and functions wel...            4   \n",
       "2377                                         Five Stars            5   \n",
       "2378                                         Five Stars            5   \n",
       "2379                                         Five Stars            5   \n",
       "2380                                         Five Stars            5   \n",
       "2381  Great product from a company that stands behin...            5   \n",
       "2382                                            5 stars            5   \n",
       "2383                                         Five Stars            5   \n",
       "2384                                      honest review            4   \n",
       "2385                                         Five Stars            5   \n",
       "2386                                         Five Stars            5   \n",
       "2387                                         Five Stars            5   \n",
       "2388                                         Five Stars            5   \n",
       "2389                                         Five Stars            5   \n",
       "2390                                         Five Stars            5   \n",
       "2391                                         Five Stars            5   \n",
       "2392                                            awesome            5   \n",
       "2393                                         Four Stars            4   \n",
       "2394                                      very pleased.            5   \n",
       "2395                                      As Advertised            5   \n",
       "2396                                         Five Stars            5   \n",
       "2397                                             GREAT!            5   \n",
       "2398                                         Five Stars            5   \n",
       "2399                                         Four Stars            4   \n",
       "\n",
       "     Verifed Review Helpful Vote Count                 Date  \\\n",
       "0               YES                 25     November 9, 2016   \n",
       "1               YES                 On        July 10, 2018   \n",
       "2               YES                 On     January 22, 2018   \n",
       "3               YES                  2       April 25, 2018   \n",
       "4               YES                  3     October 15, 2017   \n",
       "5               YES                 On      August 14, 2016   \n",
       "6               YES                 On         May 25, 2018   \n",
       "7               YES                  2    September 2, 2017   \n",
       "8               YES                  3        June 20, 2017   \n",
       "9               YES                  0     January 26, 2018   \n",
       "10              YES                  0         July 3, 2018   \n",
       "11              YES                  0    February 27, 2018   \n",
       "12              YES                  0       March 25, 2018   \n",
       "13              YES                  0        April 7, 2018   \n",
       "14              YES                 On     January 29, 2017   \n",
       "15              YES                 On     January 23, 2018   \n",
       "16              YES                  0     October 18, 2017   \n",
       "17              YES                 On     December 2, 2017   \n",
       "18              YES                 On        July 20, 2017   \n",
       "19              YES                 On        June 15, 2018   \n",
       "20              YES                  0          May 2, 2018   \n",
       "21              YES                  2      January 9, 2017   \n",
       "22              YES                 On      August 10, 2017   \n",
       "23              YES                  0        June 10, 2018   \n",
       "24              YES                  0          May 6, 2018   \n",
       "25              YES                  0      January 3, 2017   \n",
       "26              YES                 On        June 19, 2017   \n",
       "27              YES                  0     February 5, 2018   \n",
       "28              YES                  0     January 25, 2017   \n",
       "29              YES                 On      August 17, 2017   \n",
       "...             ...                ...                  ...   \n",
       "2370             NO                  0    December 15, 2017   \n",
       "2371             NO                  0        June 18, 2016   \n",
       "2372             NO                  0      August 19, 2017   \n",
       "2373             NO                  0        June 18, 2017   \n",
       "2374             NO                  0    November 26, 2017   \n",
       "2375             NO                  0      August 30, 2017   \n",
       "2376            YES                 On      August 29, 2017   \n",
       "2377             NO                  0        July 19, 2017   \n",
       "2378             NO                  0       April 16, 2017   \n",
       "2379             NO                  0    February 22, 2017   \n",
       "2380             NO                  0          May 5, 2017   \n",
       "2381             NO                  0         July 9, 2016   \n",
       "2382             NO                  0   September 30, 2016   \n",
       "2383             NO                  0       March 18, 2017   \n",
       "2384             NO                  0        July 11, 2016   \n",
       "2385             NO                  0      August 21, 2017   \n",
       "2386             NO                  0         June 9, 2016   \n",
       "2387             NO                  0          May 3, 2017   \n",
       "2388             NO                  0    February 19, 2017   \n",
       "2389             NO                  0     October 31, 2016   \n",
       "2390             NO                  0        June 11, 2017   \n",
       "2391             NO                  0      August 25, 2016   \n",
       "2392             NO                  0        July 16, 2016   \n",
       "2393             NO                  0        April 5, 2016   \n",
       "2394             NO                  0    December 11, 2016   \n",
       "2395             NO                  0        June 23, 2017   \n",
       "2396             NO                  0        April 8, 2017   \n",
       "2397             NO                  0    February 11, 2017   \n",
       "2398             NO                  0         May 18, 2017   \n",
       "2399             NO                  0     February 4, 2017   \n",
       "\n",
       "                      Author  \\\n",
       "0             S. R. Southard   \n",
       "1                       Rico   \n",
       "2                 On The Fly   \n",
       "3                     Linann   \n",
       "4       Edward Ripley-Duggan   \n",
       "5                MC Oddslice   \n",
       "6                         AR   \n",
       "7                  Alex Wang   \n",
       "8                     Hannah   \n",
       "9                    Terende   \n",
       "10         Robert S. Blackie   \n",
       "11                        IJ   \n",
       "12         lawAbidingCitizen   \n",
       "13                  sherm624   \n",
       "14                Mergatroid   \n",
       "15           Robert J. Moser   \n",
       "16                     G Tan   \n",
       "17                   Lori C.   \n",
       "18                    JulieT   \n",
       "19                    BillyP   \n",
       "20                Krysrox413   \n",
       "21               Ben Perkins   \n",
       "22                Alexandria   \n",
       "23             Seaside Sarah   \n",
       "24                    Zavage   \n",
       "25                    M.G.M.   \n",
       "26                 Kevin Lee   \n",
       "27                     Mitch   \n",
       "28          Clifford Carroll   \n",
       "29               Justin Paul   \n",
       "...                      ...   \n",
       "2370                   jensb   \n",
       "2371         Keith McCormick   \n",
       "2372         Amazon Customer   \n",
       "2373            Jenny Larkin   \n",
       "2374       Jennifer Franzone   \n",
       "2375         Amazon Customer   \n",
       "2376         Amazon Customer   \n",
       "2377             MattSanders   \n",
       "2378      Nicholas Rodriguez   \n",
       "2379         Amazon Customer   \n",
       "2380         Amazon Customer   \n",
       "2381                      CH   \n",
       "2382                   berta   \n",
       "2383         Amazon Customer   \n",
       "2384      Richard villa olea   \n",
       "2385             Zhitun Yang   \n",
       "2386                 Heather   \n",
       "2387         Amazon Customer   \n",
       "2388             D A Sleeter   \n",
       "2389                     ZIX   \n",
       "2390              hudsonview   \n",
       "2391              kim formby   \n",
       "2392                    caro   \n",
       "2393                Patricia   \n",
       "2394                      KB   \n",
       "2395  Corrie Kristina Luebke   \n",
       "2396                    Rene   \n",
       "2397         Amazon Customer   \n",
       "2398         Amazon Customer   \n",
       "2399                   Ethan   \n",
       "\n",
       "                                            Author Link  \\\n",
       "0     https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "1     https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "2     https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "3     https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "4     https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "5     https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "6     https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "7     https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "8     https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "9     https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "10    https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "11    https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "12    https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "13    https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "14    https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "15    https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "16    https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "17    https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "18    https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "19    https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "20    https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "21    https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "22    https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "23    https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "24    https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "25    https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "26    https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "27    https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "28    https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "29    https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "...                                                 ...   \n",
       "2370  https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "2371  https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "2372  https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "2373  https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "2374  https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "2375  https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "2376  https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "2377  https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "2378  https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "2379  https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "2380  https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "2381  https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "2382  https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "2383  https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "2384  https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "2385  https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "2386  https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "2387  https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "2388  https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "2389  https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "2390  https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "2391  https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "2392  https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "2393  https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "2394  https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "2395  https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "2396  https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "2397  https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "2398  https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "2399  https://amazon.com//gp/profile/amzn1.account.A...   \n",
       "\n",
       "                                            Review Link  \\\n",
       "0     https://amazon.com//gp/customer-reviews/R3V8GI...   \n",
       "1     https://amazon.com//gp/customer-reviews/R1ZA3B...   \n",
       "2     https://amazon.com//gp/customer-reviews/RG5V0S...   \n",
       "3     https://amazon.com//gp/customer-reviews/R2EYVB...   \n",
       "4     https://amazon.com//gp/customer-reviews/R1L9TU...   \n",
       "5     https://amazon.com//gp/customer-reviews/R2W29X...   \n",
       "6     https://amazon.com//gp/customer-reviews/R3FPDT...   \n",
       "7     https://amazon.com//gp/customer-reviews/R12Q4A...   \n",
       "8     https://amazon.com//gp/customer-reviews/R1UX1K...   \n",
       "9     https://amazon.com//gp/customer-reviews/R3C9IS...   \n",
       "10    https://amazon.com//gp/customer-reviews/R9Y91F...   \n",
       "11    https://amazon.com//gp/customer-reviews/R3TDZY...   \n",
       "12    https://amazon.com//gp/customer-reviews/R2PYPT...   \n",
       "13    https://amazon.com//gp/customer-reviews/R2VU5A...   \n",
       "14    https://amazon.com//gp/customer-reviews/R1C6RZ...   \n",
       "15    https://amazon.com//gp/customer-reviews/R2IXZT...   \n",
       "16    https://amazon.com//gp/customer-reviews/R38B28...   \n",
       "17    https://amazon.com//gp/customer-reviews/R2MWM3...   \n",
       "18    https://amazon.com//gp/customer-reviews/R32MI0...   \n",
       "19    https://amazon.com//gp/customer-reviews/R3DZFN...   \n",
       "20    https://amazon.com//gp/customer-reviews/R1TAZB...   \n",
       "21    https://amazon.com//gp/customer-reviews/RFQF9R...   \n",
       "22    https://amazon.com//gp/customer-reviews/RS0OF5...   \n",
       "23    https://amazon.com//gp/customer-reviews/ROM02O...   \n",
       "24    https://amazon.com//gp/customer-reviews/R3DKA9...   \n",
       "25    https://amazon.com//gp/customer-reviews/R2N49P...   \n",
       "26    https://amazon.com//gp/customer-reviews/R111SP...   \n",
       "27    https://amazon.com//gp/customer-reviews/R2TZXS...   \n",
       "28    https://amazon.com//gp/customer-reviews/RY5UFB...   \n",
       "29    https://amazon.com//gp/customer-reviews/R3VOD7...   \n",
       "...                                                 ...   \n",
       "2370  https://amazon.com//gp/customer-reviews/R1WOIR...   \n",
       "2371  https://amazon.com//gp/customer-reviews/R32LUL...   \n",
       "2372  https://amazon.com//gp/customer-reviews/R2QU4V...   \n",
       "2373  https://amazon.com//gp/customer-reviews/R39NX4...   \n",
       "2374  https://amazon.com//gp/customer-reviews/R2QKJ0...   \n",
       "2375  https://amazon.com//gp/customer-reviews/R1ZJUE...   \n",
       "2376  https://amazon.com//gp/customer-reviews/R36FW6...   \n",
       "2377  https://amazon.com//gp/customer-reviews/R204XQ...   \n",
       "2378  https://amazon.com//gp/customer-reviews/RVUQ68...   \n",
       "2379  https://amazon.com//gp/customer-reviews/RQ2D6B...   \n",
       "2380  https://amazon.com//gp/customer-reviews/R2TGWQ...   \n",
       "2381  https://amazon.com//gp/customer-reviews/R31W5S...   \n",
       "2382  https://amazon.com//gp/customer-reviews/R1UFPQ...   \n",
       "2383  https://amazon.com//gp/customer-reviews/RGAJTW...   \n",
       "2384  https://amazon.com//gp/customer-reviews/R3EQ9X...   \n",
       "2385  https://amazon.com//gp/customer-reviews/R51QEV...   \n",
       "2386  https://amazon.com//gp/customer-reviews/RJ8AM2...   \n",
       "2387  https://amazon.com//gp/customer-reviews/R3SUPI...   \n",
       "2388  https://amazon.com//gp/customer-reviews/R1O2BJ...   \n",
       "2389  https://amazon.com//gp/customer-reviews/RQO1A8...   \n",
       "2390  https://amazon.com//gp/customer-reviews/R2V8WY...   \n",
       "2391  https://amazon.com//gp/customer-reviews/R3K1FY...   \n",
       "2392  https://amazon.com//gp/customer-reviews/R1UUCR...   \n",
       "2393  https://amazon.com//gp/customer-reviews/R395TG...   \n",
       "2394  https://amazon.com//gp/customer-reviews/R169R9...   \n",
       "2395  https://amazon.com//gp/customer-reviews/RFGLZK...   \n",
       "2396  https://amazon.com//gp/customer-reviews/RDCU3C...   \n",
       "2397  https://amazon.com//gp/customer-reviews/R3PODB...   \n",
       "2398  https://amazon.com//gp/customer-reviews/R10KGM...   \n",
       "2399  https://amazon.com//gp/customer-reviews/R11KOI...   \n",
       "\n",
       "                                            Review Text  \n",
       "0     I had my first opportunity to use the umbrella...  \n",
       "1     I bought this umbrella a few months ago and un...  \n",
       "2     First of all: I have no financial interest in ...  \n",
       "3     I work in New Haven CT, and in the fall, and w...  \n",
       "4     The umbrella appears to be robust; I used it r...  \n",
       "5     Update: Too small! If there is wind, you will ...  \n",
       "6     I was excited to try out this umbrella based o...  \n",
       "7     This umbrella is pretty good. never had a umbr...  \n",
       "8     I must have received a bad item or something b...  \n",
       "9     I bought two of these for my and my spouse's u...  \n",
       "10    I cannot argue with the fact that this umbrell...  \n",
       "11    I've owned at least 50 umbrellas (some bought ...  \n",
       "12    I have benkii before(less1 year) but i lost it...  \n",
       "13    Change from 2 to 5 stars.  After a not-so-grea...  \n",
       "14    Nicely built. The metal shaft is black however...  \n",
       "15    I am a 67 year old banker, been banking for ov...  \n",
       "16    I like bullet points, thus: + Excellent build ...  \n",
       "17    3rd party seller very involved, customer servi...  \n",
       "18    I was looking for a lightweight umbrella to re...  \n",
       "19    I moved to San Francisco and needed an umbrell...  \n",
       "20    For all the money I paid for this umbrella, I'...  \n",
       "21    It's ok, the build quality seemed nice at firs...  \n",
       "22    I live in Chicago suburbia so I have very litt...  \n",
       "23    For a compact umbrella, it's a \"big\" umbrella ...  \n",
       "24    Being a bachelor, I never really felt the need...  \n",
       "25    The umbrella feels sturdy. Haven't experienced...  \n",
       "26    **Update: I'm updating my review from 2 to 4 s...  \n",
       "27    I ordered this during a rainstorm and since it...  \n",
       "28    This umbrella is of better apparent quality th...  \n",
       "29    Feels sturdy and a well constructed umbrella. ...  \n",
       "...                                                 ...  \n",
       "2370         Great product and fast shipping, thank you  \n",
       "2371  It's an expensive umbrella but i assure you th...  \n",
       "2372                                      Great quality  \n",
       "2373                                     Great product!  \n",
       "2374            It was very heavy! Not what I expected.  \n",
       "2375          Super product.... excellent value..buy 2!  \n",
       "2376  This is a very good umbrella and functions wel...  \n",
       "2377                     Amazing, easy to use umbrella!  \n",
       "2378  Sturdy and built to last. These umbrellas are ...  \n",
       "2379  Feels very sturdy and is a decent size - bigge...  \n",
       "2380  Nice quality umbrella. Arrived earlier than ex...  \n",
       "2381  Holds up well in the wind. Great product from ...  \n",
       "2382  5 stars for this umbrella. Well made with high...  \n",
       "2383  So love this umbrella. Very easy to use. I wou...  \n",
       "2384    cool product.i recieved for a reduced discount.  \n",
       "2385                                         Five Star.  \n",
       "2386  Fits in my bag and keeps my hair and clothes d...  \n",
       "2387        A wonderful umbrella at an excellent price!  \n",
       "2388          solid construction.  haven't had rain yet  \n",
       "2389  It is a well designed product and worth your m...  \n",
       "2390                                    Great umbrella!  \n",
       "2391  I received this Umbrella free and LOVE it. It ...  \n",
       "2392  The Dupont Teflon feels sturdy and keeps the r...  \n",
       "2393  love a good walk in the rain, its so relaxing ...  \n",
       "2394  These umbrellas are everything they say they a...  \n",
       "2395                                  Works well so far  \n",
       "2396                                    Great umbrella!  \n",
       "2397          Great product! Would recommend to anyone!  \n",
       "2398                                 Easy and well made  \n",
       "2399            The umbrella is easy to open and close.  \n",
       "\n",
       "[2400 rows x 9 columns]"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "(7, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.05101114, 0.04537321, 0.715312  , 0.04185817, 0.03482933,\n",
       "       0.05562435, 0.05663225], dtype=float32)"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(reviews['Review Text'].iloc[1].split('.')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Importing DepecheMood</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "depeche=pd.read_csv('depeche_word_isolation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Lemma#PoS', 'AFRAID', 'AMUSED', 'ANGRY', 'ANNOYED', 'DONT_CARE',\n",
       "       'HAPPY', 'INSPIRED', 'SAD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depeche.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anger='ANGRY'+'ANNOYED'\n",
    "disgust='ANGRY'\n",
    "fear='AFRAID'\n",
    "guilt='SAD'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Importing fb-reactions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_reactions=pd.read_json('data/fb_reactions.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_reactions['avg_wow']=fb_reactions['fb_wow']/fb_reactions['fb_like']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_reactions['message'].replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_reactions.dropna(subset=['message'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_reactions=fb_reactions.sort_values('avg_wow', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_reactions=fb_reactions.reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_reactions['emotion']='surprise'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['database', 'date_only', 'day_name', 'description', 'external_picture',\n",
       "       'fanpagelink', 'fb_angry', 'fb_haha', 'fb_id', 'fb_like', 'fb_love',\n",
       "       'fb_sad', 'fb_thankful', 'fb_total_reactions', 'fb_wow',\n",
       "       'highest_reaction', 'highest_reaction_extended', 'id', 'link',\n",
       "       'message', 'name', 'num_comments', 'page_id', 'preprocessed_name',\n",
       "       'preprocessed_stem_stop', 'shares', 'time_created', 'time_only', 'type',\n",
       "       'avg_wow', 'emotion'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb_reactions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprise=fb_reactions.iloc[:1080]\n",
    "surprise_X=surprise['message']\n",
    "surprise_y=surprise['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprise_df=pd.DataFrame()\n",
    "surprise_df[0]=surprise_y\n",
    "surprise_df[1]=surprise_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27823</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Terrifying.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27382</th>\n",
       "      <td>surprise</td>\n",
       "      <td>This is terrifying.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28303</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Yikes!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33513</th>\n",
       "      <td>surprise</td>\n",
       "      <td>For some reason this is a little hard to belie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49643</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Passengers aboard Delta flight 762 experienced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28081</th>\n",
       "      <td>surprise</td>\n",
       "      <td>The 33-year-old officer managed to avoid serio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33611</th>\n",
       "      <td>surprise</td>\n",
       "      <td>DEVELOPING...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27464</th>\n",
       "      <td>surprise</td>\n",
       "      <td>An industrial-sized barbecue grill broke free ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7140</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Oh my dear god.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27269</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Awful.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12968</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Snow in July? Not quite. But this storm produc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28410</th>\n",
       "      <td>surprise</td>\n",
       "      <td>\"I'm just glad that my son wasn't wearing them...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35154</th>\n",
       "      <td>surprise</td>\n",
       "      <td>What the?!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27894</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Warn your friends!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33714</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Each WNBA team was fined $5,000 and its player...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34614</th>\n",
       "      <td>surprise</td>\n",
       "      <td>An alligator dragged a 2-year-old into the wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34599</th>\n",
       "      <td>surprise</td>\n",
       "      <td>The child’s body was found completely intact “...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15072</th>\n",
       "      <td>surprise</td>\n",
       "      <td>\"This could happen at any store that sells tre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47543</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Noooooo!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25631</th>\n",
       "      <td>surprise</td>\n",
       "      <td>His unborn twin had hair, legs and genitals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28101</th>\n",
       "      <td>surprise</td>\n",
       "      <td>It’s their only way to get home...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13434</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Colleen Burns, 35, was hiking along the trails...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8174</th>\n",
       "      <td>surprise</td>\n",
       "      <td>“No mother should have to go [through] what I’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7230</th>\n",
       "      <td>surprise</td>\n",
       "      <td>The actor was most famous for appearing as Che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34460</th>\n",
       "      <td>surprise</td>\n",
       "      <td>\"I refuse to ruin the lives of two young men w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12957</th>\n",
       "      <td>surprise</td>\n",
       "      <td>A deer ate the thawed remains of an infected r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46672</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Bid farewell to your childhood. ???? ???? ????</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34409</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Unbelievable that this is happening.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28227</th>\n",
       "      <td>surprise</td>\n",
       "      <td>BREAKING NEWS: In a tragic start to Preakness ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27610</th>\n",
       "      <td>surprise</td>\n",
       "      <td>KTLA reporter Steve Kuzj and cameraman Victor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63826</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Is it possible to finish a marathon in under 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50729</th>\n",
       "      <td>surprise</td>\n",
       "      <td>\"To stop boys getting ideas and create a good ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>surprise</td>\n",
       "      <td>How high can we build in the future?\\nhttp://9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67278</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Researchers investigating the 2,500-year-old m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15327</th>\n",
       "      <td>surprise</td>\n",
       "      <td>It's one of the most famous ships in history -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19891</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Scientists searching for a solution to ever-re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65021</th>\n",
       "      <td>surprise</td>\n",
       "      <td>People here said they had known that a network...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6158</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Seriously? SERIOUSLY?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20816</th>\n",
       "      <td>surprise</td>\n",
       "      <td>An Oregon man has been charged with abusive se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36055</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Television footage showed fires, power outages...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41758</th>\n",
       "      <td>surprise</td>\n",
       "      <td>A new theory suggests a cataclysmic disaster b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29108</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Stewardesses were prepared to wear headscarves...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28868</th>\n",
       "      <td>surprise</td>\n",
       "      <td>The standoff is \"between the goodhearted moms ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25830</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Her dream was ripped away by a urinary tract i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26021</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Such a sad story. RIP.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20967</th>\n",
       "      <td>surprise</td>\n",
       "      <td>A Dutch woman woke up in an unfamiliar locatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48513</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Talk about a baaaaaaaaaaaddddd situation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22489</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Nope, it's not Star Trek or The Hunger Games.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25199</th>\n",
       "      <td>surprise</td>\n",
       "      <td>The fake taxi rapist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50327</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Eerie yet beautiful.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28559</th>\n",
       "      <td>surprise</td>\n",
       "      <td>The monument will be moved to another location...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25569</th>\n",
       "      <td>surprise</td>\n",
       "      <td>So sad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15007</th>\n",
       "      <td>surprise</td>\n",
       "      <td>BREAKING: Distress signal detected in vicinity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65349</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Will Smith, a former defensive end for the New...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56446</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Our video of the day: It might be a featherwei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28133</th>\n",
       "      <td>surprise</td>\n",
       "      <td>San Francisco officials upheld the city's stri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33474</th>\n",
       "      <td>surprise</td>\n",
       "      <td>This is a truly shameful response, Donald J. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25904</th>\n",
       "      <td>surprise</td>\n",
       "      <td>The 'Babes in the Wood', aged 10 and nine, wer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34004</th>\n",
       "      <td>surprise</td>\n",
       "      <td>There's a solution!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50148</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Naturally, they're marketing this water as Pur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1080 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0                                                  1\n",
       "27823  surprise                                        Terrifying.\n",
       "27382  surprise                                This is terrifying.\n",
       "28303  surprise                                             Yikes!\n",
       "33513  surprise  For some reason this is a little hard to belie...\n",
       "49643  surprise  Passengers aboard Delta flight 762 experienced...\n",
       "28081  surprise  The 33-year-old officer managed to avoid serio...\n",
       "33611  surprise                                      DEVELOPING...\n",
       "27464  surprise  An industrial-sized barbecue grill broke free ...\n",
       "7140   surprise                                    Oh my dear god.\n",
       "27269  surprise                                             Awful.\n",
       "12968  surprise  Snow in July? Not quite. But this storm produc...\n",
       "28410  surprise  \"I'm just glad that my son wasn't wearing them...\n",
       "35154  surprise                                         What the?!\n",
       "27894  surprise                                 Warn your friends!\n",
       "33714  surprise  Each WNBA team was fined $5,000 and its player...\n",
       "34614  surprise  An alligator dragged a 2-year-old into the wat...\n",
       "34599  surprise  The child’s body was found completely intact “...\n",
       "15072  surprise  \"This could happen at any store that sells tre...\n",
       "47543  surprise                                           Noooooo!\n",
       "25631  surprise        His unborn twin had hair, legs and genitals\n",
       "28101  surprise                 It’s their only way to get home...\n",
       "13434  surprise  Colleen Burns, 35, was hiking along the trails...\n",
       "8174   surprise  “No mother should have to go [through] what I’...\n",
       "7230   surprise  The actor was most famous for appearing as Che...\n",
       "34460  surprise  \"I refuse to ruin the lives of two young men w...\n",
       "12957  surprise  A deer ate the thawed remains of an infected r...\n",
       "46672  surprise     Bid farewell to your childhood. ???? ???? ????\n",
       "34409  surprise               Unbelievable that this is happening.\n",
       "28227  surprise  BREAKING NEWS: In a tragic start to Preakness ...\n",
       "27610  surprise  KTLA reporter Steve Kuzj and cameraman Victor ...\n",
       "...         ...                                                ...\n",
       "63826  surprise  Is it possible to finish a marathon in under 2...\n",
       "50729  surprise  \"To stop boys getting ideas and create a good ...\n",
       "1179   surprise  How high can we build in the future?\\nhttp://9...\n",
       "67278  surprise  Researchers investigating the 2,500-year-old m...\n",
       "15327  surprise  It's one of the most famous ships in history -...\n",
       "19891  surprise  Scientists searching for a solution to ever-re...\n",
       "65021  surprise  People here said they had known that a network...\n",
       "6158   surprise                              Seriously? SERIOUSLY?\n",
       "20816  surprise  An Oregon man has been charged with abusive se...\n",
       "36055  surprise  Television footage showed fires, power outages...\n",
       "41758  surprise  A new theory suggests a cataclysmic disaster b...\n",
       "29108  surprise  Stewardesses were prepared to wear headscarves...\n",
       "28868  surprise  The standoff is \"between the goodhearted moms ...\n",
       "25830  surprise  Her dream was ripped away by a urinary tract i...\n",
       "26021  surprise                             Such a sad story. RIP.\n",
       "20967  surprise  A Dutch woman woke up in an unfamiliar locatio...\n",
       "48513  surprise          Talk about a baaaaaaaaaaaddddd situation.\n",
       "22489  surprise      Nope, it's not Star Trek or The Hunger Games.\n",
       "25199  surprise                               The fake taxi rapist\n",
       "50327  surprise                               Eerie yet beautiful.\n",
       "28559  surprise  The monument will be moved to another location...\n",
       "25569  surprise                                            So sad.\n",
       "15007  surprise  BREAKING: Distress signal detected in vicinity...\n",
       "65349  surprise  Will Smith, a former defensive end for the New...\n",
       "56446  surprise  Our video of the day: It might be a featherwei...\n",
       "28133  surprise  San Francisco officials upheld the city's stri...\n",
       "33474  surprise  This is a truly shameful response, Donald J. T...\n",
       "25904  surprise  The 'Babes in the Wood', aged 10 and nine, wer...\n",
       "34004  surprise                                There's a solution!\n",
       "50148  surprise  Naturally, they're marketing this water as Pur...\n",
       "\n",
       "[1080 rows x 2 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surprise_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "isear[0].replace(['shame', 'disgust', 'guilt'], np.nan, inplace=True)\n",
    "isear.dropna(subset=[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "indico_emotions=isear.append(surprise_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joy</td>\n",
       "      <td>On days when I feel close to my partner and ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>Every time I imagine that someone I love or I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>When I had been obviously unjustly treated and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When I think about the short time that we live...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>joy</td>\n",
       "      <td>After my girlfriend had taken her exam we went...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fear</td>\n",
       "      <td>When, for the first time I realized the meanin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>anger</td>\n",
       "      <td>When a car is overtaking another and I am forc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When I recently thought about the hard work it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>joy</td>\n",
       "      <td>When I pass an examination which I did not thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fear</td>\n",
       "      <td>When one has arranged to meet someone and that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>anger</td>\n",
       "      <td>When one is unjustly accused of something one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When one's studies seem hopelessly difficult a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>joy</td>\n",
       "      <td>Passing an exam I did not expect to pass.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>fear</td>\n",
       "      <td>When I climbed up a tree to pick apples.  The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>joy</td>\n",
       "      <td>When I had my children.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>fear</td>\n",
       "      <td>When my 2 year old son climbed up and sat on t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>anger</td>\n",
       "      <td>When my partner was attacked and lost three te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When I see children on T.V from areas devastat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>joy</td>\n",
       "      <td>When my child was born.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>fear</td>\n",
       "      <td>It was spring and the ice was melting.  I was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>anger</td>\n",
       "      <td>Unjust accusations directed at me and my way o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Failing an examination.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>joy</td>\n",
       "      <td>When I saw a person I had not seen for a long ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>fear</td>\n",
       "      <td>When, as a child, I was nearly knocked down by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>anger</td>\n",
       "      <td>When I heard on the radio that the football ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When I feel lonely, perhaps because I have to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>joy</td>\n",
       "      <td>When I was accepted for a course on finance an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>fear</td>\n",
       "      <td>A bus drove over my right leg.  The event itse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>anger</td>\n",
       "      <td>At my Summer job, nobody looked after me in pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When I was not accepted as a student in financ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63826</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Is it possible to finish a marathon in under 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50729</th>\n",
       "      <td>surprise</td>\n",
       "      <td>\"To stop boys getting ideas and create a good ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>surprise</td>\n",
       "      <td>How high can we build in the future?\\nhttp://9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67278</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Researchers investigating the 2,500-year-old m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15327</th>\n",
       "      <td>surprise</td>\n",
       "      <td>It's one of the most famous ships in history -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19891</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Scientists searching for a solution to ever-re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65021</th>\n",
       "      <td>surprise</td>\n",
       "      <td>People here said they had known that a network...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6158</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Seriously? SERIOUSLY?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20816</th>\n",
       "      <td>surprise</td>\n",
       "      <td>An Oregon man has been charged with abusive se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36055</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Television footage showed fires, power outages...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41758</th>\n",
       "      <td>surprise</td>\n",
       "      <td>A new theory suggests a cataclysmic disaster b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29108</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Stewardesses were prepared to wear headscarves...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28868</th>\n",
       "      <td>surprise</td>\n",
       "      <td>The standoff is \"between the goodhearted moms ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25830</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Her dream was ripped away by a urinary tract i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26021</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Such a sad story. RIP.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20967</th>\n",
       "      <td>surprise</td>\n",
       "      <td>A Dutch woman woke up in an unfamiliar locatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48513</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Talk about a baaaaaaaaaaaddddd situation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22489</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Nope, it's not Star Trek or The Hunger Games.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25199</th>\n",
       "      <td>surprise</td>\n",
       "      <td>The fake taxi rapist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50327</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Eerie yet beautiful.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28559</th>\n",
       "      <td>surprise</td>\n",
       "      <td>The monument will be moved to another location...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25569</th>\n",
       "      <td>surprise</td>\n",
       "      <td>So sad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15007</th>\n",
       "      <td>surprise</td>\n",
       "      <td>BREAKING: Distress signal detected in vicinity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65349</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Will Smith, a former defensive end for the New...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56446</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Our video of the day: It might be a featherwei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28133</th>\n",
       "      <td>surprise</td>\n",
       "      <td>San Francisco officials upheld the city's stri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33474</th>\n",
       "      <td>surprise</td>\n",
       "      <td>This is a truly shameful response, Donald J. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25904</th>\n",
       "      <td>surprise</td>\n",
       "      <td>The 'Babes in the Wood', aged 10 and nine, wer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34004</th>\n",
       "      <td>surprise</td>\n",
       "      <td>There's a solution!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50148</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Naturally, they're marketing this water as Pur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5409 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0                                                  1\n",
       "0           joy  On days when I feel close to my partner and ot...\n",
       "1          fear  Every time I imagine that someone I love or I ...\n",
       "2         anger  When I had been obviously unjustly treated and...\n",
       "3       sadness  When I think about the short time that we live...\n",
       "7           joy  After my girlfriend had taken her exam we went...\n",
       "8          fear  When, for the first time I realized the meanin...\n",
       "9         anger  When a car is overtaking another and I am forc...\n",
       "10      sadness  When I recently thought about the hard work it...\n",
       "14          joy  When I pass an examination which I did not thi...\n",
       "15         fear  When one has arranged to meet someone and that...\n",
       "16        anger  When one is unjustly accused of something one ...\n",
       "17      sadness  When one's studies seem hopelessly difficult a...\n",
       "21          joy          Passing an exam I did not expect to pass.\n",
       "22         fear  When I climbed up a tree to pick apples.  The ...\n",
       "24          joy                            When I had my children.\n",
       "25         fear  When my 2 year old son climbed up and sat on t...\n",
       "26        anger  When my partner was attacked and lost three te...\n",
       "27      sadness  When I see children on T.V from areas devastat...\n",
       "31          joy                            When my child was born.\n",
       "32         fear  It was spring and the ice was melting.  I was ...\n",
       "33        anger  Unjust accusations directed at me and my way o...\n",
       "34      sadness                            Failing an examination.\n",
       "38          joy  When I saw a person I had not seen for a long ...\n",
       "39         fear  When, as a child, I was nearly knocked down by...\n",
       "40        anger  When I heard on the radio that the football ma...\n",
       "41      sadness  When I feel lonely, perhaps because I have to ...\n",
       "45          joy  When I was accepted for a course on finance an...\n",
       "46         fear  A bus drove over my right leg.  The event itse...\n",
       "47        anger  At my Summer job, nobody looked after me in pa...\n",
       "48      sadness  When I was not accepted as a student in financ...\n",
       "...         ...                                                ...\n",
       "63826  surprise  Is it possible to finish a marathon in under 2...\n",
       "50729  surprise  \"To stop boys getting ideas and create a good ...\n",
       "1179   surprise  How high can we build in the future?\\nhttp://9...\n",
       "67278  surprise  Researchers investigating the 2,500-year-old m...\n",
       "15327  surprise  It's one of the most famous ships in history -...\n",
       "19891  surprise  Scientists searching for a solution to ever-re...\n",
       "65021  surprise  People here said they had known that a network...\n",
       "6158   surprise                              Seriously? SERIOUSLY?\n",
       "20816  surprise  An Oregon man has been charged with abusive se...\n",
       "36055  surprise  Television footage showed fires, power outages...\n",
       "41758  surprise  A new theory suggests a cataclysmic disaster b...\n",
       "29108  surprise  Stewardesses were prepared to wear headscarves...\n",
       "28868  surprise  The standoff is \"between the goodhearted moms ...\n",
       "25830  surprise  Her dream was ripped away by a urinary tract i...\n",
       "26021  surprise                             Such a sad story. RIP.\n",
       "20967  surprise  A Dutch woman woke up in an unfamiliar locatio...\n",
       "48513  surprise          Talk about a baaaaaaaaaaaddddd situation.\n",
       "22489  surprise      Nope, it's not Star Trek or The Hunger Games.\n",
       "25199  surprise                               The fake taxi rapist\n",
       "50327  surprise                               Eerie yet beautiful.\n",
       "28559  surprise  The monument will be moved to another location...\n",
       "25569  surprise                                            So sad.\n",
       "15007  surprise  BREAKING: Distress signal detected in vicinity...\n",
       "65349  surprise  Will Smith, a former defensive end for the New...\n",
       "56446  surprise  Our video of the day: It might be a featherwei...\n",
       "28133  surprise  San Francisco officials upheld the city's stri...\n",
       "33474  surprise  This is a truly shameful response, Donald J. T...\n",
       "25904  surprise  The 'Babes in the Wood', aged 10 and nine, wer...\n",
       "34004  surprise                                There's a solution!\n",
       "50148  surprise  Naturally, they're marketing this water as Pur...\n",
       "\n",
       "[5409 rows x 2 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indico_emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Indico validation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import indicoio\n",
    "indicoio.config.api_key='397e82142cfdfe487c61dca634280b49'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Naturally, they're marketing this water as Purple Rain.\""
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indico_emotions[1].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_1=indicoio.emotion(indico_emotions[1].iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23341253399848938"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_1['surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    On days when I feel close to my partner and ot...\n",
       "1    Every time I imagine that someone I love or I ...\n",
       "2    When I had been obviously unjustly treated and...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indico_emotions[1].iloc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_mult=indicoio.emotion(list(indico_emotions[1].iloc[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'anger': 0.11947168409824371,\n",
       "  'fear': 0.29070523381233215,\n",
       "  'joy': 0.22359329462051392,\n",
       "  'sadness': 0.33788686990737915,\n",
       "  'surprise': 0.02834296226501465},\n",
       " {'anger': 0.3306489884853363,\n",
       "  'fear': 0.10204938054084778,\n",
       "  'joy': 0.035173580050468445,\n",
       "  'sadness': 0.5207858085632324,\n",
       "  'surprise': 0.011342236772179604},\n",
       " {'anger': 0.271008163690567,\n",
       "  'fear': 0.07341042160987854,\n",
       "  'joy': 0.03585120290517807,\n",
       "  'sadness': 0.5347471237182617,\n",
       "  'surprise': 0.08498305082321167}]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_mult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02834296226501465 0\n",
      "0.011342236772179604 1\n",
      "0.08498305082321167 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 0.02834296226501465, 1: 0.011342236772179604, 2: 0.08498305082321167}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surprise_dict={}\n",
    "for index, pred in enumerate(test_pred_mult):\n",
    "    print(pred['surprise'], index)\n",
    "    surprise_dict[index]=pred['surprise']\n",
    "surprise_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.011342236772179604), (0, 0.02834296226501465), (2, 0.08498305082321167)]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "sorted_surprise_dict=sorted(surprise_dict.items(), key=operator.itemgetter(1))\n",
    "sorted_surprise_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On days when I feel close to my partner and other friends.   \n",
      "When I feel at peace with myself and also experience a close  \n",
      "contact with people whom I regard greatly.\n",
      "Every time I imagine that someone I love or I could contact a  \n",
      "serious illness, even death.\n",
      "When I had been obviously unjustly treated and had no possibility  \n",
      "of elucidating this.\n"
     ]
    }
   ],
   "source": [
    "for index in surprise_dict:\n",
    "    print(indico_emotions[1].iloc[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evaluating many facebook entries in the message column</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surprise=fb_reactions.iloc[:4000]\n",
    "surprise_X=surprise['message']\n",
    "len(surprise_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Do NOT run this next step again, it counts against the quota</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Indico_surprise_predictions=indicoio.emotion(list(surprise_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(Indico_surprise_predictions, open('Indico_surprise_predictions.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_surprise(indico_list):\n",
    "    surprise_dict={}\n",
    "    for index, pred in enumerate(indico_list):\n",
    "        surprise_dict[index]=pred['surprise']\n",
    "    sorted_surprise_dict=sorted(surprise_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sorted_surprise_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_surprise=sort_surprise(Indico_surprise_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3683, 0.9539512395858765),\n",
       " (3883, 0.9527742862701416),\n",
       " (829, 0.949898898601532),\n",
       " (447, 0.9370132684707642),\n",
       " (2890, 0.9296550750732422),\n",
       " (2145, 0.9246888756752014),\n",
       " (3447, 0.9224801063537598),\n",
       " (2809, 0.9215435981750488),\n",
       " (2163, 0.9202695488929749),\n",
       " (151, 0.9162212610244751),\n",
       " (1989, 0.9157223701477051),\n",
       " (3298, 0.9139634966850281),\n",
       " (1070, 0.901566743850708),\n",
       " (800, 0.897817850112915),\n",
       " (749, 0.8887519836425781),\n",
       " (1754, 0.887529730796814),\n",
       " (3439, 0.8798812031745911),\n",
       " (548, 0.8695153594017029),\n",
       " (1268, 0.8664361238479614),\n",
       " (2858, 0.8638198375701904),\n",
       " (1512, 0.8535745143890381),\n",
       " (3850, 0.8436046838760376),\n",
       " (861, 0.8278483152389526),\n",
       " (1348, 0.8221002817153931),\n",
       " (1773, 0.8197835683822632),\n",
       " (2017, 0.8197430372238159),\n",
       " (1732, 0.8158684968948364),\n",
       " (3125, 0.811977744102478),\n",
       " (1006, 0.8094233274459839),\n",
       " (394, 0.808263897895813),\n",
       " (1647, 0.8046984076499939),\n",
       " (2420, 0.8036953210830688),\n",
       " (3146, 0.7918825149536133),\n",
       " (103, 0.7886497378349304),\n",
       " (2585, 0.7864409685134888),\n",
       " (3996, 0.7849421501159668),\n",
       " (1530, 0.7834092378616333),\n",
       " (1691, 0.7792932391166687),\n",
       " (1513, 0.7707408666610718),\n",
       " (572, 0.7673758864402771),\n",
       " (2938, 0.7626558542251587),\n",
       " (1722, 0.7566217184066772),\n",
       " (2824, 0.756122887134552),\n",
       " (887, 0.7557228803634644),\n",
       " (192, 0.7500152587890625),\n",
       " (786, 0.7499655485153198),\n",
       " (2576, 0.7498582601547241),\n",
       " (1895, 0.7461179494857788),\n",
       " (2942, 0.7418396472930908),\n",
       " (3440, 0.7418286800384521),\n",
       " (3849, 0.7362621426582336),\n",
       " (3591, 0.728298544883728),\n",
       " (2207, 0.7264888286590576),\n",
       " (1606, 0.725237250328064),\n",
       " (1096, 0.7176775932312012),\n",
       " (2767, 0.7149225473403931),\n",
       " (516, 0.7125385403633118),\n",
       " (2066, 0.7080731391906738),\n",
       " (1586, 0.7059670686721802),\n",
       " (3035, 0.7029675841331482),\n",
       " (3782, 0.7019439935684204),\n",
       " (3777, 0.6969588994979858),\n",
       " (1262, 0.6956998705863953),\n",
       " (1036, 0.6948436498641968),\n",
       " (1832, 0.6914515495300293),\n",
       " (3602, 0.6896507740020752),\n",
       " (273, 0.6892974376678467),\n",
       " (2030, 0.6878498792648315),\n",
       " (2739, 0.6860780119895935),\n",
       " (3179, 0.6845444440841675),\n",
       " (704, 0.6835403442382812),\n",
       " (1323, 0.6788219213485718),\n",
       " (3097, 0.6780945658683777),\n",
       " (3232, 0.6772827506065369),\n",
       " (241, 0.6770901083946228),\n",
       " (285, 0.6763696074485779),\n",
       " (2802, 0.6743148565292358),\n",
       " (2896, 0.6688090562820435),\n",
       " (1626, 0.6683692336082458),\n",
       " (1271, 0.6611875295639038),\n",
       " (3356, 0.6607730388641357),\n",
       " (2338, 0.6545461416244507),\n",
       " (3383, 0.6533165574073792),\n",
       " (264, 0.6489347219467163),\n",
       " (2154, 0.641842246055603),\n",
       " (530, 0.6357525587081909),\n",
       " (1280, 0.6321629285812378),\n",
       " (3055, 0.6289348602294922),\n",
       " (2490, 0.6277894377708435),\n",
       " (3122, 0.6269257068634033),\n",
       " (2453, 0.6264384984970093),\n",
       " (2085, 0.6213452816009521),\n",
       " (2074, 0.6211046576499939),\n",
       " (3071, 0.6204652190208435),\n",
       " (2184, 0.6200705170631409),\n",
       " (3056, 0.6161024570465088),\n",
       " (370, 0.6160140037536621),\n",
       " (567, 0.6158285140991211),\n",
       " (3715, 0.6135971546173096),\n",
       " (2758, 0.608470618724823),\n",
       " (639, 0.6080875396728516),\n",
       " (3091, 0.6051163673400879),\n",
       " (2140, 0.6023010015487671),\n",
       " (3413, 0.6011525392532349),\n",
       " (2855, 0.5974069833755493),\n",
       " (3369, 0.5965532064437866),\n",
       " (1284, 0.5871944427490234),\n",
       " (1328, 0.5791987180709839),\n",
       " (3067, 0.5780333280563354),\n",
       " (3101, 0.5779296159744263),\n",
       " (2320, 0.5764357447624207),\n",
       " (3590, 0.5758888721466064),\n",
       " (874, 0.5754921436309814),\n",
       " (628, 0.5715537667274475),\n",
       " (1413, 0.5674400329589844),\n",
       " (3684, 0.5659320950508118),\n",
       " (3537, 0.5654478669166565),\n",
       " (2692, 0.5647611021995544),\n",
       " (226, 0.5643975734710693),\n",
       " (634, 0.5632918477058411),\n",
       " (3713, 0.5616342425346375),\n",
       " (3147, 0.5597267746925354),\n",
       " (1215, 0.5580368041992188),\n",
       " (2107, 0.5573498010635376),\n",
       " (2883, 0.5573203563690186),\n",
       " (2340, 0.5549601316452026),\n",
       " (1082, 0.5548690557479858),\n",
       " (13, 0.5528103113174438),\n",
       " (3034, 0.5526117086410522),\n",
       " (710, 0.5524241328239441),\n",
       " (1646, 0.5511788129806519),\n",
       " (1884, 0.5507338047027588),\n",
       " (1802, 0.5498151183128357),\n",
       " (2456, 0.5484938621520996),\n",
       " (2669, 0.5472447872161865),\n",
       " (3415, 0.5426992774009705),\n",
       " (2438, 0.5413762331008911),\n",
       " (1420, 0.5411970019340515),\n",
       " (3944, 0.5371140241622925),\n",
       " (3524, 0.5369701385498047),\n",
       " (3965, 0.5353381633758545),\n",
       " (890, 0.5342118740081787),\n",
       " (3004, 0.532106876373291),\n",
       " (3105, 0.5318514108657837),\n",
       " (2083, 0.5242485404014587),\n",
       " (3992, 0.5225255489349365),\n",
       " (1453, 0.5211979150772095),\n",
       " (1569, 0.5196333527565002),\n",
       " (2854, 0.5165546536445618),\n",
       " (761, 0.5162725448608398),\n",
       " (2294, 0.514093816280365),\n",
       " (3658, 0.5127812623977661),\n",
       " (2160, 0.5115731358528137),\n",
       " (798, 0.5111028552055359),\n",
       " (2776, 0.49878740310668945),\n",
       " (664, 0.4978370666503906),\n",
       " (1399, 0.49441957473754883),\n",
       " (3978, 0.4929388165473938),\n",
       " (647, 0.4927877187728882),\n",
       " (1668, 0.48839807510375977),\n",
       " (2277, 0.4880051612854004),\n",
       " (2024, 0.4864565134048462),\n",
       " (1196, 0.48507779836654663),\n",
       " (3174, 0.4842117130756378),\n",
       " (999, 0.4827393889427185),\n",
       " (3660, 0.4803796112537384),\n",
       " (3364, 0.4791892170906067),\n",
       " (2703, 0.47575217485427856),\n",
       " (3881, 0.47331735491752625),\n",
       " (3410, 0.4729739725589752),\n",
       " (560, 0.472384512424469),\n",
       " (539, 0.47150060534477234),\n",
       " (1613, 0.47117018699645996),\n",
       " (2052, 0.47111791372299194),\n",
       " (2127, 0.4688704013824463),\n",
       " (2659, 0.4667859673500061),\n",
       " (2782, 0.4662914574146271),\n",
       " (3075, 0.4654635190963745),\n",
       " (3597, 0.4641178548336029),\n",
       " (1259, 0.4621790647506714),\n",
       " (1797, 0.46015381813049316),\n",
       " (2599, 0.4590962529182434),\n",
       " (2878, 0.4579334259033203),\n",
       " (2699, 0.454700231552124),\n",
       " (1293, 0.4543749690055847),\n",
       " (733, 0.4532191753387451),\n",
       " (1644, 0.4526705741882324),\n",
       " (272, 0.45257556438446045),\n",
       " (3800, 0.44934821128845215),\n",
       " (3481, 0.4480440020561218),\n",
       " (2528, 0.44791561365127563),\n",
       " (3162, 0.44732505083084106),\n",
       " (821, 0.44729337096214294),\n",
       " (1313, 0.44716575741767883),\n",
       " (148, 0.4464128315448761),\n",
       " (3957, 0.44491153955459595),\n",
       " (862, 0.44222983717918396),\n",
       " (1315, 0.44123637676239014),\n",
       " (3616, 0.44084444642066956),\n",
       " (2673, 0.4406173825263977),\n",
       " (2255, 0.43996334075927734),\n",
       " (2442, 0.43992945551872253),\n",
       " (526, 0.4390034079551697),\n",
       " (2032, 0.436635285615921),\n",
       " (165, 0.43612363934516907),\n",
       " (751, 0.4352225065231323),\n",
       " (2352, 0.43305325508117676),\n",
       " (1904, 0.43241825699806213),\n",
       " (3319, 0.43142932653427124),\n",
       " (881, 0.4305722117424011),\n",
       " (544, 0.4288754463195801),\n",
       " (2494, 0.42807984352111816),\n",
       " (622, 0.4269675016403198),\n",
       " (2973, 0.42644262313842773),\n",
       " (564, 0.42528796195983887),\n",
       " (3362, 0.42520782351493835),\n",
       " (3788, 0.4238157570362091),\n",
       " (1379, 0.4227464199066162),\n",
       " (1921, 0.4227268397808075),\n",
       " (385, 0.4217231571674347),\n",
       " (2305, 0.421054482460022),\n",
       " (3780, 0.42003563046455383),\n",
       " (1454, 0.4194789528846741),\n",
       " (1455, 0.41886210441589355),\n",
       " (3531, 0.41694778203964233),\n",
       " (2801, 0.41684556007385254),\n",
       " (3693, 0.4161037504673004),\n",
       " (256, 0.41554874181747437),\n",
       " (2822, 0.41367262601852417),\n",
       " (3346, 0.41329655051231384),\n",
       " (889, 0.4130614697933197),\n",
       " (2601, 0.4129021167755127),\n",
       " (3506, 0.41181468963623047),\n",
       " (2431, 0.4115191698074341),\n",
       " (1841, 0.41140586137771606),\n",
       " (469, 0.4110809564590454),\n",
       " (2488, 0.41104114055633545),\n",
       " (2229, 0.4093852639198303),\n",
       " (2261, 0.4093806743621826),\n",
       " (3486, 0.40916240215301514),\n",
       " (1003, 0.40861237049102783),\n",
       " (39, 0.4084694981575012),\n",
       " (2701, 0.4069797396659851),\n",
       " (3335, 0.40662261843681335),\n",
       " (416, 0.4066184461116791),\n",
       " (906, 0.4060567021369934),\n",
       " (487, 0.40586113929748535),\n",
       " (883, 0.40569132566452026),\n",
       " (3976, 0.4050067067146301),\n",
       " (421, 0.40407630801200867),\n",
       " (3492, 0.40353935956954956),\n",
       " (1023, 0.40148329734802246),\n",
       " (1877, 0.40147268772125244),\n",
       " (3005, 0.40055108070373535),\n",
       " (2175, 0.4001080393791199),\n",
       " (2778, 0.3991221487522125),\n",
       " (2978, 0.3987691402435303),\n",
       " (1341, 0.3987211585044861),\n",
       " (2788, 0.3984144628047943),\n",
       " (2003, 0.39800703525543213),\n",
       " (1776, 0.39788198471069336),\n",
       " (2688, 0.3972257673740387),\n",
       " (3211, 0.3969632387161255),\n",
       " (1539, 0.3956940770149231),\n",
       " (2116, 0.39543694257736206),\n",
       " (1375, 0.39536941051483154),\n",
       " (3831, 0.3949659764766693),\n",
       " (2075, 0.39456111192703247),\n",
       " (838, 0.3942706286907196),\n",
       " (3271, 0.3941180109977722),\n",
       " (3163, 0.39358872175216675),\n",
       " (2913, 0.3933582603931427),\n",
       " (2156, 0.39317893981933594),\n",
       " (3919, 0.3914426565170288),\n",
       " (696, 0.39098691940307617),\n",
       " (849, 0.3906329274177551),\n",
       " (177, 0.38993072509765625),\n",
       " (1793, 0.38808923959732056),\n",
       " (853, 0.38804319500923157),\n",
       " (3085, 0.3871527314186096),\n",
       " (836, 0.38700515031814575),\n",
       " (942, 0.3866040110588074),\n",
       " (1135, 0.3866040110588074),\n",
       " (1517, 0.3851558268070221),\n",
       " (2479, 0.38475412130355835),\n",
       " (843, 0.38420870900154114),\n",
       " (1472, 0.38414451479911804),\n",
       " (2227, 0.38375866413116455),\n",
       " (679, 0.3836725354194641),\n",
       " (2806, 0.38319799304008484),\n",
       " (2640, 0.3831276297569275),\n",
       " (3012, 0.382705420255661),\n",
       " (2398, 0.38246530294418335),\n",
       " (1855, 0.38169562816619873),\n",
       " (2684, 0.38151347637176514),\n",
       " (3604, 0.3799746334552765),\n",
       " (927, 0.3787726163864136),\n",
       " (1763, 0.3777272403240204),\n",
       " (1055, 0.3774121403694153),\n",
       " (3425, 0.3770756125450134),\n",
       " (2976, 0.3765456974506378),\n",
       " (3728, 0.3765132427215576),\n",
       " (1630, 0.3750544786453247),\n",
       " (931, 0.3745741546154022),\n",
       " (3737, 0.37323397397994995),\n",
       " (1654, 0.3718761205673218),\n",
       " (3016, 0.3708936274051666),\n",
       " (1509, 0.37027353048324585),\n",
       " (2001, 0.3698061406612396),\n",
       " (3305, 0.36952120065689087),\n",
       " (2946, 0.3690947890281677),\n",
       " (1150, 0.36839422583580017),\n",
       " (662, 0.36817944049835205),\n",
       " (2299, 0.3675001859664917),\n",
       " (961, 0.367178738117218),\n",
       " (855, 0.36686310172080994),\n",
       " (2478, 0.3648177981376648),\n",
       " (2369, 0.3646719455718994),\n",
       " (3568, 0.3646324574947357),\n",
       " (1121, 0.3643595278263092),\n",
       " (3802, 0.364174485206604),\n",
       " (99, 0.3638477325439453),\n",
       " (2041, 0.3634878098964691),\n",
       " (3279, 0.36309918761253357),\n",
       " (2355, 0.3630604147911072),\n",
       " (3835, 0.3629316985607147),\n",
       " (2096, 0.3626558780670166),\n",
       " (2849, 0.3624790906906128),\n",
       " (2744, 0.362138956785202),\n",
       " (1521, 0.3606952428817749),\n",
       " (980, 0.36041831970214844),\n",
       " (896, 0.3597778081893921),\n",
       " (685, 0.3594666123390198),\n",
       " (2284, 0.3594522476196289),\n",
       " (3775, 0.3589380383491516),\n",
       " (1187, 0.3587842881679535),\n",
       " (111, 0.3581158518791199),\n",
       " (1587, 0.35621312260627747),\n",
       " (2469, 0.3559219539165497),\n",
       " (2190, 0.35583820939064026),\n",
       " (2004, 0.35389065742492676),\n",
       " (3119, 0.3532417118549347),\n",
       " (1605, 0.35277360677719116),\n",
       " (229, 0.35255852341651917),\n",
       " (895, 0.35255852341651917),\n",
       " (1093, 0.35255852341651917),\n",
       " (1416, 0.3521067500114441),\n",
       " (311, 0.3521062135696411),\n",
       " (459, 0.35151398181915283),\n",
       " (2468, 0.3502436876296997),\n",
       " (96, 0.3497498333454132),\n",
       " (3559, 0.34923818707466125),\n",
       " (2359, 0.34818562865257263),\n",
       " (2986, 0.3480384349822998),\n",
       " (3618, 0.3476945757865906),\n",
       " (3230, 0.347682923078537),\n",
       " (1330, 0.34586116671562195),\n",
       " (1445, 0.34574148058891296),\n",
       " (3399, 0.3454345762729645),\n",
       " (1532, 0.34507104754447937),\n",
       " (2540, 0.34457409381866455),\n",
       " (1019, 0.3421906530857086),\n",
       " (2250, 0.34189265966415405),\n",
       " (2062, 0.3416859805583954),\n",
       " (1123, 0.340844988822937),\n",
       " (3494, 0.3404013216495514),\n",
       " (3879, 0.3401225209236145),\n",
       " (3134, 0.3400684893131256),\n",
       " (1110, 0.33985936641693115),\n",
       " (2371, 0.33922693133354187),\n",
       " (1427, 0.33888471126556396),\n",
       " (2397, 0.33848702907562256),\n",
       " (30, 0.33775922656059265),\n",
       " (1485, 0.33755993843078613),\n",
       " (3681, 0.3375456631183624),\n",
       " (3082, 0.3373045325279236),\n",
       " (3773, 0.33644795417785645),\n",
       " (2111, 0.3353213965892792),\n",
       " (3461, 0.33386534452438354),\n",
       " (3700, 0.33332422375679016),\n",
       " (1331, 0.3323189318180084),\n",
       " (2549, 0.3319617509841919),\n",
       " (2663, 0.3318999707698822),\n",
       " (1380, 0.3313656747341156),\n",
       " (2546, 0.3293386399745941),\n",
       " (3354, 0.3292721211910248),\n",
       " (3208, 0.3291938602924347),\n",
       " (1719, 0.32914236187934875),\n",
       " (930, 0.32824572920799255),\n",
       " (200, 0.32799142599105835),\n",
       " (1575, 0.3270933926105499),\n",
       " (3482, 0.3257937729358673),\n",
       " (3621, 0.32537397742271423),\n",
       " (1939, 0.3248876631259918),\n",
       " (1965, 0.32219570875167847),\n",
       " (11, 0.320464551448822),\n",
       " (342, 0.32031962275505066),\n",
       " (1376, 0.3200361132621765),\n",
       " (2541, 0.31916409730911255),\n",
       " (2996, 0.31900930404663086),\n",
       " (1312, 0.31874191761016846),\n",
       " (1211, 0.31861579418182373),\n",
       " (553, 0.31802037358283997),\n",
       " (3434, 0.31788313388824463),\n",
       " (409, 0.3178093433380127),\n",
       " (2844, 0.31652742624282837),\n",
       " (750, 0.31603291630744934),\n",
       " (1931, 0.31506508588790894),\n",
       " (2087, 0.31434762477874756),\n",
       " (2547, 0.3138909339904785),\n",
       " (1671, 0.3138778507709503),\n",
       " (102, 0.31257855892181396),\n",
       " (1467, 0.3120661973953247),\n",
       " (2498, 0.3118119239807129),\n",
       " (3634, 0.3117539882659912),\n",
       " (3223, 0.3116926848888397),\n",
       " (3872, 0.30963361263275146),\n",
       " (2049, 0.3077661693096161),\n",
       " (2864, 0.30758270621299744),\n",
       " (2587, 0.30744025111198425),\n",
       " (2916, 0.30738914012908936),\n",
       " (3010, 0.3072717487812042),\n",
       " (3790, 0.3072300851345062),\n",
       " (617, 0.30678075551986694),\n",
       " (3738, 0.30617964267730713),\n",
       " (1386, 0.30592605471611023),\n",
       " (1430, 0.30588677525520325),\n",
       " (2422, 0.3050526976585388),\n",
       " (3615, 0.305001437664032),\n",
       " (3421, 0.3049098551273346),\n",
       " (2581, 0.3034414052963257),\n",
       " (3925, 0.3022941052913666),\n",
       " (3109, 0.30187204480171204),\n",
       " (213, 0.30182206630706787),\n",
       " (3983, 0.30175599455833435),\n",
       " (2172, 0.30020320415496826),\n",
       " (2502, 0.30010369420051575),\n",
       " (1973, 0.2998601496219635),\n",
       " (2682, 0.29947781562805176),\n",
       " (129, 0.298440158367157),\n",
       " (62, 0.29838213324546814),\n",
       " (2124, 0.29707780480384827),\n",
       " (3558, 0.29641133546829224),\n",
       " (1403, 0.2962872087955475),\n",
       " (481, 0.2955213785171509),\n",
       " (3333, 0.2951567769050598),\n",
       " (3426, 0.2943405508995056),\n",
       " (2893, 0.29246872663497925),\n",
       " (2621, 0.29229575395584106),\n",
       " (1220, 0.2916554808616638),\n",
       " (2204, 0.29116666316986084),\n",
       " (3675, 0.2911625802516937),\n",
       " (3398, 0.2904926836490631),\n",
       " (3270, 0.2896234393119812),\n",
       " (1842, 0.28846338391304016),\n",
       " (74, 0.2882283926010132),\n",
       " (2573, 0.2879635989665985),\n",
       " (678, 0.28781312704086304),\n",
       " (2637, 0.28769034147262573),\n",
       " (2911, 0.28743112087249756),\n",
       " (352, 0.2870643138885498),\n",
       " (3198, 0.2869901657104492),\n",
       " (3191, 0.2865247130393982),\n",
       " (3345, 0.2857098877429962),\n",
       " (3750, 0.285620778799057),\n",
       " (1326, 0.28473928570747375),\n",
       " (474, 0.28467875719070435),\n",
       " (2159, 0.2843537926673889),\n",
       " (2520, 0.28419309854507446),\n",
       " (2029, 0.28396838903427124),\n",
       " (2451, 0.2837388813495636),\n",
       " (1958, 0.28369593620300293),\n",
       " (2622, 0.28327327966690063),\n",
       " (3623, 0.2822340726852417),\n",
       " (2417, 0.28222599625587463),\n",
       " (1049, 0.28155526518821716),\n",
       " (1615, 0.2810133099555969),\n",
       " (2222, 0.28082075715065),\n",
       " (687, 0.2806878089904785),\n",
       " (356, 0.2802111506462097),\n",
       " (3292, 0.2801598310470581),\n",
       " (987, 0.2799553871154785),\n",
       " (3318, 0.2797749638557434),\n",
       " (3365, 0.27965307235717773),\n",
       " (2671, 0.2789098918437958),\n",
       " (2649, 0.2788345515727997),\n",
       " (2034, 0.278778612613678),\n",
       " (1004, 0.27866506576538086),\n",
       " (2035, 0.2785761058330536),\n",
       " (3237, 0.27784010767936707),\n",
       " (1550, 0.2773084342479706),\n",
       " (1025, 0.2770382761955261),\n",
       " (633, 0.27607211470603943),\n",
       " (1498, 0.27572429180145264),\n",
       " (782, 0.2757066488265991),\n",
       " (2212, 0.27560070157051086),\n",
       " (3341, 0.2754546105861664),\n",
       " (2306, 0.2751534581184387),\n",
       " (2677, 0.27462902665138245),\n",
       " (91, 0.27418726682662964),\n",
       " (3290, 0.2739034593105316),\n",
       " (48, 0.27311792969703674),\n",
       " (768, 0.2727974057197571),\n",
       " (253, 0.27234745025634766),\n",
       " (2984, 0.2719661593437195),\n",
       " (727, 0.2717928886413574),\n",
       " (3514, 0.27176037430763245),\n",
       " (1505, 0.2712273597717285),\n",
       " (1774, 0.2711520493030548),\n",
       " (349, 0.2708459198474884),\n",
       " (953, 0.2707862854003906),\n",
       " (2589, 0.27056455612182617),\n",
       " (1449, 0.26933276653289795),\n",
       " (521, 0.269275426864624),\n",
       " (2726, 0.26894107460975647),\n",
       " (2990, 0.26809072494506836),\n",
       " (943, 0.2680196166038513),\n",
       " (2256, 0.26762545108795166),\n",
       " (1360, 0.2675042450428009),\n",
       " (2716, 0.2674659788608551),\n",
       " (366, 0.2674393653869629),\n",
       " (655, 0.2674393653869629),\n",
       " (659, 0.2674393653869629),\n",
       " (1483, 0.2664840817451477),\n",
       " (933, 0.2660446763038635),\n",
       " (411, 0.26515549421310425),\n",
       " (3718, 0.26508602499961853),\n",
       " (1589, 0.26494765281677246),\n",
       " (275, 0.26483482122421265),\n",
       " (3808, 0.2645435631275177),\n",
       " (1192, 0.2637741267681122),\n",
       " (2481, 0.2636783719062805),\n",
       " (2061, 0.2636413872241974),\n",
       " (1084, 0.2632198929786682),\n",
       " (3526, 0.26313310861587524),\n",
       " (3941, 0.26242077350616455),\n",
       " (1173, 0.26193857192993164),\n",
       " (3844, 0.26150935888290405),\n",
       " (1060, 0.26150786876678467),\n",
       " (3267, 0.2609104812145233),\n",
       " (1735, 0.26067638397216797),\n",
       " (3441, 0.2606542706489563),\n",
       " (236, 0.2601310610771179),\n",
       " (1464, 0.26004093885421753),\n",
       " (1069, 0.25992822647094727),\n",
       " (672, 0.2592594623565674),\n",
       " (3766, 0.2592189311981201),\n",
       " (1695, 0.2590630054473877),\n",
       " (3062, 0.25893089175224304),\n",
       " (2584, 0.25873029232025146),\n",
       " (1356, 0.25814419984817505),\n",
       " (3116, 0.25765275955200195),\n",
       " (2455, 0.25722435116767883),\n",
       " (1893, 0.25714942812919617),\n",
       " (1426, 0.25706028938293457),\n",
       " (3509, 0.2569000720977783),\n",
       " (1886, 0.2564515769481659),\n",
       " (1089, 0.2563985586166382),\n",
       " (2508, 0.2554837465286255),\n",
       " (1588, 0.25514593720436096),\n",
       " (2482, 0.25465965270996094),\n",
       " (3159, 0.2544972002506256),\n",
       " (3367, 0.25446733832359314),\n",
       " (3132, 0.25408485531806946),\n",
       " (2607, 0.2539248764514923),\n",
       " (2376, 0.2538304626941681),\n",
       " (75, 0.2535874843597412),\n",
       " (313, 0.2535874843597412),\n",
       " (602, 0.2535874843597412),\n",
       " (1081, 0.2535874843597412),\n",
       " (2393, 0.2535874843597412),\n",
       " (2424, 0.2535874843597412),\n",
       " (3652, 0.2518194913864136),\n",
       " (831, 0.2518148124217987),\n",
       " (2719, 0.25172334909439087),\n",
       " (3138, 0.25168389081954956),\n",
       " (866, 0.25130027532577515),\n",
       " (2208, 0.2512374222278595),\n",
       " (1648, 0.2508852183818817),\n",
       " (2013, 0.2508668899536133),\n",
       " (3382, 0.2501348853111267),\n",
       " (1817, 0.25001364946365356),\n",
       " (2348, 0.2499937117099762),\n",
       " (1883, 0.2499869465827942),\n",
       " (2755, 0.2497839629650116),\n",
       " (3950, 0.24956969916820526),\n",
       " (2136, 0.24919697642326355),\n",
       " (484, 0.24916356801986694),\n",
       " (1040, 0.24908605217933655),\n",
       " (2967, 0.24904105067253113),\n",
       " (1839, 0.24870653450489044),\n",
       " (3846, 0.24828317761421204),\n",
       " (3269, 0.24792136251926422),\n",
       " (3359, 0.24718521535396576),\n",
       " (2619, 0.2458137571811676),\n",
       " (3108, 0.2457445114850998),\n",
       " (3890, 0.24524830281734467),\n",
       " (2835, 0.2449996918439865),\n",
       " (3343, 0.2448684126138687),\n",
       " (1974, 0.24424636363983154),\n",
       " (3702, 0.24396878480911255),\n",
       " (2139, 0.24357236921787262),\n",
       " (3259, 0.24353143572807312),\n",
       " (308, 0.2433285117149353),\n",
       " (537, 0.24305561184883118),\n",
       " (3311, 0.241876482963562),\n",
       " (3058, 0.24174898862838745),\n",
       " (3543, 0.24151082336902618),\n",
       " (456, 0.241313636302948),\n",
       " (413, 0.24033653736114502),\n",
       " (3454, 0.2400859296321869),\n",
       " (950, 0.24007722735404968),\n",
       " (3751, 0.24005399644374847),\n",
       " (1640, 0.23931878805160522),\n",
       " (3164, 0.23930281400680542),\n",
       " (3898, 0.23926027119159698),\n",
       " (690, 0.23859752714633942),\n",
       " (1902, 0.23805159330368042),\n",
       " (3154, 0.2370111644268036),\n",
       " (2817, 0.23687607049942017),\n",
       " (2193, 0.2367793619632721),\n",
       " (724, 0.23612546920776367),\n",
       " (1470, 0.2359272837638855),\n",
       " (1738, 0.23551973700523376),\n",
       " (533, 0.23548948764801025),\n",
       " (1638, 0.23520486056804657),\n",
       " (2093, 0.23495715856552124),\n",
       " (2271, 0.23483861982822418),\n",
       " (2225, 0.23464012145996094),\n",
       " (2210, 0.2338702380657196),\n",
       " (3582, 0.23314684629440308),\n",
       " (3430, 0.23308895528316498),\n",
       " (2343, 0.23301896452903748),\n",
       " (1397, 0.23284517228603363),\n",
       " (3257, 0.2328421026468277),\n",
       " (1034, 0.23255126178264618),\n",
       " (3397, 0.23245282471179962),\n",
       " (3572, 0.23244012892246246),\n",
       " (857, 0.23238015174865723),\n",
       " (1736, 0.23180469870567322),\n",
       " (1705, 0.2316213995218277),\n",
       " (1257, 0.2315102368593216),\n",
       " (3262, 0.23132647573947906),\n",
       " (575, 0.23113298416137695),\n",
       " (2535, 0.23112785816192627),\n",
       " (1800, 0.23087556660175323),\n",
       " (621, 0.23044556379318237),\n",
       " (2943, 0.2302333414554596),\n",
       " (1167, 0.23013833165168762),\n",
       " (3732, 0.22994273900985718),\n",
       " (3073, 0.22986051440238953),\n",
       " (2290, 0.22979426383972168),\n",
       " (160, 0.22952690720558167),\n",
       " (3901, 0.22951418161392212),\n",
       " (3547, 0.22916960716247559),\n",
       " (1775, 0.22901754081249237),\n",
       " (159, 0.22901341319084167),\n",
       " (1663, 0.22848355770111084),\n",
       " (3842, 0.2281816452741623),\n",
       " (1172, 0.2279939204454422),\n",
       " (2203, 0.22775810956954956),\n",
       " (1900, 0.22713983058929443),\n",
       " (2177, 0.22669294476509094),\n",
       " (2728, 0.22651731967926025),\n",
       " (3975, 0.22639212012290955),\n",
       " (703, 0.2257600873708725),\n",
       " (2596, 0.22558799386024475),\n",
       " (418, 0.2255159616470337),\n",
       " (2474, 0.22548410296440125),\n",
       " (1185, 0.22548064589500427),\n",
       " (133, 0.2251981645822525),\n",
       " (1547, 0.22482538223266602),\n",
       " (2020, 0.22478538751602173),\n",
       " (2314, 0.22462990880012512),\n",
       " (1634, 0.22437229752540588),\n",
       " (1617, 0.2232489138841629),\n",
       " (2416, 0.2231529951095581),\n",
       " (663, 0.22271835803985596),\n",
       " (1751, 0.22266338765621185),\n",
       " (3585, 0.2223040610551834),\n",
       " (3953, 0.22226113080978394),\n",
       " (189, 0.22181126475334167),\n",
       " (2295, 0.2216913402080536),\n",
       " (3669, 0.22151580452919006),\n",
       " (2036, 0.22117364406585693),\n",
       " (1270, 0.220921590924263),\n",
       " (3261, 0.22089916467666626),\n",
       " (1740, 0.22025121748447418),\n",
       " (3497, 0.21954327821731567),\n",
       " (2765, 0.21940447390079498),\n",
       " (3124, 0.2190392017364502),\n",
       " (2466, 0.21893076598644257),\n",
       " (3862, 0.21892955899238586),\n",
       " (1812, 0.218686044216156),\n",
       " (238, 0.21854494512081146),\n",
       " (2303, 0.2182200402021408),\n",
       " (2791, 0.2181483954191208),\n",
       " (3676, 0.21786196529865265),\n",
       " (1210, 0.21775372326374054),\n",
       " (581, 0.21743062138557434),\n",
       " (391, 0.21701186895370483),\n",
       " (1595, 0.2163715809583664),\n",
       " (3226, 0.21628278493881226),\n",
       " (1718, 0.21626630425453186),\n",
       " (2617, 0.21619723737239838),\n",
       " (3739, 0.21595367789268494),\n",
       " (848, 0.21489517390727997),\n",
       " (3655, 0.21478477120399475),\n",
       " (2590, 0.2142978012561798),\n",
       " (2897, 0.21427813172340393),\n",
       " (3661, 0.21425941586494446),\n",
       " (1250, 0.21413567662239075),\n",
       " (3851, 0.2137650102376938),\n",
       " (3969, 0.21336330473423004),\n",
       " (3920, 0.21292473375797272),\n",
       " (3632, 0.21256376802921295),\n",
       " (2187, 0.2119205892086029),\n",
       " (288, 0.21136091649532318),\n",
       " (3175, 0.21114686131477356),\n",
       " (2679, 0.21101880073547363),\n",
       " (2704, 0.2107679545879364),\n",
       " (2236, 0.21056899428367615),\n",
       " (2524, 0.21050438284873962),\n",
       " (2611, 0.2102401703596115),\n",
       " (706, 0.20999455451965332),\n",
       " (1849, 0.2099582850933075),\n",
       " (3839, 0.20972374081611633),\n",
       " (3937, 0.20958396792411804),\n",
       " (2583, 0.20911012589931488),\n",
       " (629, 0.20906880497932434),\n",
       " (196, 0.20889189839363098),\n",
       " (1624, 0.2088504433631897),\n",
       " (2050, 0.20857417583465576),\n",
       " (1079, 0.20855817198753357),\n",
       " (323, 0.20846068859100342),\n",
       " (449, 0.2081509828567505),\n",
       " (686, 0.20794659852981567),\n",
       " (2326, 0.2078905552625656),\n",
       " (2789, 0.20786383748054504),\n",
       " (2233, 0.2077859342098236),\n",
       " (3923, 0.20728003978729248),\n",
       " (1574, 0.2069999724626541),\n",
       " (3880, 0.20682457089424133),\n",
       " (3344, 0.2067261040210724),\n",
       " (1867, 0.2067108005285263),\n",
       " (1878, 0.20669712126255035),\n",
       " (98, 0.2057695835828781),\n",
       " (1016, 0.20575465261936188),\n",
       " (2356, 0.2056627869606018),\n",
       " (1190, 0.20562197268009186),\n",
       " (1418, 0.20548619329929352),\n",
       " (3947, 0.2051849663257599),\n",
       " (976, 0.20514154434204102),\n",
       " (3011, 0.2051171064376831),\n",
       " (1419, 0.20511594414710999),\n",
       " (1692, 0.20485955476760864),\n",
       " (1522, 0.20478372275829315),\n",
       " (2028, 0.20478372275829315),\n",
       " (2231, 0.20478372275829315),\n",
       " (2388, 0.20478372275829315),\n",
       " (2707, 0.20478372275829315),\n",
       " (3192, 0.20478372275829315),\n",
       " (3214, 0.20478372275829315),\n",
       " (3868, 0.20467278361320496),\n",
       " (3803, 0.20435434579849243),\n",
       " (2337, 0.20393507182598114),\n",
       " (1628, 0.20341217517852783),\n",
       " (2080, 0.2032041698694229),\n",
       " (3052, 0.2028815746307373),\n",
       " (164, 0.20277139544487),\n",
       " (403, 0.2027224600315094),\n",
       " (3408, 0.20262013375759125),\n",
       " (1100, 0.20249013602733612),\n",
       " (3556, 0.20245975255966187),\n",
       " (693, 0.20201271772384644),\n",
       " (1131, 0.20184054970741272),\n",
       " (946, 0.20182809233665466),\n",
       " (157, 0.2018168419599533),\n",
       " (1970, 0.20177555084228516),\n",
       " (283, 0.20165881514549255),\n",
       " (2876, 0.2009645700454712),\n",
       " (3945, 0.200792595744133),\n",
       " (725, 0.20070502161979675),\n",
       " (3337, 0.20009508728981018),\n",
       " (960, 0.19987882673740387),\n",
       " (694, 0.19943398237228394),\n",
       " (23, 0.1992921680212021),\n",
       " (3549, 0.19911935925483704),\n",
       " (2825, 0.19892428815364838),\n",
       " (1651, 0.19889292120933533),\n",
       " (3942, 0.19875183701515198),\n",
       " (2040, 0.19759738445281982),\n",
       " (3065, 0.19754987955093384),\n",
       " (1639, 0.19727465510368347),\n",
       " (1677, 0.19720888137817383),\n",
       " (1601, 0.19715481996536255),\n",
       " (2784, 0.19712959229946136),\n",
       " (774, 0.19685852527618408),\n",
       " (220, 0.19660720229148865),\n",
       " (1283, 0.19659793376922607),\n",
       " (1662, 0.19659793376922607),\n",
       " (2413, 0.19659793376922607),\n",
       " (260, 0.19643890857696533),\n",
       " (1184, 0.19643434882164001),\n",
       " (675, 0.19638952612876892),\n",
       " (1860, 0.19607487320899963),\n",
       " (3845, 0.19597819447517395),\n",
       " (2009, 0.19561827182769775),\n",
       " (716, 0.19542554020881653),\n",
       " (1495, 0.19532105326652527),\n",
       " (1988, 0.1953044831752777),\n",
       " (2901, 0.19518589973449707),\n",
       " (3536, 0.1950003206729889),\n",
       " (2033, 0.1948697417974472),\n",
       " (1333, 0.19430312514305115),\n",
       " (3720, 0.19404272735118866),\n",
       " (405, 0.19356100261211395),\n",
       " (2105, 0.19328303635120392),\n",
       " (3570, 0.1932394653558731),\n",
       " (2722, 0.19315247237682343),\n",
       " (758, 0.1925896257162094),\n",
       " (2559, 0.19227787852287292),\n",
       " (803, 0.1922699213027954),\n",
       " (2382, 0.19191932678222656),\n",
       " (2770, 0.19191057980060577),\n",
       " (2307, 0.19173769652843475),\n",
       " (1234, 0.1915695071220398),\n",
       " (597, 0.19151288270950317),\n",
       " (1943, 0.19144681096076965),\n",
       " (1309, 0.19084720313549042),\n",
       " (3612, 0.19067949056625366),\n",
       " (2626, 0.19054466485977173),\n",
       " (582, 0.19021384418010712),\n",
       " (3070, 0.1900774985551834),\n",
       " (551, 0.18992596864700317),\n",
       " (1209, 0.18988075852394104),\n",
       " (401, 0.1898048371076584),\n",
       " (333, 0.18975268304347992),\n",
       " (2763, 0.18945464491844177),\n",
       " (545, 0.18940988183021545),\n",
       " (3431, 0.18924842774868011),\n",
       " (3393, 0.18919974565505981),\n",
       " (3096, 0.1891721487045288),\n",
       " (1660, 0.18888327479362488),\n",
       " (3287, 0.18881107866764069),\n",
       " (2006, 0.1886298507452011),\n",
       " (2894, 0.18853455781936646),\n",
       " (414, 0.18853367865085602),\n",
       " (2059, 0.18850460648536682),\n",
       " (365, 0.18828299641609192),\n",
       " (1725, 0.1881100833415985),\n",
       " (583, 0.18785929679870605),\n",
       " (3313, 0.18780860304832458),\n",
       " (2614, 0.18734335899353027),\n",
       " (2363, 0.1873359978199005),\n",
       " (3489, 0.1873355209827423),\n",
       " (1122, 0.1865965574979782),\n",
       " (3358, 0.18648895621299744),\n",
       " (2871, 0.18644988536834717),\n",
       " (1251, 0.18622031807899475),\n",
       " (2042, 0.1860814392566681),\n",
       " (1564, 0.18588793277740479),\n",
       " (2418, 0.18551763892173767),\n",
       " (712, 0.18546535074710846),\n",
       " (3106, 0.18526890873908997),\n",
       " (3076, 0.18515394628047943),\n",
       " (2595, 0.18502411246299744),\n",
       " (1674, 0.18482013046741486),\n",
       " (1116, 0.18475820124149323),\n",
       " (3491, 0.18442197144031525),\n",
       " (1604, 0.18439050018787384),\n",
       " (1310, 0.18422532081604004),\n",
       " (1002, 0.18398018181324005),\n",
       " (3695, 0.18383634090423584),\n",
       " (3395, 0.18358927965164185),\n",
       " (178, 0.1834927350282669),\n",
       " (3886, 0.1830819547176361),\n",
       " (318, 0.18268701434135437),\n",
       " (541, 0.1823580414056778),\n",
       " (2530, 0.18230314552783966),\n",
       " (259, 0.1820564717054367),\n",
       " (919, 0.18197789788246155),\n",
       " (2319, 0.1818629503250122),\n",
       " (2795, 0.18110889196395874),\n",
       " (2553, 0.1808476597070694),\n",
       " (1597, 0.18080100417137146),\n",
       " (375, 0.1806512027978897),\n",
       " (528, 0.18045367300510406),\n",
       " (258, 0.18040242791175842),\n",
       " (2987, 0.18034079670906067),\n",
       " (3921, 0.180323988199234),\n",
       " (3663, 0.1801685094833374),\n",
       " (2863, 0.1800926923751831),\n",
       " (2088, 0.17997166514396667),\n",
       " (3664, 0.17983375489711761),\n",
       " (3435, 0.17979054152965546),\n",
       " (3610, 0.17970509827136993),\n",
       " (2489, 0.17952841520309448),\n",
       " (127, 0.17909055948257446),\n",
       " (364, 0.1788385510444641),\n",
       " (3922, 0.17877119779586792),\n",
       " (2189, 0.17833730578422546),\n",
       " (2991, 0.17831844091415405),\n",
       " (1913, 0.17824769020080566),\n",
       " (1834, 0.17789016664028168),\n",
       " (1409, 0.17784331738948822),\n",
       " (3840, 0.17759035527706146),\n",
       " (327, 0.1775466799736023),\n",
       " (4, 0.1772681623697281),\n",
       " (1227, 0.17718607187271118),\n",
       " (1371, 0.17714114487171173),\n",
       " (2969, 0.17703121900558472),\n",
       " (1926, 0.17699813842773438),\n",
       " (507, 0.1769929826259613),\n",
       " (2138, 0.17690619826316833),\n",
       " (2148, 0.17626827955245972),\n",
       " (2900, 0.17601598799228668),\n",
       " (523, 0.17596301436424255),\n",
       " (3885, 0.1755954623222351),\n",
       " (3966, 0.17548322677612305),\n",
       " (132, 0.17523355782032013),\n",
       " (626, 0.17496037483215332),\n",
       " (1941, 0.17395922541618347),\n",
       " (2056, 0.1739114224910736),\n",
       " (3552, 0.17364083230495453),\n",
       " (3117, 0.17360202968120575),\n",
       " (3635, 0.17359042167663574),\n",
       " (1298, 0.17358407378196716),\n",
       " (3757, 0.1735670566558838),\n",
       " (3891, 0.17337700724601746),\n",
       " (2332, 0.17324985563755035),\n",
       " (390, 0.17293643951416016),\n",
       " (2568, 0.1728687584400177),\n",
       " (3112, 0.17267996072769165),\n",
       " (3455, 0.17265962064266205),\n",
       " (3013, 0.17251692712306976),\n",
       " (3794, 0.1724703162908554),\n",
       " (1901, 0.17245471477508545),\n",
       " (1225, 0.1721612811088562),\n",
       " (3546, 0.17207422852516174),\n",
       " (3302, 0.172011137008667),\n",
       " (1058, 0.17112770676612854),\n",
       " (3182, 0.17102967202663422),\n",
       " (3438, 0.1709812432527542),\n",
       " (3312, 0.170729860663414),\n",
       " (2446, 0.1706664115190506),\n",
       " (3554, 0.17063474655151367),\n",
       " (255, 0.17028069496154785),\n",
       " (212, 0.16961108148097992),\n",
       " (3986, 0.16960100829601288),\n",
       " (977, 0.16956552863121033),\n",
       " (918, 0.1695641577243805),\n",
       " (1750, 0.169464573264122),\n",
       " (2738, 0.1693461388349533),\n",
       " (1263, 0.1688932478427887),\n",
       " (2531, 0.1687946617603302),\n",
       " (1632, 0.16878144443035126),\n",
       " (498, 0.1681745946407318),\n",
       " (2067, 0.1681598722934723),\n",
       " (2367, 0.1681157350540161),\n",
       " (2350, 0.16791822016239166),\n",
       " (949, 0.167844757437706),\n",
       " (3667, 0.1678086519241333),\n",
       " (1307, 0.1675720512866974),\n",
       " (509, 0.1675523966550827),\n",
       " (230, 0.16750724613666534),\n",
       " (442, 0.1673375964164734),\n",
       " (2533, 0.16728883981704712),\n",
       " (2323, 0.16721394658088684),\n",
       " (2196, 0.16698575019836426),\n",
       " (2846, 0.16695541143417358),\n",
       " (2270, 0.16687577962875366),\n",
       " (2764, 0.1668735295534134),\n",
       " (2048, 0.16654270887374878),\n",
       " (2702, 0.1663438379764557),\n",
       " (3801, 0.16625992953777313),\n",
       " (559, 0.16618718206882477),\n",
       " (2831, 0.16596485674381256),\n",
       " (2351, 0.16574151813983917),\n",
       " (1879, 0.16563621163368225),\n",
       " (1880, 0.16551753878593445),\n",
       " (201, 0.1650940477848053),\n",
       " (2954, 0.1649969071149826),\n",
       " (3613, 0.16462242603302002),\n",
       " (2209, 0.16453884541988373),\n",
       " (1583, 0.16427265107631683),\n",
       " (1396, 0.16415879130363464),\n",
       " (278, 0.16399794816970825),\n",
       " (1698, 0.1638568788766861),\n",
       " (711, 0.1636597365140915),\n",
       " (554, 0.1635603904724121),\n",
       " (3255, 0.16324380040168762),\n",
       " (902, 0.16324014961719513),\n",
       " (372, 0.1631798893213272),\n",
       " (3641, 0.16309690475463867),\n",
       " (3074, 0.1626889556646347),\n",
       " (3633, 0.16248975694179535),\n",
       " (939, 0.16227316856384277),\n",
       " (658, 0.16225190460681915),\n",
       " (1721, 0.1619875133037567),\n",
       " ...]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_surprise={}\n",
    "for key, value in sorted_surprise:\n",
    "    if value>0.5:\n",
    "        high_surprise[key]=value\n",
    "len(high_surprise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Think of these lesser-known places before you book your next vacation.'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb_reactions.iloc[3872]['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Once you cook salmon like this, you'll never want it any other way.\""
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb_reactions.iloc[3255]['message']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Importing Semeval</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "semeval_emotions=pd.read_csv('data/semeval_emotions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "semeval_emotions.rename({'0': 0, '1': 1}, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "isear_plus_semeval=isear.append(semeval_emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joy</td>\n",
       "      <td>On days when I feel close to my partner and ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>Every time I imagine that someone I love or I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>When I had been obviously unjustly treated and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When I think about the short time that we live...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>joy</td>\n",
       "      <td>After my girlfriend had taken her exam we went...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fear</td>\n",
       "      <td>When, for the first time I realized the meanin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>anger</td>\n",
       "      <td>When a car is overtaking another and I am forc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When I recently thought about the hard work it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>joy</td>\n",
       "      <td>When I pass an examination which I did not thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fear</td>\n",
       "      <td>When one has arranged to meet someone and that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>anger</td>\n",
       "      <td>When one is unjustly accused of something one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When one's studies seem hopelessly difficult a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>joy</td>\n",
       "      <td>Passing an exam I did not expect to pass.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>fear</td>\n",
       "      <td>When I climbed up a tree to pick apples.  The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>joy</td>\n",
       "      <td>When I had my children.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>fear</td>\n",
       "      <td>When my 2 year old son climbed up and sat on t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>anger</td>\n",
       "      <td>When my partner was attacked and lost three te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When I see children on T.V from areas devastat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>joy</td>\n",
       "      <td>When my child was born.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>fear</td>\n",
       "      <td>It was spring and the ice was melting.  I was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>anger</td>\n",
       "      <td>Unjust accusations directed at me and my way o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Failing an examination.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>joy</td>\n",
       "      <td>When I saw a person I had not seen for a long ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>fear</td>\n",
       "      <td>When, as a child, I was nearly knocked down by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>anger</td>\n",
       "      <td>When I heard on the radio that the football ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When I feel lonely, perhaps because I have to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>joy</td>\n",
       "      <td>When I was accepted for a course on finance an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>fear</td>\n",
       "      <td>A bus drove over my right leg.  The event itse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>anger</td>\n",
       "      <td>At my Summer job, nobody looked after me in pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When I was not accepted as a student in financ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>sadness</td>\n",
       "      <td>i got his bitch depress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Really planned on making videos this week. The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2700</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Regret for the things we did can be tempered b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>sadness</td>\n",
       "      <td>im having the worst week ever and i cant even ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2702</th>\n",
       "      <td>sadness</td>\n",
       "      <td>we never taste happiness in perfection, our mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2703</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Whenever I'm feeling sad I will listen to mons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Another grim &amp;amp; compelling news report by @...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Absolutely hate the Apple Watch iOS 10 update....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>sadness</td>\n",
       "      <td>@TNFryed Jesus, you just made think that of al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Never ever been this unhappy before in my life...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2708</th>\n",
       "      <td>sadness</td>\n",
       "      <td>@GRIPLIKEAVICE_ I wouldn't mind if it didn't y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2709</th>\n",
       "      <td>sadness</td>\n",
       "      <td>@flybe Doesn't explain the ability to land at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2710</th>\n",
       "      <td>sadness</td>\n",
       "      <td>@FoxNews Very thought provoking &amp;amp; leads on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2711</th>\n",
       "      <td>sadness</td>\n",
       "      <td>I miss when social media was a place to get la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712</th>\n",
       "      <td>sadness</td>\n",
       "      <td>My encouragement today is my dog while my head...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2713</th>\n",
       "      <td>sadness</td>\n",
       "      <td>@pureleine though lately with how bad my depre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714</th>\n",
       "      <td>sadness</td>\n",
       "      <td>now im all alone and my joy's turned to moping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>sadness</td>\n",
       "      <td>I hate when it's gloomy outside because it alw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2716</th>\n",
       "      <td>sadness</td>\n",
       "      <td>So unbelievably discouraged with music as of l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2717</th>\n",
       "      <td>sadness</td>\n",
       "      <td>@charles_gaba No, I am probably the person mos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2718</th>\n",
       "      <td>sadness</td>\n",
       "      <td>the sad moment when u hand in an exam knowing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2719</th>\n",
       "      <td>sadness</td>\n",
       "      <td>@keyshamackie it's fucking dreadful for live f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2720</th>\n",
       "      <td>sadness</td>\n",
       "      <td>@narcissusheiyan  maybe it'd have been differe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2721</th>\n",
       "      <td>sadness</td>\n",
       "      <td>It's sad when your man leaves work a little bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2722</th>\n",
       "      <td>sadness</td>\n",
       "      <td>My friends tell me I'm pretty. Trigger tells m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2723</th>\n",
       "      <td>sadness</td>\n",
       "      <td>@CrystiCaro yeah agree - I think it was a fami...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>sadness</td>\n",
       "      <td>@wabermes The @RavalliRepublic had a good one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>sadness</td>\n",
       "      <td>If Troyler will die, I'm gonna die with them\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2726</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Overwhelming sadness.  This too shall pass. #l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Idk why people be glorifying depression. I wou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7057 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0                                                  1\n",
       "0         joy  On days when I feel close to my partner and ot...\n",
       "1        fear  Every time I imagine that someone I love or I ...\n",
       "2       anger  When I had been obviously unjustly treated and...\n",
       "3     sadness  When I think about the short time that we live...\n",
       "7         joy  After my girlfriend had taken her exam we went...\n",
       "8        fear  When, for the first time I realized the meanin...\n",
       "9       anger  When a car is overtaking another and I am forc...\n",
       "10    sadness  When I recently thought about the hard work it...\n",
       "14        joy  When I pass an examination which I did not thi...\n",
       "15       fear  When one has arranged to meet someone and that...\n",
       "16      anger  When one is unjustly accused of something one ...\n",
       "17    sadness  When one's studies seem hopelessly difficult a...\n",
       "21        joy          Passing an exam I did not expect to pass.\n",
       "22       fear  When I climbed up a tree to pick apples.  The ...\n",
       "24        joy                            When I had my children.\n",
       "25       fear  When my 2 year old son climbed up and sat on t...\n",
       "26      anger  When my partner was attacked and lost three te...\n",
       "27    sadness  When I see children on T.V from areas devastat...\n",
       "31        joy                            When my child was born.\n",
       "32       fear  It was spring and the ice was melting.  I was ...\n",
       "33      anger  Unjust accusations directed at me and my way o...\n",
       "34    sadness                            Failing an examination.\n",
       "38        joy  When I saw a person I had not seen for a long ...\n",
       "39       fear  When, as a child, I was nearly knocked down by...\n",
       "40      anger  When I heard on the radio that the football ma...\n",
       "41    sadness  When I feel lonely, perhaps because I have to ...\n",
       "45        joy  When I was accepted for a course on finance an...\n",
       "46       fear  A bus drove over my right leg.  The event itse...\n",
       "47      anger  At my Summer job, nobody looked after me in pa...\n",
       "48    sadness  When I was not accepted as a student in financ...\n",
       "...       ...                                                ...\n",
       "2698  sadness                            i got his bitch depress\n",
       "2699  sadness  Really planned on making videos this week. The...\n",
       "2700  sadness  Regret for the things we did can be tempered b...\n",
       "2701  sadness  im having the worst week ever and i cant even ...\n",
       "2702  sadness  we never taste happiness in perfection, our mo...\n",
       "2703  sadness  Whenever I'm feeling sad I will listen to mons...\n",
       "2704  sadness  Another grim &amp; compelling news report by @...\n",
       "2705  sadness  Absolutely hate the Apple Watch iOS 10 update....\n",
       "2706  sadness  @TNFryed Jesus, you just made think that of al...\n",
       "2707  sadness  Never ever been this unhappy before in my life...\n",
       "2708  sadness  @GRIPLIKEAVICE_ I wouldn't mind if it didn't y...\n",
       "2709  sadness  @flybe Doesn't explain the ability to land at ...\n",
       "2710  sadness  @FoxNews Very thought provoking &amp; leads on...\n",
       "2711  sadness  I miss when social media was a place to get la...\n",
       "2712  sadness  My encouragement today is my dog while my head...\n",
       "2713  sadness  @pureleine though lately with how bad my depre...\n",
       "2714  sadness     now im all alone and my joy's turned to moping\n",
       "2715  sadness  I hate when it's gloomy outside because it alw...\n",
       "2716  sadness  So unbelievably discouraged with music as of l...\n",
       "2717  sadness  @charles_gaba No, I am probably the person mos...\n",
       "2718  sadness  the sad moment when u hand in an exam knowing ...\n",
       "2719  sadness  @keyshamackie it's fucking dreadful for live f...\n",
       "2720  sadness  @narcissusheiyan  maybe it'd have been differe...\n",
       "2721  sadness  It's sad when your man leaves work a little bi...\n",
       "2722  sadness  My friends tell me I'm pretty. Trigger tells m...\n",
       "2723  sadness  @CrystiCaro yeah agree - I think it was a fami...\n",
       "2724  sadness  @wabermes The @RavalliRepublic had a good one ...\n",
       "2725  sadness  If Troyler will die, I'm gonna die with them\\n...\n",
       "2726  sadness  Overwhelming sadness.  This too shall pass. #l...\n",
       "2727  sadness  Idk why people be glorifying depression. I wou...\n",
       "\n",
       "[7057 rows x 2 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isear_plus_semeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_duplicator_train(text):\n",
    "    splits=text.split(' ')\n",
    "    while len(splits)<7:\n",
    "        orig_doc=splits.copy()\n",
    "        for word in orig_doc:\n",
    "            splits.append(word)\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=isear_plus_semeval[1].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=isear_plus_semeval[1].apply(input_duplicator_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['One',\n",
       " 'Saturday',\n",
       " 'morning',\n",
       " 'I',\n",
       " 'had',\n",
       " 'got',\n",
       " 'ready',\n",
       " 'to',\n",
       " 'go',\n",
       " 'out',\n",
       " 'swimming',\n",
       " 'with',\n",
       " 'my',\n",
       " '',\n",
       " '\\nfriends.',\n",
       " '',\n",
       " 'Unfortunately',\n",
       " 'the',\n",
       " 'weather',\n",
       " 'did',\n",
       " 'not',\n",
       " 'permit',\n",
       " 'it,',\n",
       " 'so',\n",
       " 'we',\n",
       " '',\n",
       " '\\nstayed',\n",
       " 'indoors.']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[2678]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1, y_1=transform_t6_train(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=LabelEncoder()\n",
    "encoder.fit(y_1)\n",
    "y_1=encoder.transform(y_1)\n",
    "y_1=np_utils.to_categorical(y_1)\n",
    "y_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_1, y_1, test_size = 0.2, random_state = 0)\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Further options</h3>\n",
    "\n",
    "I could \n",
    "\n",
    "1.Gather and combine many emotional labelled datasets to have larger training data\n",
    "\n",
    "2.Create new training data synthetically\n",
    "\n",
    "3.Create labelled data using word averages (auto-labelling) data\n",
    "\n",
    "4.Use Indico to get around 10,000 more labelled training data rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Idea:</strong>Duplicate input if length of input too short\n",
    "\n",
    "<strong>Idea:</strong>Branch out to several models depending on input size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Indico's emotions</strong>:\n",
    "Anger, Fear, Joy, Sadness, Surprise\n",
    "\n",
    "<strong>ISEAR's emotions</strong>: Anger, Fear, Joy, Sadness, Disgust, Shame, Guilt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four emotions:\n",
    "Anger, Fear, Joy, Sadness\n",
    "\n",
    "Disgust goes with Anger, Surprise goes with Fear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Plan for API</h3>\n",
    "\n",
    "1.For now, retrain model with just four emotions. Use ISEAR and Semeval for better accuracy. Redeploy with good formatting\n",
    "\n",
    "2.For the future, \n",
    "Download facebook data tagged with 'Wow' emoji predominantly for 'surprise' (This results in a low yield of actually surprised texts, about 150/ every 4000)\n",
    "To use Indico to find the surprising texts, in order to get to around 1000 surprising texts it will cost around $150. If we don't use multiple fake accounts.\n",
    "\n",
    "Alternative option: Get Facebook scraper approved in order to download facebook comments from \"wow\" stories (might have a higher yield of surprised texts)\n",
    "\n",
    "Continue looking for source of texts labelled with surprise (couldn't find yet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Input shape\n",
    "\n",
    "3D tensor with shape (batch_size, timesteps, input_dim)</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0:anger\n",
    "\n",
    "1:disgust\n",
    "\n",
    "2:fear\n",
    "\n",
    "3:guilt\n",
    "\n",
    "4: joy\n",
    "\n",
    "5:sadness\n",
    "\n",
    "6:shame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
